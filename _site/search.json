[
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Ex04",
    "section": "",
    "text": "1 Installing and Importing the data\n\npacman::p_load(haven, tidyverse, SmartEDA, tidymodels)\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n2 Draw a boxplot\n\nggplot(exam, aes(x=ENGLISH, y=CLASS))+\n  geom_boxplot()+\n  labs(title =\"English Score by Class\")+\n  theme_classic()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "About\nHi! I’m Johsuan (Doreen) Huang, a finance and accounting professional in the beauty industry with a passion for uncovering insights through visual analytics.\nIf you have any questions, please feel free to contact me :-)\n\n- Contact Info -\n\nLinkedin: johsuan-h\nEmail: johsuan.h@gmail.com"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 01",
    "section": "",
    "text": "1.1 Learning Objectives:\n\nBasic principles and essential components of ggplot2.\nApply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphic.\n\n\n\n1.2 Load the Package and Import the Data\n\n\n\n\n\n\nThe code chunk below assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\n\n# Load the package\npacman::p_load(tidyverse)\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr(one of the tidyverse package) package.\n\n\n# Import the data\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThe dataset contains examination grades for 3 subjects from a local school. We can use head() and summary() function inspect the dataset.\nThere are a total of 7 attributes. 4 of them are categorical data type and the other 3 are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\nhead(exam_data,5)\n\n# A tibble: 5 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n\n\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\n\n1.3 R Graphics VS ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR graphicsggplot 2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x=MATHS)) +\n  # use geom_histogram() to create a hist plot\n  geom_histogram(bins=10,\n                 boundary=100,\n                 color=\"black\",\n                 fill=\"#E8C8DB\") +\n  # setting a clean background\n  theme_classic()+\n  ggtitle(\"Distribution of Maths scores\")+\n  # adjust the position and weight of the title\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\nAlthough R Graphics’s code looks simpler than ggplot, according to Hadley Wickham, “The transferrable skills from ggplot2 are not the idiosyncracies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive”.\n\n\n1.4 Grammar of Graphics\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer.\nThe grammar of graphics is an answer to a question: ” What’s a statistical graphic? “\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\n\n1.4.1 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\n\n\n1.5 Essential Grammatical Elements in ggplot2: data\nLet us call the ggplot() function using the code chunk below.\n\n\n\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()\n\n\n\n\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\n\n\n\n\n\nggplot includes the x-axis and the axis’s label.\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. A plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nExamples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nBelow are the examples of geom:\n\n\nBarDotHistDensityBoxViolinPointCombined\n\n\n\ngeom_bar()\n\nggplot(data=exam_data,\n       aes(x=RACE))+\n  geom_bar(color=\"black\",\n           fill=\"#E8C8DB\")+\n  ggtitle(\"Distribution of Race\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_dotplot()\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\n\n\n\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS))+\n  geom_dotplot(binwidth=2.5,\n               dotsize = 0.5,\n               fill=\"#E8C8DB\")+\n  # use scale_y_continuous() to turn off y-axis\n  scale_y_continuous(NULL,\n                     breaks=NULL)+\n  ggtitle(\"Distribution of Math Scores\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_histogram()\n\n#  default bin is 30\nggplot(data=exam_data, \n       aes(x=MATHS))+\n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"#E8C8DB\")+\n  ggtitle(\"Distribution of Math Scores\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\ngeom_histogram() by Gender\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           fill=GENDER))+\n  geom_histogram(bins=20,\n                 color=\"black\")+\n  # customize the fill color\n  scale_fill_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data,\n       aes(x=MATHS))+\n  geom_density()+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\ngeom_density() by Gender\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data,\n       aes(x=MATHS,colour = GENDER))+\n  geom_density()+\n    # customize the color\n  scale_color_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot()\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\nggplot(data=exam_data,\n       aes(x=GENDER,\n           y=MATHS,\n           # add \"fill\" to customize boxplot's colors\n           fill=GENDER))+\n         geom_boxplot()+\n    # customize the color\n  scale_fill_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() with notch &gt;&gt;&gt; shows median\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\n\nggplot(data = exam_data,\n       aes(x = GENDER,\n           y = MATHS,\n           fill = GENDER))+\n  geom_boxplot(notch = TRUE)+\n  scale_fill_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_violin()\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\n\nggplot(data = exam_data,\n       aes(x = GENDER,\n           y = MATHS,\n           fill = GENDER))+\n  geom_violin()+\n  scale_fill_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\ngeom_point()\ngeom_point() is especially useful for creating scatterplot.\n\nggplot(data = exam_data,\n       aes(x = MATHS,\n           y = ENGLISH,\n           color = GENDER))+\n  geom_point()+\n  scale_color_manual(values = c(\"#D9A4C3\", \"#A4A8D9\"))+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCombine multiple geom objects\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot()and geom_point().\n\nggplot(data = exam_data,\n       aes(y = MATHS,\n           x = GENDER,\n           fill = GENDER))+\n  geom_point(position = \"jitter\", \n             size = 0.5)+\n  geom_boxplot()+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  scale_fill_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat_summary() or geom()\n\nstat_summary()geom_point()\n\n\n\nggplot(data = exam_data,\n       aes(x = GENDER, y = MATHS, fill = GENDER))+\n  geom_boxplot()+\n  scale_fill_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  theme_classic()+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))+\n  stat_summary(geom = \"point\",\n               fun = \"mean\",\n               color = \"black\",\n               size = 3\n               )\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = GENDER, y = MATHS, fill = GENDER))+\n  geom_boxplot()+\n  scale_fill_manual(values = c(\"#E8C8DB\", \"#C8DBE8\"))+\n  theme_classic()+\n  ggtitle(\"Distribution of Math Scores by Gender\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))+\n  geom_point(stat = \"summary\",\n               fun = \"mean\",\n               color = \"black\",\n               size = 3\n               )\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.2 Adding a best fit curve on a scatter plot with geom_smooth()\n geom_smooth() is used to plot a best fit curve on the scatterplot:\n\nLOESS MehodLM Method\n\n\nLOESS method is the default method of geom_smooth().\nLOESS (Locally Estimated Scatterplot Smoothing) is a non-parametric regression method that fits a smooth curve to the data. This method is particularly useful when the relationship between variables is non-linear.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH))+\n  geom_point()+\n  # default use loess regression method\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\n\n\nLM(Linear Model) refers to linear regression. It assumes the relationship between the dependent and independent variables are linear.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH))+\n  geom_point()+\n  geom_smooth(method = \"lm\", size=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.9 Essential Grammatical Elements in ggplot2: Facets\n\n1.9.1 Facets: Working with facet_wrap() and facet_grid()\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\nfacet_warp(): Creates facets by wrapping them into multiple rows or columns. It is useful for plotting a single variable (as below tab shown). We can control the number of rows or columns with the nrow and ncol arguments.\nfacet_grid(): Creates a grid of facets defined by one or two variables. It is useful for exploring relationships between two variables(as below tab shown).\n\n\nfacet_wrap()facet_grid()\n\n\n\nOne variable: Math by Class\n\n\nggplot(data = exam_data,\n       aes(x = MATHS))+\n  geom_histogram(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  facet_wrap(~ CLASS, nrow = 3)+\n  ggtitle(\"Distribution of Math Scores by Class\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\nTwo variables: Math by Class & RACE\n\n\nggplot(data = exam_data,\n       aes(x = CLASS, y = MATHS))+\n  geom_boxplot() +\n  stat_summary(geom = \"point\", fun = mean, colour =\"#C8DBE8\", size=2) + \n  facet_wrap(~ RACE)+\n  ggtitle(\"Distribution of Math Scores by Race and Class \")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nOne variable: Math by Class\n\n\nggplot(data = exam_data,\n       aes(MATHS))+\n  geom_histogram(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  facet_grid(~ CLASS)+\n  ggtitle(\"Distribution of Math Scores by Class \")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\nTwo variables: Math by Class & RACE\n\n\nggplot(data = exam_data,\n       aes(x = CLASS, y = MATHS))+\n  geom_boxplot() +\n  stat_summary(geom = \"point\", fun = mean, colour =\"#C8DBE8\", size=2) + \n  facet_grid(~ RACE)+\n  ggtitle(\"Distribution of Math Scores by Race and Class \")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.10 Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian(): fixed both the y-axis and x-axis in certain ranges.\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\ncoord_flip()coord_cartesian()\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  ggtitle(\"Number of Students by Race\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        panel.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\nThe scatterplot below is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH))+\n  geom_point()+\n  geom_smooth(method = \"lm\", size=0.5)+\n  # fixes both the y-axis and x-axis range from 0-100\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"Relationship between English and Math\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        panel.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\ntheme_gray()theme_classic()theme_minimal()theme_bw()theme_dark()theme_linedraw()theme_void()\n\n\nThis is the default theme.\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_classic()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_minimal()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_bw()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        # adjust the color of panel grid\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_dark()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_linedraw()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        # adjust the color of panel grid\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_void()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        # adjust the color of panel grid\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.12 References\n\nKam, T.S. (2025). A Layered Grammar of Graphics: ggplot2 methods.\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html",
    "title": "Hands-on Exercise 05.d",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#overview",
    "title": "Hands-on Exercise 05.d",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#getting-started",
    "title": "Hands-on Exercise 05.d",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImporting the dataObserving the dataData Wrangling\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(treemap, treemapify, tidyverse)\n\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\ntidyverse\na family of R packages for data processing\n\n\ntreemapify\nThe treemapify package allows creating treemaps in ggplot2\n\n\n\n\n\nIn this hands-on exercise, REALIS2018.csv will be used. This dataset provides information of private property transaction records in 2018, and was extracted from REALIS portal of Urban Redevelopment Authority (URA).\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 20 attributes and 23,205 observations with no missing values.\n\nhead(realis2018)\n\n# A tibble: 6 × 20\n  `Project Name`  Address             `No. of Units` `Area (sqm)` `Type of Area`\n  &lt;chr&gt;           &lt;chr&gt;                        &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;         \n1 ADANA @ THOMSON 8 Old Upper Thomso…              1           52 Strata        \n2 ALANA           156 Sunrise Terrace              1          284 Strata        \n3 ALANA           104 Sunrise Terrace              1          256 Strata        \n4 ALANA           126 Sunrise Terrace              1          256 Strata        \n5 ATELIER VILLAS  43 Yio Chu Kang Dr…              1          277 Strata        \n6 ATELIER VILLAS  11 Yio Chu Kang Dr…              1          285 Strata        \n# ℹ 15 more variables: `Transacted Price ($)` &lt;dbl&gt;, `Nett Price($)` &lt;chr&gt;,\n#   `Unit Price ($ psm)` &lt;dbl&gt;, `Unit Price ($ psf)` &lt;dbl&gt;, `Sale Date` &lt;chr&gt;,\n#   `Property Type` &lt;chr&gt;, Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;,\n#   `Type of Sale` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal District` &lt;dbl&gt;, `Postal Sector` &lt;dbl&gt;, `Postal Code` &lt;dbl&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\nstr(realis2018)\n\nspc_tbl_ [23,205 × 20] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Project Name               : chr [1:23205] \"ADANA @ THOMSON\" \"ALANA\" \"ALANA\" \"ALANA\" ...\n $ Address                    : chr [1:23205] \"8 Old Upper Thomson Road  #05-03\" \"156 Sunrise Terrace\" \"104 Sunrise Terrace\" \"126 Sunrise Terrace\" ...\n $ No. of Units               : num [1:23205] 1 1 1 1 1 1 1 1 1 1 ...\n $ Area (sqm)                 : num [1:23205] 52 284 256 256 277 285 234 155 115 117 ...\n $ Type of Area               : chr [1:23205] \"Strata\" \"Strata\" \"Strata\" \"Strata\" ...\n $ Transacted Price ($)       : num [1:23205] 888888 2530000 2390863 2450000 1980000 ...\n $ Nett Price($)              : chr [1:23205] \"-\" \"-\" \"2382517\" \"2441654\" ...\n $ Unit Price ($ psm)         : num [1:23205] 17094 8908 9307 9538 7148 ...\n $ Unit Price ($ psf)         : num [1:23205] 1588 828 865 886 664 ...\n $ Sale Date                  : chr [1:23205] \"4-Jul-18\" \"5-Oct-18\" \"9-Jun-18\" \"14-May-18\" ...\n $ Property Type              : chr [1:23205] \"Apartment\" \"Terrace House\" \"Terrace House\" \"Terrace House\" ...\n $ Tenure                     : chr [1:23205] \"Freehold\" \"103 Yrs From 12/08/2013\" \"103 Yrs From 12/08/2013\" \"103 Yrs From 12/08/2013\" ...\n $ Completion Date            : chr [1:23205] \"2018\" \"2018\" \"2018\" \"2018\" ...\n $ Type of Sale               : chr [1:23205] \"New Sale\" \"Sub Sale\" \"New Sale\" \"New Sale\" ...\n $ Purchaser Address Indicator: chr [1:23205] \"Private\" \"Private\" \"HDB\" \"N.A\" ...\n $ Postal District            : num [1:23205] 20 28 28 28 26 26 26 26 26 26 ...\n $ Postal Sector              : num [1:23205] 57 80 80 80 78 78 78 78 78 78 ...\n $ Postal Code                : num [1:23205] 573868 804555 804529 804540 786300 ...\n $ Planning Region            : chr [1:23205] \"North East Region\" \"North East Region\" \"North East Region\" \"North East Region\" ...\n $ Planning Area              : chr [1:23205] \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   `Project Name` = col_character(),\n  ..   Address = col_character(),\n  ..   `No. of Units` = col_double(),\n  ..   `Area (sqm)` = col_double(),\n  ..   `Type of Area` = col_character(),\n  ..   `Transacted Price ($)` = col_double(),\n  ..   `Nett Price($)` = col_character(),\n  ..   `Unit Price ($ psm)` = col_double(),\n  ..   `Unit Price ($ psf)` = col_double(),\n  ..   `Sale Date` = col_character(),\n  ..   `Property Type` = col_character(),\n  ..   Tenure = col_character(),\n  ..   `Completion Date` = col_character(),\n  ..   `Type of Sale` = col_character(),\n  ..   `Purchaser Address Indicator` = col_character(),\n  ..   `Postal District` = col_double(),\n  ..   `Postal Sector` = col_double(),\n  ..   `Postal Code` = col_double(),\n  ..   `Planning Region` = col_character(),\n  ..   `Planning Area` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(realis2018)\n\n Project Name         Address           No. of Units   Area (sqm)    \n Length:23205       Length:23205       Min.   :1     Min.   :  24.0  \n Class :character   Class :character   1st Qu.:1     1st Qu.:  67.0  \n Mode  :character   Mode  :character   Median :1     Median :  98.0  \n                                       Mean   :1     Mean   : 118.2  \n                                       3rd Qu.:1     3rd Qu.: 127.0  \n                                       Max.   :1     Max.   :4836.0  \n Type of Area       Transacted Price ($) Nett Price($)      Unit Price ($ psm)\n Length:23205       Min.   :    40000    Length:23205       Min.   :  355     \n Class :character   1st Qu.:   950000    Class :character   1st Qu.:11231     \n Mode  :character   Median :  1280000    Mode  :character   Median :14621     \n                    Mean   :  1734099                       Mean   :15246     \n                    3rd Qu.:  1858000                       3rd Qu.:18075     \n                    Max.   :100000000                       Max.   :54363     \n Unit Price ($ psf)  Sale Date         Property Type         Tenure         \n Min.   :  33       Length:23205       Length:23205       Length:23205      \n 1st Qu.:1043       Class :character   Class :character   Class :character  \n Median :1358       Mode  :character   Mode  :character   Mode  :character  \n Mean   :1416                                                               \n 3rd Qu.:1679                                                               \n Max.   :5050                                                               \n Completion Date    Type of Sale       Purchaser Address Indicator\n Length:23205       Length:23205       Length:23205               \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal District Postal Sector    Postal Code     Planning Region   \n Min.   : 1.00   Min.   : 1.00   Min.   : 18965   Length:23205      \n 1st Qu.:10.00   1st Qu.:26.00   1st Qu.:267952   Class :character  \n Median :15.00   Median :45.00   Median :456068   Mode  :character  \n Mean   :14.96   Mean   :42.66   Mean   :434269                     \n 3rd Qu.:19.00   3rd Qu.:54.00   3rd Qu.:548461                     \n Max.   :28.00   Max.   :82.00   Max.   :829750                     \n Planning Area     \n Length:23205      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n# check missing value\nany(is.na(realis2018))\n\n[1] FALSE\n\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarise() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\nThere are two ways to group the summaries:\n\nGrouped summaries without the Pipe\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\nGrouped summaries with the Pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\nhead(realis2018_summarised)\n\n# A tibble: 6 × 9\n# Groups:   Project Name, Planning Region, Planning Area, Property Type [6]\n  `Project Name`     `Planning Region` `Planning Area` `Property Type`      \n  &lt;chr&gt;              &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;                \n1 # 1 LOFT           Central Region    Geylang         Apartment            \n2 # 1 SUITES         Central Region    Geylang         Apartment            \n3 1 CANBERRA         North Region      Yishun          Executive Condominium\n4 1 KING ALBERT PARK Central Region    Bukit Timah     Condominium          \n5 10 EVELYN          Central Region    Novena          Apartment            \n6 10 SHELFORD        Central Region    Bukit Timah     Apartment            \n# ℹ 5 more variables: `Type of Sale` &lt;chr&gt;, `Total Unit Sold` &lt;dbl&gt;,\n#   `Total Area` &lt;dbl&gt;, `Median Unit Price ($ psm)` &lt;dbl&gt;,\n#   `Median Transacted Price` &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#designing-static-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#designing-static-treemap-with-treemap-package",
    "title": "Hands-on Exercise 05.d",
    "section": "3 Designing Static Treemap with treemap Package",
    "text": "3 Designing Static Treemap with treemap Package\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale & condominium property type from realis2018_selected data frame using filter().\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n3.1 Using the basic arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.(e.g. Central Region -&gt; Kallang -&gt; Pebble Bay)\n\nvSize\n\nThe column must not contain negative values. This is because its value will be used to map the sizes of the rectangles of the treemaps.\n\n\n\n\n\n\n3.2 Working with vColor and type arguments\nFor a correctly designed treemap, the rectangles should display varying color intensities. The plot in 3.1 is an incorrect example of this. In our case, median unit prices should determine the color intensity of each rectangle.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above\n\n\n\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\n\n3.3 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette.\nThe only difference between “value” and “manual” is the default value for mapping:\n\n“value” type treemap: considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color.\n“manual” type treemap: simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\nvalue-typemanual-type\n\n\nThe code chunk below shows a value type treemap:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nAs the plot shown below, The colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n3.5 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithmargument:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n3.6 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 05.d",
    "section": "4 Designing Treemap using treemapify Package",
    "text": "4 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n4.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n4.2 Defining hierarchy\n\nGroup by Planning RegionGroup by Planning Area\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +  #&lt;&lt;&lt; adding\n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line:\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\", #&lt;&lt; adding border for PA\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\") #&lt;&lt; adding border for planning region"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Exercise 05.d",
    "section": "5 Designing Interactive Treemap using d3treeR",
    "text": "5 Designing Interactive Treemap using d3treeR\n\n5.1 Load d3treeR package\n\nlibrary(d3treeR)\n\n\n\n5.2 Designing An Interactive Treemap\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap:\n\nd3tree(tm,rootname = \"Singapore\") #&lt;&lt; set up root name (the root) as Singapore"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_d.html#reference",
    "title": "Hands-on Exercise 05.d",
    "section": "6 Reference",
    "text": "6 Reference\n\nKam, T.S. (2025). Treemap Visualisation with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html",
    "title": "Hands-on Exercise 05.b",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will learn using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#overview",
    "title": "Hands-on Exercise 05.b",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will learn using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#getting-started",
    "title": "Hands-on Exercise 05.b",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoad the packagesImport the dataObserve the dataPrepare the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse, plotly)\n\n\n\n\nLibrary\nDescription\n\n\n\n\nseriation\nIt provides the infrastructure for ordering objects with an implementation of severalseriation/sequencing/ordination techniques to reorder matrices\n\n\ntidyverse\na family of R packages for data processing\n\n\ndendextend\nIt offers a set of functions for extending dendrogram objects in R, letting you visualizeand compare trees of hierarchical clusterings\n\n\nheatmaply\nIt help create cluster heatmaps based on plotly\n\n\n\n\n\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 12 attributes and 156 observations with no missing values.\n\nhead(wh)\n\n# A tibble: 6 × 12\n  Country         Region `Happiness score` `Whisker-high` `Whisker-low` Dystopia\n  &lt;chr&gt;           &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 Albania         Centr…              4.59           4.70          4.48     1.46\n2 Bosnia and Her… Centr…              5.13           5.22          5.04     1.88\n3 Bulgaria        Centr…              4.93           5.02          4.84     1.22\n4 Croatia         Centr…              5.32           5.40          5.24     1.77\n5 Czech Republic  Centr…              6.71           6.78          6.64     2.49\n6 Estonia         Centr…              5.74           5.82          5.66     1.46\n# ℹ 6 more variables: `GDP per capita` &lt;dbl&gt;, `Social support` &lt;dbl&gt;,\n#   `Healthy life expectancy` &lt;dbl&gt;, `Freedom to make life choices` &lt;dbl&gt;,\n#   Generosity &lt;dbl&gt;, `Perceptions of corruption` &lt;dbl&gt;\n\n\n\nstr(wh)\n\nspc_tbl_ [156 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Country                     : chr [1:156] \"Albania\" \"Bosnia and Herzegovina\" \"Bulgaria\" \"Croatia\" ...\n $ Region                      : chr [1:156] \"Central and Eastern Europe\" \"Central and Eastern Europe\" \"Central and Eastern Europe\" \"Central and Eastern Europe\" ...\n $ Happiness score             : num [1:156] 4.59 5.13 4.93 5.32 6.71 ...\n $ Whisker-high                : num [1:156] 4.7 5.22 5.02 5.4 6.78 ...\n $ Whisker-low                 : num [1:156] 4.48 5.04 4.84 5.24 6.64 ...\n $ Dystopia                    : num [1:156] 1.46 1.88 1.22 1.77 2.49 ...\n $ GDP per capita              : num [1:156] 0.916 0.915 1.054 1.115 1.233 ...\n $ Social support              : num [1:156] 0.817 1.078 1.515 1.161 1.489 ...\n $ Healthy life expectancy     : num [1:156] 0.79 0.758 0.712 0.737 0.854 0.737 0.732 0.578 0.671 0.716 ...\n $ Freedom to make life choices: num [1:156] 0.419 0.28 0.359 0.38 0.543 0.553 0.259 0.448 0.363 0.35 ...\n $ Generosity                  : num [1:156] 0.149 0.216 0.064 0.12 0.064 0.086 0.061 0.274 0.092 0.026 ...\n $ Perceptions of corruption   : num [1:156] 0.032 0 0.009 0.039 0.034 0.174 0.022 0.023 0.066 0.006 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Country = col_character(),\n  ..   Region = col_character(),\n  ..   `Happiness score` = col_double(),\n  ..   `Whisker-high` = col_double(),\n  ..   `Whisker-low` = col_double(),\n  ..   Dystopia = col_double(),\n  ..   `GDP per capita` = col_double(),\n  ..   `Social support` = col_double(),\n  ..   `Healthy life expectancy` = col_double(),\n  ..   `Freedom to make life choices` = col_double(),\n  ..   Generosity = col_double(),\n  ..   `Perceptions of corruption` = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(wh)\n\n   Country             Region          Happiness score  Whisker-high  \n Length:156         Length:156         Min.   :2.905   Min.   :3.074  \n Class :character   Class :character   1st Qu.:4.454   1st Qu.:4.590  \n Mode  :character   Mode  :character   Median :5.378   Median :5.478  \n                                       Mean   :5.376   Mean   :5.479  \n                                       3rd Qu.:6.168   3rd Qu.:6.260  \n                                       Max.   :7.632   Max.   :7.695  \n  Whisker-low       Dystopia     GDP per capita   Social support \n Min.   :2.735   Min.   :0.292   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:4.345   1st Qu.:1.654   1st Qu.:0.6162   1st Qu.:1.077  \n Median :5.285   Median :1.909   Median :0.9495   Median :1.262  \n Mean   :5.273   Mean   :1.923   Mean   :0.8874   Mean   :1.217  \n 3rd Qu.:6.051   3rd Qu.:2.270   3rd Qu.:1.1978   3rd Qu.:1.463  \n Max.   :7.569   Max.   :2.961   Max.   :1.6490   Max.   :1.644  \n Healthy life expectancy Freedom to make life choices   Generosity    \n Min.   :0.0000          Min.   :0.0000               Min.   :0.0000  \n 1st Qu.:0.4223          1st Qu.:0.3583               1st Qu.:0.1095  \n Median :0.6440          Median :0.4940               Median :0.1740  \n Mean   :0.5980          Mean   :0.4570               Mean   :0.1816  \n 3rd Qu.:0.7772          3rd Qu.:0.5800               3rd Qu.:0.2422  \n Max.   :1.0300          Max.   :0.7240               Max.   :0.5980  \n Perceptions of corruption\n Min.   :0.0000           \n 1st Qu.:0.0510           \n Median :0.0820           \n Mean   :0.1125           \n 3rd Qu.:0.1390           \n Max.   :0.4570           \n\n\n\n# check missing value\nany(is.na(wh))\n\n[1] FALSE\n\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name:\n\n\nTransform the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix:\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\nhead(wh_matrix)\n\n                       Country Region Happiness score Whisker-high Whisker-low\nAlbania                      2      1           4.586        4.695       4.477\nBosnia and Herzegovina      18      1           5.129        5.224       5.035\nBulgaria                    21      1           4.933        5.022       4.844\nCroatia                     35      1           5.321        5.398       5.244\nCzech Republic              37      1           6.711        6.783       6.639\nEstonia                     43      1           5.739        5.815       5.663\n                       Dystopia GDP per capita Social support\nAlbania                   1.462          0.916          0.817\nBosnia and Herzegovina    1.883          0.915          1.078\nBulgaria                  1.219          1.054          1.515\nCroatia                   1.769          1.115          1.161\nCzech Republic            2.494          1.233          1.489\nEstonia                   1.457          1.200          1.532\n                       Healthy life expectancy Freedom to make life choices\nAlbania                                  0.790                        0.419\nBosnia and Herzegovina                   0.758                        0.280\nBulgaria                                 0.712                        0.359\nCroatia                                  0.737                        0.380\nCzech Republic                           0.854                        0.543\nEstonia                                  0.737                        0.553\n                       Generosity Perceptions of corruption\nAlbania                     0.149                     0.032\nBosnia and Herzegovina      0.216                     0.000\nBulgaria                    0.064                     0.009\nCroatia                     0.120                     0.039\nCzech Republic              0.064                     0.034\nEstonia                     0.086                     0.174"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#static-heatmap",
    "title": "Hands-on Exercise 05.b",
    "section": "3 Static Heatmap",
    "text": "3 Static Heatmap\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\n\n3.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below:\n\nBasic HeatmapCluster HeatmapNormalized Heatmap\n\n\n\npar(bg = \"#f3f1e9\") # set the background of plotting area\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\n\n\n\n\n\npar(bg = \"#f3f1e9\")\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\n\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\n\n\nThe code chunk below normalizes the matrix column-wise, making the dendrogram easier to interpret.\n\npar(bg = \"#f3f1e9\")\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, #font size of y axis\n                      cexCol = 0.8, #font size of x axis\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that the values are scaled now.\nNote that margins argument is used to ensure that the entire x-axis labels are displayed completely and,\ncexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 05.b",
    "section": "4 Creating Interactive Heatmap",
    "text": "4 Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n4.1 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\n\n\n\n\n\n\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\n\n\n\n\n\nThe code wh_matrix[, -c(1, 2, 4, 5)] is using negative indexing in R to exclude specific columns before passing the data to the heatmaply() function.\n\n-c(1, 2, 4, 5) means remove columns 1,2,4,5, which are “Country”, “Region”, “Whisker-high” and “Whisker-low” (The upper and lower confidence interval for the happiness score)\n\n\n\n\n\n\n4.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\nScaling methodNormalising methodPercentising method\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise:\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\n\n4.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndistfun\nfunction used to compute the distance (dissimilarity) between both rows and columns.\n\n\nhclustfun\nfunction used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\n\n\ndist_method\ndefault is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\n\n\nhclust_method\ndefault is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\n\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n4.4 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n4.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method (optim = 0.6701688) should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster:\n\npar(bg = \"#f3f1e9\")\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3) # cluster number\n\n\n\n\n\n\n\n4.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nHeatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as ggplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")+\n  theme()\n\nNULL\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix:\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n4.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used:\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n4.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins = c (bottom, left, top, right), change the margin to make space for plot and text element\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\nwidth and height are used to set plot size\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(100,150,100,100), #bottom, left, top, right\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\",\n          width = 600,\n          height = 1200\n          ) %&gt;%\n  layout(plot_bgcolor = \"#f3f1e9\",paper_bgcolor = \"#f3f1e9\",\n         legend = list(bgcolor = \"#f3f1e9\"),\n         title = list(\n      text = \"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n      font = list(size = 18, face = \"bold\")\n    ))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_b.html#reference",
    "title": "Hands-on Exercise 05.b",
    "section": "5 Reference",
    "text": "5 Reference\n\nKam, T.S. (2025). Heatmap for Visualising and Analysing Multivariate Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html",
    "title": "Hands-on Exercise 05.a",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#overview",
    "title": "Hands-on Exercise 05.a",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#getting-started",
    "title": "Hands-on Exercise 05.a",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImport dataObserve dataPrepare data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(tidyverse, ggtern, plotly)\n\n\n\n\nLibrary\nDescription\n\n\n\n\nggtern\na ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\n\n\ntidyverse\na family of R packages for data processing\n\n\nPlotly R\nan R package for creating interactive web-based graphs via plotly’s JavaScript graphing library.\n\n\n\n\n\nIn this exercise, the  Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 will be used. We use read_csv() of readr to import the data:\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 5 attributes and 108,126 observations with no missing values:\n\nhead(pop_data)\n\n# A tibble: 6 × 5\n  PA         SZ                     AG      Year Population\n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2011        290\n2 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2012        270\n3 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2013        260\n4 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2014        250\n5 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2015        260\n6 Ang Mo Kio Ang Mo Kio Town Centre AGE0-4  2016        250\n\n\n\nstr(pop_data)\n\nspc_tbl_ [108,126 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ PA        : chr [1:108126] \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" ...\n $ SZ        : chr [1:108126] \"Ang Mo Kio Town Centre\" \"Ang Mo Kio Town Centre\" \"Ang Mo Kio Town Centre\" \"Ang Mo Kio Town Centre\" ...\n $ AG        : chr [1:108126] \"AGE0-4\" \"AGE0-4\" \"AGE0-4\" \"AGE0-4\" ...\n $ Year      : num [1:108126] 2011 2012 2013 2014 2015 ...\n $ Population: num [1:108126] 290 270 260 250 260 250 200 180 290 290 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   PA = col_character(),\n  ..   SZ = col_character(),\n  ..   AG = col_character(),\n  ..   Year = col_double(),\n  ..   Population = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(pop_data)\n\n      PA                 SZ                 AG                 Year     \n Length:108126      Length:108126      Length:108126      Min.   :2000  \n Class :character   Class :character   Class :character   1st Qu.:2004  \n Mode  :character   Mode  :character   Mode  :character   Median :2009  \n                                                          Mean   :2009  \n                                                          3rd Qu.:2014  \n                                                          Max.   :2018  \n   Population     \n Min.   :    0.0  \n 1st Qu.:    0.0  \n Median :  140.0  \n Mean   :  644.1  \n 3rd Qu.:  800.0  \n Max.   :14560.0  \n\n\n\nany(is.na(pop_data))\n\n[1] FALSE\n\n\n\n\nFrom the “Observe data” tab, we can see that age is a categorical variable. For better analysis, we should transpose this variable and group the ages into young, active, and old categories to make the data more interpretable:\nThere are 10 age groups in this dataset:\n\npop_data %&gt;% distinct(AG)\n\n# A tibble: 18 × 1\n   AG       \n   &lt;chr&gt;    \n 1 AGE0-4   \n 2 AGE10-14 \n 3 AGE15-19 \n 4 AGE20-24 \n 5 AGE25-29 \n 6 AGE30-34 \n 7 AGE35-39 \n 8 AGE40-44 \n 9 AGE45-49 \n10 AGE05-9  \n11 AGE50-54 \n12 AGE55-59 \n13 AGE60-64 \n14 AGE65-69 \n15 AGE70-74 \n16 AGE75-79 \n17 AGE80-84 \n18 AGE85over\n\n\n\n# Adding new derived variables for the young, economy active and old age group\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year)) %&gt;%\n  spread(AG, Population) %&gt;% \n  mutate(YOUNG = rowSums(.[4:8])) %&gt;%     # Ages 0-24\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%  # Ages 25-64\n  mutate(OLD = rowSums(.[17:21])) %&gt;%     # Above 65\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%   # All\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\nhead(agpop_mutated)\n\n# A tibble: 6 × 25\n  PA         SZ        Year  `AGE0-4` `AGE05-9` `AGE10-14` `AGE15-19` `AGE20-24`\n  &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo K… 2018       180       270        320        300        260\n2 Ang Mo Kio Cheng San 2018      1060      1080       1080       1260       1400\n3 Ang Mo Kio Chong Bo… 2018       900       900       1030       1220       1380\n4 Ang Mo Kio Kebun Ba… 2018       720       850       1010       1120       1230\n5 Ang Mo Kio Sembawan… 2018       220       310        380        500        550\n6 Ang Mo Kio Shangri-… 2018       550       630        670        780        950\n# ℹ 17 more variables: `AGE25-29` &lt;dbl&gt;, `AGE30-34` &lt;dbl&gt;, `AGE35-39` &lt;dbl&gt;,\n#   `AGE40-44` &lt;dbl&gt;, `AGE45-49` &lt;dbl&gt;, `AGE50-54` &lt;dbl&gt;, `AGE55-59` &lt;dbl&gt;,\n#   `AGE60-64` &lt;dbl&gt;, `AGE65-69` &lt;dbl&gt;, `AGE70-74` &lt;dbl&gt;, `AGE75-79` &lt;dbl&gt;,\n#   `AGE80-84` &lt;dbl&gt;, AGE85over &lt;dbl&gt;, YOUNG &lt;dbl&gt;, ACTIVE &lt;dbl&gt;, OLD &lt;dbl&gt;,\n#   TOTAL &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 05.a",
    "section": "3 Plotting Ternary Diagram with R",
    "text": "3 Plotting Ternary Diagram with R\n\n3.1 Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n3.1.1 Basic plot\n\n#Building the static ternary plot\nggtern(data = agpop_mutated,\n       aes(x = YOUNG,\n           y = ACTIVE, \n           z = OLD)) +\n  geom_point() +\n  theme_classic()+\n  ggtitle(\"Basic static ternary plot\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        panel.background = element_rect(colour =\"#f3f1e9\",fill = \"#f3f1e9\"),\n        plot.background = element_rect(colour =\"#f3f1e9\",fill = \"#f3f1e9\")) \n\n\n\n\n\n\n\n\n\n\n3.1.2 Adding colour and title\n\n#Building the static ternary plot\nggtern(data = agpop_mutated, \n       aes(x = YOUNG,\n           y = ACTIVE, \n           z = OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw() +\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        panel.background = element_rect(colour =\"#f3f1e9\",fill = \"#f3f1e9\"),\n        plot.background = element_rect(colour =\"#f3f1e9\",fill = \"#f3f1e9\")) \n\n\n\n\n\n\n\n\n\n\n\n3.2 Plotting an interative ternary diagram with Plot_ly()\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n\n\nDisplay Code\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Economically Active\"), \n  caxis = axis(\"Aged\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_a.html#reference",
    "title": "Hands-on Exercise 05.a",
    "section": "4 Reference",
    "text": "4 Reference\n\nKam, T.S. (2025). Creating Ternary Plot with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html",
    "title": "Hands-on Exercise 03.a",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#learning-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#learning-object",
    "title": "Hands-on Exercise 03.a",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#getting-started",
    "title": "Hands-on Exercise 03.a",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task:\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse, hrbrthemes)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#importing-data",
    "title": "Hands-on Exercise 03.a",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nhead(exam_data,5)\n\n# A tibble: 5 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 03.a",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. \n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\n\n\n\n\n\nWhat’s the difference between geom_dotplot and geom_dotplot_interactive?\n\ngeom_dotplot (from ggplot2): Creates a dot plot in static visualizations using the ggplot2 package.\ngeom_dotplot_interactive (from ggiraph): Provides interactive dot plots using the ggiraph package, allowing features like tooltips, click events, and hover effects. It needs girafe() function to display it interactively in an HTML-compatible environment (e.g., RMarkdown, Shiny, or an R notebook).\n\n\n\n\n\n\n\n\n\n\nLet’s breakdown the setting in geom_dotplot_interactive():\n\naes(tooltip = ID): This is the aesthetic mapping (aes) that specifies what information should appear in the tooltip when a user interacts with a dot.\nstackgroups=TRUE: It means the dots representing the same value will be stacked on top of each other. The default setting is FALSE.\nbinwidth=1: The binwidth argument controls the width of the bins used in the dot plot. This is similar to the “bin width” concept in histograms.\nmethod=\"histodot\": This specifies the method used to place the dots.\n\n“histodot”: It places the dots in a manner similar to how a histogram is drawn, but each dot represents an individual data point, and they are stacked or spaced according to the data.\n\n\n\n\n\n\n# create ggplot object\np &lt;- ggplot(data=exam_data, aes(x=MATHS))+\n  geom_dotplot_interactive(aes(tooltip = ID),stackgroups=TRUE, \n                           binwidth=1,method =\"histodot\")+\n  # remove the y-axis to avoid misleading visualization\n  scale_y_continuous(NULL, breaks = NULL)+\n  theme_ipsum()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(size=14, face = \"bold\"),\n        plot.subtitle = element_text(size = 9,face= \"italic\" ,family = \"Helvetica\"),\n        plot.caption = element_text(size=6, face=\"plain\"))+\n  labs(title = \"The example of an interactive graph\",\n       subtitle = \"By hovering the mouse pointer on an data point of interest, the student's ID will be displayed.\",\n       x = \"Math Score\",\n       caption=\"Source: ISSS608 VAA - Exam_data\")\n  \n\n# use girafe() to create an interactive svg object (the tooltips) compatible in html environments.\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactivity",
    "title": "Hands-on Exercise 03.a",
    "section": "3.5 Interactivity",
    "text": "3.5 Interactivity\n\n3.5.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customized by including a list object as shown in the code chunk below.\n\n\n\n\n\n\nLet’s break down the code step by step:\n\nexam_data$tooltip: This is creating a new column in the exam_data data frame called tooltip. The $ operator is used to refer to and create or access columns in a data frame.\nc(...): This function in R is used to combine values into a vector. Vectors are often used as building blocks for more complex data structures like data frames, matrices, and lists in R. In this case, it’s combining the result of the paste0()function.\npaste0(): This function is used to concatenate strings without any separator. It’s used here to combine different pieces of information (e.g., “Name =”, exam_data$ID, etc.).\nexam_data$ID & exam_data$CLASS: Accesses the “ID” and “CLASS” column in the exam_data data frame.\n\n\n\n\n\n# create new column \"tooltip\" in the dataframe \"exam_data\"\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS\n))\n\n# create ggplot object\np1 &lt;- ggplot(data=exam_data, aes(x=MATHS))+\n  geom_dotplot_interactive(aes(tooltip = exam_data$tooltip),stackgroups=TRUE, \n                           binwidth=1,method =\"histodot\")+\n  # remove the y-axis to avoid misleading visualization\n  scale_y_continuous(NULL, breaks = NULL)+\n  theme_ipsum()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(size=14, face = \"bold\"),\n        plot.subtitle = element_text(size = 9,face= \"italic\" ,family = \"Helvetica\"),\n        plot.caption = element_text(size=6, face=\"plain\"))+\n  labs(title = \"The example of an interactive graph\",\n       subtitle = \"By hovering the mouse pointer on an data point of interest, the student's ID will be displayed.\",\n       x = \"Math Score\",\n       caption=\"Source: ISSS608 VAA - Exam_data\")\n  \n\n# use girafe() to create an interactive svg object (the tooltips) compatible in html environments.\ngirafe(ggobj = p1,\n       width_svg = 6,\n       height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactivity---customization",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactivity---customization",
    "title": "Hands-on Exercise 03.a",
    "section": "3.6 Interactivity - Customization",
    "text": "3.6 Interactivity - Customization\n\n3.6.1 Customising Tooltip and Hover style\nThe code chunk below uses opts_tooltip() and opts_hover() from ggiraph to customize tooltip and hover rendering by adding CSS declarations.\nTo highlight data points on hover, we can use ggiraph’s interactive feature data_id. The default hover CSS setting is hover_css = “fill:orange;”.\nWe can also add opts_hover_inv(css = \"opacity:0.1;\") to the options argument to highlight observations on hover (as shown in Example 2).\n\nExample 1Example 2\n\n\n\n# create a varibale for customized tooltip style\nhover_css &lt;- \"fill:#A4A9D9; stroke:black ;stroke-width:1px;\"\ntooltip_css &lt;- \"background-color:white; font-style: bold; color:black; border-radius: 5px; margin: 3px; padding:3px;\"  \n\n# create ggplot object\np2 &lt;- ggplot(data=exam_data, aes(x=MATHS))+\n  geom_dotplot_interactive(tooltip = exam_data$tooltip, data_id= exam_data$ID,\n                           stackgroups=TRUE, \n                           binwidth=1,method =\"histodot\")+\n  # remove the y-axis to avoid misleading visualization\n  scale_y_continuous(NULL, breaks = NULL)+\n  theme_ipsum()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(size=14, face = \"bold\"),\n        plot.subtitle = element_text(size = 9,face= \"italic\" ,family = \"Helvetica\"),\n        plot.caption = element_text(size=6, face=\"plain\"))+\n  labs(title = \"The example of an interactive graph\",\n       subtitle = \"By hovering the mouse pointer on an data point of interest, the student's ID will be displayed.\",\n       x = \"Math Score\",\n       caption=\"Source: ISSS608 VAA - Exam_data\")\n\n\ngirafe(ggobj = p2,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(\n         opts_hover(css = hover_css),       # Apply hover CSS\n         opts_tooltip(css = tooltip_css)   # Apply tooltip CSS\n       ))\n\n\n\n\n\n\n\n\n#| eval: true\n#| echo: true\n\n\n# create a varibale for customized tooltip style\nhover_css &lt;- \"fill:black; stroke:black ;stroke-width:1px;\"\ntooltip_css &lt;- \"background-color:white; font-style: bold; color:black; border-radius: 5px; margin: 3px; padding:3px;\"  \n\n# create ggplot object\np3 &lt;- ggplot(data=exam_data, aes(x=MATHS, y=ENGLISH, color = GENDER))+\n  scale_color_manual(values = c(\"#D9A4C3\", \"#A4A8D9\"))+\n  geom_point_interactive(aes(tooltip= tooltip, data_id = tooltip),hover_nearest = TRUE)+\n  theme_ipsum()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(size=14, face = \"bold\"),\n        plot.subtitle = element_text(size = 9,face= \"italic\" ,family = \"Helvetica\"),\n        plot.caption = element_text(size=6, face=\"plain\",),\n        legend.title = element_text(size = 8,face= \"bold\" ,family = \"Arial\"),\n        legend.text = element_text(size = 8,family = \"Arial\"),\n        )+\n  labs(title = \"The example of an interactive graph\",\n       subtitle = \"By hovering the mouse pointer on an data point of interest, the student's ID will be displayed.\",\n       caption=\"Source: ISSS608 VAA - Exam_data\")\n    \n\ngirafe(ggobj = p3,\n       width_svg = 6,\n       height_svg = 6 * 0.618,\n       options = list(\n         opts_hover(css = hover_css),       # Apply hover CSS\n         opts_tooltip(css = tooltip_css),   # Apply tooltip CSS\n         opts_hover_inv(css = \"opacity:0.4;\")  # Make other points less visible when hovering\n       ))\n\n\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n3.6.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\n\n\n\n\nLet’s break down the code below step by step:\nFirst code\n\nfunction(y, ymax, accuracy= .01): We first define a function() with 2 positional argument (y and ymax) and 1 key word argument (accuracy) and assign it to variable “tooltip_s”\n{}: The {} groups together the steps of computing the mean and standard error and finally returning the formatted text. Without {}, only the first statement would be considered inside the function, and the rest would be ignored.\n\nscales::number(y,accuracy=0.01): The function number() from the scales package is used to format numbers in a human-readable way. It adds commas, controls decimal places, and adjusts numerical representations.\npaste(): Concatenates strings with a specified separator (default is a space \" \"). paste0(): Concatenates strings without any separator.\n\n\nSecond code\n\nfun.data = \"mean_se\": mean_se is a built-in summary function in ggplot2.It calculates:\n\ny → the mean of the data (e.g., mean(MATHS))\nymin → lower bound of the error bar (mean - standard error)\nymax → upper bound of the error bar (mean + standard error)\n\n\n\nThese computed values (y, ymin, and ymax) are then made available internally in the plotting process, allowing them to be accessed using after_stat().\n\nafter_stat(tooltip_s(y, ymax)): after_stat() ensures that the variables being passed to the function tooltip_s(y, ymax) are computed after ggplot2applies statistical transformations (like calculating means and standard errors).\ngeom = GeomInteractiveCol: It is the interactive version of geom_col(), allowing for tooltips, hover effects, and onclick actions.\n\n\n\n\n\ntooltip_s &lt;- function(y, ymax, accuracy= .01){\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n} \n\ngg_point &lt;- ggplot(data=exam_data, aes(x=RACE))+\n  stat_summary(aes(y=MATHS, tooltip = after_stat(tooltip_s(y,ymax))),\n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"#C8DBE8\")+\n  stat_summary(aes(y=MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, size = 0.2)+\n  theme_ipsum()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(size=14, face = \"bold\"),\n        plot.subtitle = element_text(size = 10,face= \"italic\" ,family = \"Helvetica\"),\n        plot.caption = element_text(size=10, face=\"plain\"),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.title = element_text(size=14)\n        )+\n  labs(title = \"The example of an interactive graph\",\n       subtitle = \"By hovering the mouse pointer over a box of interest, the 90% of CI of mean math scores will be displayed.\",\n       caption=\"Source: ISSS608 VAA - Exam_data\")\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n3.6.3 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\n\n\n\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n                             \"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\n                             as.character(exam_data$ID))\ngg_click &lt;- ggplot(data=exam_data,aes(x=MATHS))+\n  geom_dotplot_interactive(\n    aes(onclick=onclick),\n    stackgroups = TRUE,\n    binwidth = 1, method = \"histodot\")+\n  scale_y_continuous(NULL,breaks = NULL)+\n  theme_ipsum()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(size=14, face = \"bold\"),\n        plot.subtitle = element_text(size = 10,face= \"italic\" ,family = \"Helvetica\"),\n        plot.caption = element_text(size=10, face=\"plain\"),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.title = element_text(size=14)\n        )+\n  labs(title = \"The example of an interactive graph\",\n       subtitle = \"Clicking on the graph will link you to the external website.\",\n       caption=\"Source: ISSS608 VAA - Exam_data\")\n\n\ngirafe(                                  \n  ggobj = gg_click,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618) \n\n\n\n\n\n\n\n3.6.4 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\n\n\n\n\n\n\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\ncommon_theme &lt;- theme_minimal(base_size = 10) +\n  theme(\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n    panel.background = element_rect(fill = \"#f3f1e9\", color = \"black\", size=1),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.title = element_text(size = 10, face = \"bold\",hjust=0.5),\n    axis.text = element_text(size = 8),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10, face = \"italic\"),\n    plot.caption = element_text(size = 8)\n  )\n\np1 &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID,tooltip = tooltip),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL, breaks = NULL)+\n  common_theme\n\np2 &lt;- ggplot(data=exam_data, aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID, tooltip = tooltip),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL, breaks = NULL)+\n  common_theme\n\n\npatch &lt;- (p1 / p2) + # patchwork \n  common_theme +\n  plot_annotation(\n    title = \"The example of an interactive graph\",\n    subtitle = \"Clicking on the graph will link you to the external website.\",\n    caption = \"Source: ISSS608 VAA - Exam_data\",\n    theme = common_theme  \n  )\n\ngirafe(\n  code = print(patch), \n  width_svg = 6,\n  height_svg = 4,\n  options = list(\n    opts_hover(css = \"fill: #202020;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  ))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 03.a",
    "section": "3.7 Interactive Data Visualisation - plotly methods!",
    "text": "3.7 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, x = ~MATHS, y = ~ENGLISH) %&gt;%\n  layout(plot_bgcolor = \"#f3f1e9\",paper_bgcolor = \"#f3f1e9\",\n         title = list(\n      text = \"The example of an interactive graph by plot_ly()\",\n      font = list(size = 18, face = \"bold\")\n    ))\n\n\n\n\n\n\n\n3.7.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, x = ~ENGLISH, y = ~MATHS, \n        color = ~RACE) %&gt;%\n  layout(plot_bgcolor = \"#f3f1e9\",paper_bgcolor = \"#f3f1e9\",\n         title = list(\n      text = \"The example of an interactive graph by plot_ly()\",\n      font = list(size = 18, face = \"bold\")\n    ))\n\n\n\n\n\n\n\n3.7.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly(). * Notice that the only extra line you need to include in the code chunk is ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))+\n  ggtitle(\"The example of an interactive graph\")+\n  theme_ipsum()+\n      theme(\n        plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n        panel.background = element_rect(fill = \"#f3f1e9\", color = \"black\", size=1),\n        axis.title = element_text(size = 10, face = \"bold\",hjust=0.5),\n        axis.text = element_text(size = 8),\n        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n      )\nggplotly(p)\n\n\n\n\n\n\n\n3.7.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk.\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\n\ncommon_theme &lt;- theme_ipsum()+\n      theme(\n        plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n        panel.background = element_rect(fill = \"#f3f1e9\", color = \"black\", size=1),\n        axis.title = element_text(size = 10, face = \"bold\",hjust=0.5),\n        axis.text = element_text(size = 8),\n        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n      )\n\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))+\n  common_theme\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))+\n  common_theme+\n  ggtitle(\"The example of an interactive graph\")\n\n\nsubplot(ggplotly(p1),ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 03.a",
    "section": "3.8 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.8 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.8.1 Interactive Data Table: DT package\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\ntable &lt;- DT::datatable(exam_data, class= \"display\",\n              caption = \"Table 1: Exam data\") %&gt;%\n  formatStyle(\n    columns = colnames(exam_data), \n    fontSize = '12px', \n    fontFamily = 'Helvetica', \n    lineHeight = '1.2'\n  )\ntable\n\n\n\n\n\n\n\n3.8.2 Linked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown below.\n\nd &lt;- highlight_key(exam_data) \n\np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))+\n  ggtitle(\"Exam Data\")+\n  theme_ipsum()+\n  theme(\n        plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n        panel.background = element_rect(fill = \"#f3f1e9\", color = \"black\", size=1),\n        axis.title = element_text(size = 10, face = \"bold\",hjust=0.5),\n        axis.text = element_text(size = 8),\n        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n      )\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = c(5,6))        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_EX03.html#reference",
    "title": "Hands-on Exercise 03.a",
    "section": "3.9 Reference",
    "text": "3.9 Reference\n\n3.9.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.9.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\ngganimate - Getting Started\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 04.a",
    "section": "",
    "text": "In previous hand-on exercises, we have draw some popular statistical graphs, like histogram, boxplot, scatter plot and etc. In this hands-on exercise, we are going to learn new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "title": "Hands-on Exercise 04.a",
    "section": "",
    "text": "In previous hand-on exercises, we have draw some popular statistical graphs, like histogram, boxplot, scatter plot and etc. In this hands-on exercise, we are going to learn new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "title": "Hands-on Exercise 04.a",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImporting the dataExamining the dataTransforming the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse, patchwork)\n\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nggridges\na ggplot2 extension specially designed for plotting ridgeline plots\n\n\nggdist\na ggplot2 extension spacially desgin for visualising distribution and uncertainty. (*dist stands for distribution)\n\n\ntidyverse\na family of R packages for data processing\n\n\nggthemes\na ggplot extension for ggplots, providing additional themes, scales, and geoms\n\n\ncolorspace\na R package provides a broad toolbox for selecting individual colors or color palettes, manipulating and employing these colors in various kinds of visualisations.\n\n\n\n\n\nIn this exercise, Exam_data.csv will be used. We use read_csv() of readr to import the data:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 7 attributes and 322 observations with no missing values.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\n\nstr(exam)\n\nspc_tbl_ [322 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ID     : chr [1:322] \"Student321\" \"Student305\" \"Student289\" \"Student227\" ...\n $ CLASS  : chr [1:322] \"3I\" \"3I\" \"3H\" \"3F\" ...\n $ GENDER : chr [1:322] \"Male\" \"Female\" \"Male\" \"Male\" ...\n $ RACE   : chr [1:322] \"Malay\" \"Malay\" \"Chinese\" \"Chinese\" ...\n $ ENGLISH: num [1:322] 21 24 26 27 27 31 31 31 33 34 ...\n $ MATHS  : num [1:322] 9 22 16 77 11 16 21 18 19 49 ...\n $ SCIENCE: num [1:322] 15 16 16 31 25 16 25 27 15 37 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ID = col_character(),\n  ..   CLASS = col_character(),\n  ..   GENDER = col_character(),\n  ..   RACE = col_character(),\n  ..   ENGLISH = col_double(),\n  ..   MATHS = col_double(),\n  ..   SCIENCE = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(exam)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\nany(is.na(exam))\n\n[1] FALSE\n\n\n\n\nIn R, factors are used to handle categorical data and ordered variable. As there are categorical attributes in our dataset, we are going to convert their data type from &lt;chr&gt; to &lt;fctr&gt;:\n\ncol &lt;- c(\"CLASS\",\"GENDER\",\"RACE\")\nexam &lt;- exam %&gt;% mutate(across(all_of(col), as.factor))\n\nAfter converting the attributes, let’s check the data again:\n\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 04.a",
    "section": "3 Visualising Distribution with Ridgeline Plot",
    "text": "3 Visualising Distribution with Ridgeline Plot\nA Ridgeline plot (sometimes called Joyplot) shows the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\n\n\n\n\n\nWhat for?\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than ~6 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n3.1 Plotting ridgeline graph: ggridges method\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges():\n\n\n\nDisplay Code\n\nggplot(exam, aes(x=ENGLISH, y=CLASS))+\n  geom_density_ridges(\n    scale = 2, # adjust the size (height) of the ridges\n    rel_min_height = 0.01, # control the min height of the ridges\n    bandwidth = 3, # control the smoothness of the density estimate\n    fill = lighten(\"#EBCF89\", .6), # lighten the color \n    color = \"#D18A7D\") + # border color\n  scale_x_continuous(\n    name = \"English Grades\",\n    expand = c(0,0)) + #remove spaces before and after the data range\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.5,1)) # add more spaces before 3A and after 3I\n  )+\n  theme_ridges()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThe density plot of English grades by class, reveals the clear differences in grade distributions: Classes 3A and 3B show similar grade ranges, also do classes 3C and 3D, and 3E~3G, while class 3F notably contains few outliers with lower grades around 25.\n\n\nThe ggridges package offers enhanced versions of geom_density_ridges2 and geom_ridgeline2. These versions improve compatibility with different data structures and eliminate the need to manually adjust ridge heights using parameters like scale or rel_min_height.\nHowever, in the patchwork below, under the default setting, the only noticeabke difference is the border displayed under each class’s density plot:\n\n\n\nDisplay Code\n\na &lt;- ggplot(exam, aes(x = ENGLISH, y=CLASS))+\n  geom_density_ridges2()+\n  ggtitle(\"geom_density_ridges2\")+\n  theme_ridges()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\nb &lt;- ggplot(exam, aes(x = ENGLISH, y=CLASS))+\n  geom_density_ridges()+\n  ggtitle(\"geom_density_ridges\")+\n  theme_ridges()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\na+b\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Varying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\nWe use the argument scale_fill_viridis_c() to apply color scaling, where “c” represents continuous data. The palette is also available for binned data (scale_fill_viridis_b()) and discrete data (scale_fill_viridis_d()).\nBelow are the argument we used to adjust the scale_fill_viridis_c():\n\n\n\nArgument\nDiscription\n\n\n\n\nname\nThe name of the scale. Used as the axis or legend title\n\n\nalpha\nThe alpha transparency, a number in [0,1], see argument alpha in hsv.\n\n\ndirection\nSets the order of colors in the scale. If 1, the default, colors are ordered from darkest to lightest. If -1, the order of colors is reversed.\n\n\noption\nA character string indicating the color map option to use. Eight options are available:\n\n\"magma\" (or \"A\")\n\"inferno\" (or \"B\")\n\"plasma\" (or \"C\")\n\"viridis\" (or \"D\")\n\"cividis\" (or \"E\")\n\"rocket\" (or \"F\")\n\"mako\" (or \"G\")\n\"turbo\" (or \"H\")\n\n\n\n\n\n\n\nDisplay Code\n\nggplot(exam, aes(x=ENGLISH, y=CLASS,\n                 fill = stat(x)))+\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01)+\n  scale_fill_viridis_c(name = NULL,\n                       option = \"C\",\n                       alpha=1)+ \n  scale_x_continuous(name = \"English Grades\", expand = c(0,0))+\n  scale_y_discrete(name=NULL)+\n  theme_ridges()+\n  labs(title = 'Gradient Colors for English Scores') +\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3 Mapping the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\n\n\nDisplay Code\n\nggplot(exam, aes(x=ENGLISH, y=CLASS,\n                 fill = 0.5 - abs(0.5-stat(ecdf))))+\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE)+\n    scale_fill_viridis_c(name = \"Tail probability\",\n                         option = \"F\",\n                       direction = -1)+\n    theme_ridges()+\n  labs(title = 'Distribution of English Scores Across Classes') +\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\n\n\nDisplay Code\n\nggplot(exam, aes(x=ENGLISH, y=CLASS,\n                 fill = factor(stat(quantile))))+\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE,\n                      quantiles = 4,\n                      quantile_lines = TRUE)+\n    scale_fill_viridis_d(name = \"Qunatile\",\n                         option = \"D\")+\n    theme_ridges()+\n  labs(title = 'Distribution of English Scores Across Classes') +\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nBy filling with quantile colors, we can now clearly compare grades across classes. While classes 3D and 3E have similar overall grade ranges and distributions in their top 50%, class 3D shows a higher proportion of students with lower grades in Quantile 1.\n\n\nInstead of using number to define the quartiles, we can also specify quartiles by cut points such as 10% and 90% tails to colour the ridgeline plot as shown in the figure below:\n\n\n\nDisplay Code\n\nggplot(exam, aes(x=ENGLISH, y=CLASS,\n                 fill = factor(stat(quantile))))+\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE,\n                      quantiles = c(0.025,0.975))+\n    scale_fill_manual(name = \"Probability\",\n                         values = c())+\n    theme_ridges()+\n  labs(title = 'Quantile Distribution of English Grades') +\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nIf we only care about comparing the difference of top 10% and bottom 10% of students’ performance, setting the quantiles c(0.1,0.9) would make it easier for readers to understand the performance differences across classes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 04.a",
    "section": "4 Visualising Distribution with Raincloud Plot",
    "text": "4 Visualising Distribution with Raincloud Plot\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modes. The boxplot does not show where densities are clustered, but the raincloud plot does.\n\n4.1 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\nDisplay Code\n\nggplot(exam, \n       aes(x = RACE,y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)+\n  labs(title =\"Distribution of English Scores Across Races\",\n       x = \"\", y=\"English Score\")+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\n\n\nDisplay Code\n\nggplot(exam, \n       aes(x = RACE,y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)+\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA)+\n  labs(title =\"Distribution of English Scores Across Races\",\n       x = \"\", y=\"English Score\")+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nDensity cloud: stat_halfeye() provides the overall probability distribution of observations\nDots plot: stat_dots() provides details on numbers of observations\nBox plot: geom_boxplot() provides statistic information of observations\n\n\n\n\nDisplay Code\n\nggplot(exam, \n       aes(x = RACE,y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)+\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA)+\n  stat_dots(side = \"left\",\n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2\n            )+\n  labs(title =\"Distribution of English Scores Across Races\",\n       x = \"\", y=\"English Score\")+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThis graph contains a lot of information, including numbers of student and distribution, outliers, range and quartiles of English scores across races:\n\nNumbers of student: Chinese &gt; Malay &gt;&gt; Indian &gt; Others\nMedian of English scores: Chinese &gt; Others &gt; Malay &gt; Indian\nIQR of English scores: Indian &gt; Malay &gt; Chinese &gt; Others\nNumbers of Outliers (lower scores): Chinese &gt; Others &gt; Malay = Indian\n\nIn conclusion, both Chinese students and those in the “Others” category perform well in English, with mean scores around 70. The Chinese group shows more extreme performance variation, with notable numbers of students having scores below 40. Meanwhile, the “Others” group shows a more normal distribution with few outliers, suggesting consistently strong English performance across the group.\n\n\n\n\n4.4 Finishing the touching\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. Also, we add aes(fill = RACE) in stat_halfeye() function to highlight different races:\n\n\n\nDisplay Code\n\nggplot(exam, \n       aes(x = RACE,y = ENGLISH)) +\n  stat_halfeye(aes(fill = RACE),\n               alpha = 0.5,\n               adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)+\n  geom_boxplot(width = 0.20,\n               outlier.shape = NA)+\n  stat_dots(\n            side = \"left\",\n            justification = 1.2, \n            binwidth = NA,\n            dotsize = 2\n            )+\n  labs(title =\"Distribution of English Scores Across Races\",\n       x = \"\", y=\"English Score\")+\n  coord_flip() +\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.position = 'none',\n        plot.title = element_text(face = \"bold\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#reference",
    "title": "Hands-on Exercise 04.a",
    "section": "5 Reference",
    "text": "5 Reference\n\nKam, T.S. (2025). Visualising Distribution.\nIntroducing Ridgeline Plots (formerly Joyplots)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html",
    "title": "Hands-on Exercise 04.b",
    "section": "",
    "text": "In this exercise, we will gain hands-on expirience on using:\n\nggstatsplot package to create visual graphics with rich statistical information\nperformance package to visualise model diagnostics\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#learning-outcome",
    "title": "Hands-on Exercise 04.b",
    "section": "",
    "text": "In this exercise, we will gain hands-on expirience on using:\n\nggstatsplot package to create visual graphics with rich statistical information\nperformance package to visualise model diagnostics\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#getting-started",
    "title": "Hands-on Exercise 04.b",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImporting the dataExamining the dataTransforming the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(ggstatsplot, tidyverse, nortest)\n\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nggstatsplot\na ggplot2 extension for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\ntidyverse\na family of R packages for data processing\n\n\nnortest\na package for normality test\n\n\n\n\n\nIn this exercise, Exam_data.csv will be used. We use read_csv() of readr to import the data:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 7 attributes and 322 observations with no missing values.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\n\nstr(exam)\n\nspc_tbl_ [322 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ID     : chr [1:322] \"Student321\" \"Student305\" \"Student289\" \"Student227\" ...\n $ CLASS  : chr [1:322] \"3I\" \"3I\" \"3H\" \"3F\" ...\n $ GENDER : chr [1:322] \"Male\" \"Female\" \"Male\" \"Male\" ...\n $ RACE   : chr [1:322] \"Malay\" \"Malay\" \"Chinese\" \"Chinese\" ...\n $ ENGLISH: num [1:322] 21 24 26 27 27 31 31 31 33 34 ...\n $ MATHS  : num [1:322] 9 22 16 77 11 16 21 18 19 49 ...\n $ SCIENCE: num [1:322] 15 16 16 31 25 16 25 27 15 37 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ID = col_character(),\n  ..   CLASS = col_character(),\n  ..   GENDER = col_character(),\n  ..   RACE = col_character(),\n  ..   ENGLISH = col_double(),\n  ..   MATHS = col_double(),\n  ..   SCIENCE = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(exam)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\nany(is.na(exam))\n\n[1] FALSE\n\n\n\n\nIn R, factors are used to handle categorical data and ordered variable. As there are categorical attributes in our dataset, we are going to convert their data type from &lt;chr&gt; to &lt;fctr&gt;:\n\ncol &lt;- c(\"CLASS\",\"GENDER\",\"RACE\")\nexam &lt;- exam %&gt;% mutate(across(all_of(col), as.factor))\n\nAfter converting the attributes, let’s check the data again:\n\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#statistics-test-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#statistics-test-ggstatsplot",
    "title": "Hands-on Exercise 04.b",
    "section": "3 Statistics Test: ggstatsplot",
    "text": "3 Statistics Test: ggstatsplot\n\n3.1 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() of ggstatsplot is used to to build an visual of one-sample test on English scores.\n\nOne-sample test is a statistical test used to determine whether the mean of a single sample is significantly different from a known or hypothesized population mean (mu=60).\n\n\nBF-plotArgument\n\n\n\nHypothesis\nH0: Mean of English score = 60\nH1: Mean of English score != 60\n\n\nConclusion\nSince BF = e^-31.52, which is a tiny number close to 0. We have significant evidence to reject the null hypothesis and conclude that the mean English score doesn’t equal to 60.\n\n\n\nDisplay Code\n\nset.seed(1)\n\ngghistostats(exam,\n             x = ENGLISH,\n             type = \"bayes\",\n             test.value = 60, #mu\n             xlab = \"English scores\",\n             bin.args = list(fill = \"grey90\", color=\"grey30\"),\n             centrality.line.args = list(color = \"black\", linewidth = 1, linetype = \"dashed\"))+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngghistostats() includes below arguments:\n\n\n\nArgument\nDescription\n\n\n\n\nbinwidth\nThe width of the histogram bins. The default is to use the max(x) - min(x) / sqrt(N)\n\n\ntype\nA character specifying the type of statistical approach and its hypothesis testing:\n\n\"parametric\": One-sample Student’s t-test (stats::t.test())\n\"nonparametric\": One-sample Wilcoxon test (stats::wilcox.test())\n\"robust\": Bootstrap-t method for one-sample test(WRS2::trimcibt())\n\"bayes\": One-sample Student’s t-test (BayesFactor::ttestBF())\n\n\n\ntest.value\nA number indicating the true value of the mean (Default: 0).\n\n\nbin.args\nA list of additional aesthetic arguments to be passed to the stat_bin used to display the bins.\n\n\ncentrality.line.args\nA list of additional aesthetic arguments to be passed to the ggplot2::geom_line() used to display the lines corresponding to the centrality parameter.\n\n\n\n\n\n\n\n3.1.1 Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\nBayes Factor can be any positive number:\nOne of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\n\nHowever, before one-sample testing, we should use Anderson-Darling normality test to check if English scores follow normal distribution:\nHypothesis\nH0: English scores follow the normal distribution\nH1: English scores don’t follow the normal distribution\nalpha = 0.05\n\nad.test(exam$ENGLISH)\n\n\n    Anderson-Darling normality test\n\ndata:  exam$ENGLISH\nA = 4.3661, p-value = 7.341e-11\n\n\nResults from the Anderson-Darling normality test shows siginificant evidence (p-value &lt;0.05) to reject the null hypothesis and conclude that the English scores do not follow normal distribution . Thus non parametric: One-sample Wilcoxon test is used in the following one-sample test model.\nHypothesis:\nH0: Mean of English score = 60\nH1: Mean of English score != 60\nAlpha = 0.05\n\n\n\n\n\n\nConclusion\n\n\n\nWe reach the same conclusion using both approaches:\nSince the p-value &lt; 0.05, we have significant evidence to reject the null hypothesis and suggests that the mean English score is different from 60.\n\n\n\n\n\nDisplay Code\n\nset.seed(1)\n\ngghistostats(exam,\n             x = ENGLISH,\n             type = \"np\",\n             test.value = 60, #mu\n             xlab = \"English scores\",\n             bin.args = list(fill = \"grey90\", color=\"grey30\"),\n             centrality.line.args = list(color = \"black\", linewidth = 1, linetype = \"dashed\"))+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Two-sample mean test: ggbetweenstats() method\nggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender:\nBefore testing, we use Shapiro-Wilk normality test to check if math scores for both genders follow normal distribution:\nHypothesis\nH0: Math scores for male / female follow the normal distribution\nH1: Math scores for male / female don’t follow the normal distribution\nalpha = 0.05\n\nby(exam$MATHS, exam$GENDER, shapiro.test)\n\nexam$GENDER: Female\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.92752, p-value = 1.604e-07\n\n------------------------------------------------------------ \nexam$GENDER: Male\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.91268, p-value = 6.269e-08\n\n\nResults from Shapiro-Wilk test shows significant evidence (p-value &lt;0.05) to reject the null hypothesis and conclude that the math scores for both gender do not follow normal distribution . Thus non-parametric: Mann-Whitney U test is used in the following two-sample test model.\n\nnon-parametric test use “median” value as parameter, while parametric test use “mean” value as parameter.\n\n\nTwo Sample plotArgument\n\n\n\nHypothesis\nH0: Mean math score for male = Mean math score for female\nH1: Mean math score for male != Mean math score for female\nalpha = 0.05\n\n\n\n\n\n\nConclusion\n\n\n\nSince the p-value is &gt; 0.05, we don’t have enough evidence to reject the null hypothesis and conclude that there is no statistically significant difference in the mean math scores between males and females.\n\n\n\n\n\nDisplay Code\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\", #nonparametric\n  messages = FALSE)+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats() includes below arguments:\n\n\n\nArgument\nDescription\n\n\n\n\ntype\nA character specifying the type of statistical approach and its hypothesis testing:\nNo. of groups:\n\n\"parametric\": Student’s or Welch’s t-test(stats::t.test())\n\"nonparametric\": Mann-Whitney U test(stats::wilcox.test())\n\"robust\": Yuen’s test for trimmed means(WRS2::yuen())\n\"bayes\": Student’s t-test (BayesFactor::ttestBF())\n\nNo. of groups &gt; 2:\n\n\"parametric\" or \"p\": Fisher’s or Welch’s one-way ANOVA (stats::oneway.test())\n\"nonparametric\" or \"np\": Kruskal-Wallis one-way ANOVA (stats::kruskal.test())\n\"robust\" or \"r\": Heteroscedastic one-way ANOVA for trimmed means (WRS2::t1way()) &gt;&gt; remove all the outliers globally.\n\"bayes\": Fisher’s ANOVA (BayesFactor::anovaBF())\n\n\n\npairwise.display\n(ANOVA)\nDecides which pairwise comparisons to display. Available options are:\n\n\"significant\" (abbreviation accepted: \"s\") &gt;&gt;&gt; display only significant\n\"non-significant\" (abbreviation accepted: \"ns\") &gt;&gt;&gt; display only non-significant\n\"all\"&gt;&gt;&gt; display everything\nIf set to \"none\", no pairwise comparisons will be displayed.\n\n\n\nbf.message\nIt decides whether to display Bayes Factor in favor of the null hypothesis. This argument is relevant only for parametric test (Default: TRUE).\n\n\nvar.equal\nwhether to treat the two variances as being equal. If TRUE then the pooled variance is used to estimate the variance otherwise the Welch (or Satterthwaite) approximation to the degrees of freedom is used.\n\n\ncentrality.point.args, centrality.label.args\nA list of additional aesthetic arguments to be passed to ggplot2::geom_point() andggrepel::geom_label_repel() geoms, which are involved in mean plotting.\n\n\npoint.args\nA list of additional aesthetic arguments to be passed to the ggplot2::geom_point().\n\n\nboxplot.args\nA list of additional aesthetic arguments passed on to ggplot2::geom_boxplot().\n\n\nviolin.args\nA list of additional aesthetic arguments to be passed to the ggplot2::geom_violin().\n\n\nggsignif.args\nA list of additional aesthetic arguments to be passed to ggsignif::geom_signif().\n\n\n\n\n\n\n\n\n3.3 Oneway ANOVA Test: ggbetweenstats() method\nggbetweenstats() can also be used to build a visual for One-way ANOVA test on English score by race.\nBefore testing, we use Shapiro-Wilk normality test to check if math scores for both genders follow normal distribution:\nHypothesis\nH0: English scores for races follow the normal distribution\nH1: English scores for races don’t follow the normal distribution\nalpha = 0.05\n\nby(exam$ENGLISH, exam$RACE, shapiro.test)\n\nexam$RACE: Chinese\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.93491, p-value = 1.305e-07\n\n------------------------------------------------------------ \nexam$RACE: Indian\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.9647, p-value = 0.8483\n\n------------------------------------------------------------ \nexam$RACE: Malay\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.96894, p-value = 0.01251\n\n------------------------------------------------------------ \nexam$RACE: Others\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.93378, p-value = 0.5182\n\n\nResults from Shapiro-Wilk test doesn’t show significant evidence (p-value &gt;0.05) for all races and fail to reject the null hypothesis. Thus parametric test is used in the following onw-way ANOVA model.\n\nHypothesis\nH0: There is no difference in English scores among races.\nH1: There are differences in English scores among races.\nalpha = 0.05\n\n\n\n\n\n\nConclusion\n\n\n\nSince p-value &lt; 0.05, we have enough evidence to reject the null hypothesis and conclude that there are differences in English scores among races.\nThe pairwise test ggbetweenstats() below further shows that the means of English scores of Chinese, Indian and Malay are significantly different.\n\n\n\n\n\nDisplay Code\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\", # parametric\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\", # display only significant one\n  p.adjust.method = \"fdr\", # False Discovery Rate\n  messages = FALSE\n)+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\n\n\n\n\n\nConclusion\n\n\n\nThe result indicates a statistically significant posistive relationship (r = 0.83, p-value &lt;0.05) between English and math scores. This suggests that higher English scores are correlated with higher math scores.\n\n\n\nggscatterstats(data = exam,\n               x = MATHS,\n               y = ENGLISH,\n               marginal = FALSE,)+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n3.5 Significant Test of Association (Depedence): ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;%\n  mutate(MATHS_bins=\n           cut(MATHS, breaks = c(0,60,75,85,100)))\n\n\n(0,60] means excluding 0 and including 60.\n\n\nhead(exam1)\n\n# A tibble: 6 × 8\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE MATHS_bins\n  &lt;chr&gt;      &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;     \n1 Student321 3I    Male   Malay        21     9      15 (0,60]    \n2 Student305 3I    Female Malay        24    22      16 (0,60]    \n3 Student289 3H    Male   Chinese      26    16      16 (0,60]    \n4 Student227 3F    Male   Chinese      27    77      31 (75,85]   \n5 Student318 3I    Male   Malay        27    11      25 (0,60]    \n6 Student306 3I    Female Malay        31    16      16 (0,60]    \n\n\nSince ggplot2 doesn’t provide mosaic plot, we can use ggbarstats() to create stacked bar chart to simulate it.\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\nHypothesis\nH0: There is no association between math_bin and gender.\nH1: There is an association between math_bin and gender.\nAlpha = 0.05\n\n\n\n\n\n\nConclusion\n\n\n\nSince the p-value is &gt; 0.05, we don’t have enough evidence to reject the null hypothesis that there is no association between the math_bin and gender variables.\n\n\n\nggbarstats(exam1,\n           x = MATHS_bins,\n           y = GENDER)+\n  theme(legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA\n                                       ))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#visualizing-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#visualizing-models",
    "title": "Hands-on Exercise 04.b",
    "section": "4 Visualizing Models",
    "text": "4 Visualizing Models\nIn this section, Toyota Corolla case study will be used. We will learn how to visualize model diagnostic and model parameters by using parameters package.\n\n4.1 Getting Started\n\nInstalling and loading the packagesImporting the dataExamining the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(readxl, performance, parameters, see, qqplotr)\n\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nperformance\nThis package provides tools to evaluate and check the performance of regression models\n\n\nparameters\nThis package is used to extract and interpret parameters from regression models, e.g., coefficients, standard errors, p-values in an easy-to-interpret format\n\n\nsee & qqplotr\nThe see package is designed for visualizing the results of statistical models and model diagnostics. qqplotr(): Plots a QQ plot of the residuals to check for normality.\n\n\n\n\n\nIn this exercise, Exam_data.csv will be used. We use read_csv() of readr to import the data:\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\"data\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 38 attributes and 1,436 observations with no missing values.\n\nhead(car_resale)\n\n# A tibble: 6 × 38\n     Id Model      Price Age_08_04 Mfg_Month Mfg_Year    KM Quarterly_Tax Weight\n  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1    81 TOYOTA Co… 18950        25         8     2002 20019           100   1180\n2     1 TOYOTA Co… 13500        23        10     2002 46986           210   1165\n3     2 TOYOTA Co… 13750        23        10     2002 72937           210   1165\n4     3  TOYOTA C… 13950        24         9     2002 41711           210   1165\n5     4 TOYOTA Co… 14950        26         7     2002 48000           210   1165\n6     5 TOYOTA Co… 13750        30         3     2002 38500           210   1170\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;,\n#   Radio &lt;dbl&gt;, Mistlamps &lt;dbl&gt;, Sport_Model &lt;dbl&gt;, Backseat_Divider &lt;dbl&gt;, …\n\n\n\nstr(car_resale)\n\ntibble [1,436 × 38] (S3: tbl_df/tbl/data.frame)\n $ Id              : num [1:1436] 81 1 2 3 4 5 6 7 8 44 ...\n $ Model           : chr [1:1436] \"TOYOTA Corolla 1.6 5drs 1 4/5-Doors\" \"TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\" \"TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\" \" TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\" ...\n $ Price           : num [1:1436] 18950 13500 13750 13950 14950 ...\n $ Age_08_04       : num [1:1436] 25 23 23 24 26 30 32 27 30 27 ...\n $ Mfg_Month       : num [1:1436] 8 10 10 9 7 3 1 6 3 6 ...\n $ Mfg_Year        : num [1:1436] 2002 2002 2002 2002 2002 ...\n $ KM              : num [1:1436] 20019 46986 72937 41711 48000 ...\n $ Quarterly_Tax   : num [1:1436] 100 210 210 210 210 210 210 210 210 234 ...\n $ Weight          : num [1:1436] 1180 1165 1165 1165 1165 ...\n $ Guarantee_Period: num [1:1436] 3 3 3 3 3 3 3 3 3 3 ...\n $ HP_Bin          : chr [1:1436] \"100-120\" \"&lt; 100\" \"&lt; 100\" \"&lt; 100\" ...\n $ CC_bin          : chr [1:1436] \"1600\" \"&gt;1600\" \"&gt;1600\" \"&gt;1600\" ...\n $ Doors           : num [1:1436] 5 3 3 3 3 3 3 3 3 5 ...\n $ Gears           : num [1:1436] 5 5 5 5 5 5 5 5 5 5 ...\n $ Cylinders       : num [1:1436] 4 4 4 4 4 4 4 4 4 4 ...\n $ Fuel_Type       : chr [1:1436] \"Petrol\" \"Diesel\" \"Diesel\" \"Diesel\" ...\n $ Color           : chr [1:1436] \"Blue\" \"Blue\" \"Silver\" \"Blue\" ...\n $ Met_Color       : num [1:1436] 1 1 1 1 0 0 0 1 1 0 ...\n $ Automatic       : num [1:1436] 1 0 0 0 0 0 0 0 0 0 ...\n $ Mfr_Guarantee   : num [1:1436] 0 0 0 1 1 1 0 0 1 1 ...\n $ BOVAG_Guarantee : num [1:1436] 0 1 1 1 1 1 1 1 1 1 ...\n $ ABS             : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Airbag_1        : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Airbag_2        : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Airco           : num [1:1436] 1 0 1 0 0 1 1 1 1 1 ...\n $ Automatic_airco : num [1:1436] 1 0 0 0 0 0 0 0 0 0 ...\n $ Boardcomputer   : num [1:1436] 0 1 1 1 1 1 1 1 1 1 ...\n $ CD_Player       : num [1:1436] 1 0 1 0 0 0 0 0 1 0 ...\n $ Central_Lock    : num [1:1436] 1 1 1 0 0 1 1 1 1 1 ...\n $ Powered_Windows : num [1:1436] 1 1 0 0 0 1 1 1 1 1 ...\n $ Power_Steering  : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Radio           : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n $ Mistlamps       : num [1:1436] 0 0 0 0 0 1 1 0 0 0 ...\n $ Sport_Model     : num [1:1436] 0 0 0 0 0 0 0 1 0 1 ...\n $ Backseat_Divider: num [1:1436] 0 1 1 1 1 1 1 1 1 1 ...\n $ Metallic_Rim    : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n $ Radio_cassette  : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n $ Tow_Bar         : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n\n\n\nany(is.na(car_resale))\n\n[1] FALSE\n\n\n\n\n\n\n\n4.2 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period,\n            data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n4.3 Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\nlibrary(ggplot2)\n\ncheck_c &lt;-check_collinearity(model)\n\nggplot(check_c, aes(x = Term, y = VIF)) +\n  geom_col() +\n  coord_flip() +\n  theme_minimal()+\n    theme(legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA\n                                       ))\n\n\n\n\n\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c) # showing error\n\nThe plots above show high collinearity between Age and Mfg_Year. We should remove one of them.\n\n\n4.4 Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\ncheck_n\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\nplot(check_n,type=\"qq\")+\n    theme(legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA\n                                       ))\n\n\n\n\n\n\n\n\nThe QQ-plot above shows the regression model does not follow a normal distribution. The data may have skewness, outliers or heteroscedasticity.\n\n\n4.5 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\ncheck_h\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\n\nplot(check_h)+\n    theme(legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA\n                                       ))\n\n\n\n\n\n\n\n\nThe plot and the check_heteroscedasticity(model1) result show the model having heteroscedasticity issue. It is possible the model is misspecified, such as not capturing the true relationship between the dependent and independent variables.\n\n\n4.6 Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n4.7 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package are used to visualise the parameters of a regression model.\n\nplot(parameters(model1))+\n    theme(legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA\n                                       ))\n\n\n\n\n\n\n\n\n\n\n4.8 Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_b.html#reference",
    "title": "Hands-on Exercise 04.b",
    "section": "5 Reference",
    "text": "5 Reference\n\nKam, T.S. (2025). Visual Statistical Analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html",
    "title": "Hands-on Exercise 04.c",
    "section": "",
    "text": "In this exercise, we will gain hands-on experience on creating statistical graphics for visualising uncertainty. The learning objectives are:\n\nplot statistics error bars by using ggplot2\nplot interactive error bars by combining ggplot2, plotly and DT\ncreate advanced and more appealing plot by using ggdist\ncreate hypothetical outcome plots (HOPs) by using ungeviz package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#learning-outcome",
    "title": "Hands-on Exercise 04.c",
    "section": "",
    "text": "In this exercise, we will gain hands-on experience on creating statistical graphics for visualising uncertainty. The learning objectives are:\n\nplot statistics error bars by using ggplot2\nplot interactive error bars by combining ggplot2, plotly and DT\ncreate advanced and more appealing plot by using ggdist\ncreate hypothetical outcome plots (HOPs) by using ungeviz package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#getting-started",
    "title": "Hands-on Exercise 04.c",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImporting the dataExamining the dataTransforming the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(plotly, crosstalk, DT, gganimate,\n               ggdist, tidyverse, ggthemes)\n\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nggdist\na ggplot2 extension spacially desgin for visualising distribution and uncertainty\n\n\ntidyverse\na family of R packages for data processing\n\n\ncrosstalk\nfor implementing cross-widget interactions (currently, linked brushing and filtering)\n\n\n\n\n\nIn this exercise, Exam_data.csv will be used. We use read_csv() of readr to import the data:\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 7 attributes and 322 observations with no missing values.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\n\nstr(exam)\n\nspc_tbl_ [322 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ID     : chr [1:322] \"Student321\" \"Student305\" \"Student289\" \"Student227\" ...\n $ CLASS  : chr [1:322] \"3I\" \"3I\" \"3H\" \"3F\" ...\n $ GENDER : chr [1:322] \"Male\" \"Female\" \"Male\" \"Male\" ...\n $ RACE   : chr [1:322] \"Malay\" \"Malay\" \"Chinese\" \"Chinese\" ...\n $ ENGLISH: num [1:322] 21 24 26 27 27 31 31 31 33 34 ...\n $ MATHS  : num [1:322] 9 22 16 77 11 16 21 18 19 49 ...\n $ SCIENCE: num [1:322] 15 16 16 31 25 16 25 27 15 37 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ID = col_character(),\n  ..   CLASS = col_character(),\n  ..   GENDER = col_character(),\n  ..   RACE = col_character(),\n  ..   ENGLISH = col_double(),\n  ..   MATHS = col_double(),\n  ..   SCIENCE = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(exam)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\nany(is.na(exam))\n\n[1] FALSE\n\n\n\n\nIn R, factors are used to handle categorical data and ordered variable. As there are categorical attributes in our dataset, we are going to convert their data type from &lt;chr&gt; to &lt;fctr&gt;:\n\ncol &lt;- c(\"CLASS\",\"GENDER\",\"RACE\")\nexam &lt;- exam %&gt;% mutate(across(all_of(col), as.factor))\n\nAfter converting the attributes, let’s check the data again:\n\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 04.c",
    "section": "3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "3 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;% # group the observation by RACE\n  summarise(n=n(), #sample size \n            mean = mean(MATHS),\n            sd = sd(MATHS)) %&gt;%\n  mutate(se=sd/sqrt(n-1)) #calculate standard error of the sample mean\n\nmy_sum\n\n# A tibble: 4 × 5\n  RACE        n  mean    sd    se\n  &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Chinese   193  76.5  15.7  1.13\n2 Indian     12  60.7  23.4  7.04\n3 Malay     108  57.4  21.1  2.04\n4 Others      9  69.7  10.7  3.79\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format by using kable() function in knitr.\n\nknitr::kable(head(my_sum),format = \"html\")\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nstat = 'identity' in the geom_point() means that don’t apply any statistics, just plot ‘mean’ values.\nThe error bars are computed by using the formula mean+/-se.\n\n\n\n\nDisplay Code\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE,\n        ymin = mean-se,\n        ymax = mean+se),\n    width = 0.2,\n    colour = \"black\",\n    alpha = 0.9,\n    linewidth =0.5)+\n  geom_point(aes(x=RACE,y=mean),\n             stat = 'identity', \n             color = \"#D9A4C3\",\n             size = 1.5, alpha=1)+\n  labs(title = \"Standard Error of Mean Math Score by Race\",\n       subtitle = \"68% Confidence Interval\",\n       y=\"Mean math score\")+\n  theme_wsj(base_size = 9)+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(hjust=0, face=\"bold\", size = 18),\n        plot.subtitle = element_text(hjust=0, size = 14),\n        axis.title.y = element_text(size = 10),\n        axis.line.x = element_line(linewidth = 0.3),\n        axis.line.y = element_line(linewidth = 0.3)\n        )\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se\nThe reorder(RACE, -mean) function reorders the RACE factor so that the groups with the highest means appear first on the x-axis.\n\n\n\n\nDisplay Code\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean),\n        ymin = mean-1.96*se,\n        ymax = mean+1.96*se),\n    width = 0.2,\n    colour = \"black\",\n    alpha = 0.9,\n    linewidth =0.5)+\n  geom_point(aes(x=RACE,y=mean),\n             stat = 'identity', \n             color = \"#D9A4C3\",\n             size = 1.5, alpha=1)+\n  labs(title = \"Standard Error of Mean Math Score by Race\",\n       subtitle = \"95% Confidence Interval\",\n       y=\"Mean math score\")+\n  theme_wsj(base_size = 9)+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(hjust=0, face=\"bold\", size = 18),\n        plot.subtitle = element_text(hjust=0, size = 14),\n        axis.title.y = element_text(size = 10),\n        axis.line.x = element_line(linewidth = 0.3),\n        axis.line.y = element_line(linewidth = 0.3)\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, we will plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nbscols(): This is used to create a layout where the plot occupies 4 columns (out of a 12-column grid) and the data table occupies 8 columns. This is typically used in Shiny apps or R Markdown documents to create a side-by-side layout.\n\n\n\n\nDisplay Code\n\nshared_df = SharedData$new(my_sum) #create new shared data frame\n\nbscols(\n  widths = c(4, 8),  # Set column widths for plot and table 4:8\n  ggplotly(\n    ggplot(shared_df) + \n      geom_errorbar(\n        aes(x = reorder(RACE, -mean),\n            ymin = mean - 2.58 * se,  \n            ymax = mean + 2.58 * se), \n        width = 0.2, \n        colour = \"black\",\n        alpha = 0.9,\n        linewidth = 0.5\n      ) +\n      geom_point(\n        aes(x = RACE, y = mean,\n            text = paste(\"RACE:\", RACE,\n                         \"&lt;br&gt;N:\", n,\n                         \"&lt;br&gt;Avg. Scores:\", round(mean, 2),\n                         \"&lt;br&gt;99% CI:[\", round((mean - 2.58 * se), 2), \",\",\n                         round((mean + 2.58 * se), 2), \"]\")),\n        stat = 'identity', \n        color = \"#D9A4C3\", \n        size = 1.5, \n        alpha = 1\n      ) +\n      labs(x=\"Race\",y=\"Average Scores\",\n           title = \"99% Confidence interval of average /&lt;br&gt;maths scores by race\")+\n      theme_wsj(base_size = 9) + \n      theme(\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n        plot.title = element_text(hjust = 0, face = \"bold\", size = 11.5),\n        axis.title.y = element_text(size = 10),\n        axis.title.x = element_text(size = 10),\n        axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1),\n        tooltip = \"text\"\n      )\n  ), \n  DT::datatable(\n    shared_df,\n    rownames = FALSE,\n    class = \"compact\",\n    width = \"100%\",\n    options = list(pageLength = 10, scrollX = TRUE),\n    colnames = c(\"No. of pupils\", \"Avg Scores\", \"Std Dev\", \"Std Error\")\n  ) %&gt;%\n    formatRound(columns = c('mean', 'sd', 'se'), digits = 2)\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 04.c",
    "section": "4 Visualising Uncertainty: ggdist package",
    "text": "4 Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nFrequentist models: Visualizing confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nBayesian models: Visualizing probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race:\n\n\n\nDisplay Code\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  aes(interval_color=stat(level)) +\n  scale_color_manual(\n    values = c(\"grey20\", \"grey50\"), # customize colors for 95% and 99% CI\n    aesthetics = \"interval_color\") +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot of 66% and 95%\")+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        plot.title = element_text(face = \"bold\"),\n        axis.line.x = element_line(linewidth = 0.3),\n        axis.line.y = element_line(linewidth = 0.3))\n\n\n\n\n\n\n\n\n\n\n\nBelow are some stat_pointinterval() argument\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n.width\na vector of probabilities to use that determine the widths of the resulting intervals. The default setting is .width = c(0.66, 0.95), meaning plotting 66% CI and 95% CI\n\n\n.point\nThis argument determines the point summary (typically mean, median, or mode)\n\n\n.interval\nIt decides the interval type (quantile interval, qi; highest-density interval, hdi; or highest-density continuous interval, hdci).\n\n\norientation\nWhether this geom is drawn horizontally or vertically: \"horizontal\" (or \"y\"), \"vertical\" (or \"x\"), NA\n\n\n\nWe are going to customize the arguments we learned above:\n\n\n\nDisplay Code\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n                     .point = median,\n                     .interval = qi,\n                     .orientation = \"na\") +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + 95% CI plot\")+\n    theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(face = \"bold\"),\n        axis.line.x = element_line(linewidth = 0.3),\n        axis.line.y = element_line(linewidth = 0.3))\n\n\n\n\n\n\n\n\n\n\n\nBelow is the multiple CI plot showing both 95% and 99% levels:\n\n\n\nDisplay Code\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = c(0.95,0.99),\n                     .point = mean,\n                     .interval = qi,\n                     .orientation = \"na\") +\n  aes(interval_color=stat(level)) +\n  scale_color_manual(\n    values = c(\"#6a994e\", \"#E8C8DB\"), # customize colors for 95% and 99% CI\n    aesthetics = \"interval_color\") +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple of interval plot of 95% and 99% levels\")+\n    theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(face = \"bold\"),\n        axis.line.x = element_line(linewidth = 0.3),\n        axis.line.y = element_line(linewidth = 0.3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\n\nDisplay Code\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS))+\n  stat_gradientinterval(   \n    fill = \"grey30\",      \n    show.legend = TRUE)+                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(face = \"bold\"),\n        legend.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        axis.line.x = element_line(linewidth = 0.3),\n        axis.line.y = element_line(linewidth = 0.3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\n\n4.3.1 Install and launch the ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\nlibrary(ungeviz)\n\n\n\n4.3.2 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nNext, the code chunk below will be used to build the HOPs.\n\n\n\nDisplay Code\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"grey40\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), \n              height = 0.6, \n              color = \"#D9A4C3\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)+\n  labs(x=\"Race\",y=\"Math Score\")+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        plot.title = element_text(face = \"bold\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_c.html#reference",
    "title": "Hands-on Exercise 04.c",
    "section": "5 Reference",
    "text": "5 Reference\n\nKam, T.S. (2025). Visualising Uncertainty."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html",
    "title": "Hands-on Exercise 04.d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. The learning objectives are:\n\nplotting funnel plots by using funnelPlotR package\nplotting static funnel plot by using ggplot2 package\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#learning-outcome",
    "title": "Hands-on Exercise 04.d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. The learning objectives are:\n\nplotting funnel plots by using funnelPlotR package\nplotting static funnel plot by using ggplot2 package\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#getting-started",
    "title": "Hands-on Exercise 04.d",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImporting the dataExamining the dataTransforming the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nLibrary\nDescription\n\n\n\n\nFunnelPlotR, ggplot2\ncreating funnel plot\n\n\nknitr\nbuilding static html table\n\n\nplotly\ncreating interactive funnel plot\n\n\n\n\n\nIn this exercise, COVID-19_DKI_Jakarta.csv will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. \nIn this exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 7 attributes and 267 observations with no missing values.\n\nhead(covid19)\n\n# A tibble: 6 × 7\n  `Sub-district ID` City        District `Sub-district` Positive Recovered Death\n              &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1        3172051003 JAKARTA UT… PADEMAN… ANCOL              1776      1691    26\n2        3173041007 JAKARTA BA… TAMBORA  ANGKE              1783      1720    29\n3        3175041005 JAKARTA TI… KRAMAT … BALE KAMBANG       2049      1964    31\n4        3175031003 JAKARTA TI… JATINEG… BALI MESTER         827       797    13\n5        3175101006 JAKARTA TI… CIPAYUNG BAMBU APUS         2866      2792    27\n6        3174031002 JAKARTA SE… MAMPANG… BANGKA             1828      1757    26\n\n\n\nstr(covid19)\n\nspc_tbl_ [267 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sub-district ID: num [1:267] 3.17e+09 3.17e+09 3.18e+09 3.18e+09 3.18e+09 ...\n $ City           : chr [1:267] \"JAKARTA UTARA\" \"JAKARTA BARAT\" \"JAKARTA TIMUR\" \"JAKARTA TIMUR\" ...\n $ District       : chr [1:267] \"PADEMANGAN\" \"TAMBORA\" \"KRAMAT JATI\" \"JATINEGARA\" ...\n $ Sub-district   : chr [1:267] \"ANCOL\" \"ANGKE\" \"BALE KAMBANG\" \"BALI MESTER\" ...\n $ Positive       : num [1:267] 1776 1783 2049 827 2866 ...\n $ Recovered      : num [1:267] 1691 1720 1964 797 2792 ...\n $ Death          : num [1:267] 26 29 31 13 27 26 37 68 38 52 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   `Sub-district ID` = col_double(),\n  ..   City = col_character(),\n  ..   District = col_character(),\n  ..   `Sub-district` = col_character(),\n  ..   Positive = col_double(),\n  ..   Recovered = col_double(),\n  ..   Death = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(covid19)\n\n Sub-district ID         City             District         Sub-district      \n Min.   :3.101e+09   Length:267         Length:267         Length:267        \n 1st Qu.:3.172e+09   Class :character   Class :character   Class :character  \n Median :3.173e+09   Mode  :character   Mode  :character   Mode  :character  \n Mean   :3.172e+09                                                           \n 3rd Qu.:3.174e+09                                                           \n Max.   :3.175e+09                                                           \n    Positive      Recovered        Death       \n Min.   :  72   Min.   :  69   Min.   :  0.00  \n 1st Qu.:1644   1st Qu.:1578   1st Qu.: 24.50  \n Median :2420   Median :2329   Median : 39.00  \n Mean   :2572   Mean   :2477   Mean   : 40.99  \n 3rd Qu.:3372   3rd Qu.:3242   3rd Qu.: 55.00  \n Max.   :6231   Max.   :5970   Max.   :158.00  \n\n\n\nany(is.na(covid19))\n\n[1] FALSE\n\n\n\n\nIn R, factors are used to handle categorical data and ordered variable. As there are categorical attributes in our dataset, we are going to convert their data type from &lt;chr&gt; to &lt;fctr&gt;:\n\n# convert all chr type into factor type\ncovid19 &lt;- covid19 %&gt;% mutate_if(is.character, as.factor)\n\nAfter converting the attributes, let’s check the data again:\n\nhead(covid19)\n\n# A tibble: 6 × 7\n  `Sub-district ID` City        District `Sub-district` Positive Recovered Death\n              &lt;dbl&gt; &lt;fct&gt;       &lt;fct&gt;    &lt;fct&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1        3172051003 JAKARTA UT… PADEMAN… ANCOL              1776      1691    26\n2        3173041007 JAKARTA BA… TAMBORA  ANGKE              1783      1720    29\n3        3175041005 JAKARTA TI… KRAMAT … BALE KAMBANG       2049      1964    31\n4        3175031003 JAKARTA TI… JATINEG… BALI MESTER         827       797    13\n5        3175101006 JAKARTA TI… CIPAYUNG BAMBU APUS         2866      2792    27\n6        3174031002 JAKARTA SE… MAMPANG… BANGKA             1828      1757    26"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#funnelplotr-methods",
    "title": "Hands-on Exercise 04.d",
    "section": "3 FunnelPlotR methods",
    "text": "3 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n3.1 FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n3.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05))\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThe plot above label 7 outliers.\nThings to learn from the code chunk above:\n\n data_type argument is used to change from default “SR” to “PR” (i.e. proportions).\n xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n3.3 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\", #proportion\n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA, #remove the label\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\",          \n  x_label = \"Cumulative COVID-19 Positive Cases\", \n  y_label = \"Cumulative Fatality Rate\"\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 04.d",
    "section": "4 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "4 Funnel Plot for Fair Visual Comparison: ggplot2 methods\n\n4.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n4.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n4.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12,face=\"bold\"),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\np\n\n\n\n\n\n\n\n\n\n\n4.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_d.html#reference",
    "title": "Hands-on Exercise 04.d",
    "section": "5 Reference",
    "text": "5 Reference\n\nKam, T.S. (2025). Funnel Plots for Fair Comparisons."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html",
    "title": "Hands-on Exercise 03.b",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to:\n\nCreate animated data visualisation by using gganimate and plotly r packages\nReshape data by using tidyverse package\nProcess, wrangle and transform data by using dplyr package\n\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#overview",
    "title": "Hands-on Exercise 03.b",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to:\n\nCreate animated data visualisation by using gganimate and plotly r packages\nReshape data by using tidyverse package\nProcess, wrangle and transform data by using dplyr package\n\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#getting-started",
    "title": "Hands-on Exercise 03.b",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Loading the R packages\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse, ggthemes, DT)\n\n\n\n4.2.2 Importing and Examing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWe first use read_xls of tidyverse package to import the document:\n\nglobalpop_raw &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") \n\nNext, we use function str() , head() from R, function summarise_all() and n_distinct() from dplyr to examine the data structure and variable types:\n\nThe dataset contains 6,204 observations with no missing values\n\n\n\nCountry: The dataset contains 222 countries stored as character data type\nYear: The data spans from 1996 to 1950 and stored as double data type\nYoung: Based on the data context, the “Young” variable represents the percentage of young people in the population with values ranging from 15.5% to 109.2%. It stored as double data type\nOld: Based on the data context, the “Old” variable represents the percentage of elderly people in the population with values ranging from 1% to 77.1% It stored as double data type\nPopulation: The values ranging from 3 K to 1,807,878.6 K within the data period\nContinent: The dataset contains 6 continenet stored as character data type\n\n\nstr(globalpop_raw)\n\ntibble [6,204 × 6] (S3: tbl_df/tbl/data.frame)\n $ Country   : chr [1:6204] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Year      : num [1:6204] 1996 1998 2000 2002 2004 ...\n $ Young     : num [1:6204] 83.6 84.1 84.6 85.1 84.5 84.3 84.1 83.7 82.9 82.1 ...\n $ Old       : num [1:6204] 4.5 4.5 4.5 4.5 4.5 4.6 4.6 4.6 4.6 4.7 ...\n $ Population: num [1:6204] 21560 22913 23898 25268 28514 ...\n $ Continent : chr [1:6204] \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n\n\n\nhead(globalpop_raw)\n\n# A tibble: 6 × 6\n  Country      Year Young   Old Population Continent\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    \n1 Afghanistan  1996  83.6   4.5     21560. Asia     \n2 Afghanistan  1998  84.1   4.5     22913. Asia     \n3 Afghanistan  2000  84.6   4.5     23898. Asia     \n4 Afghanistan  2002  85.1   4.5     25268. Asia     \n5 Afghanistan  2004  84.5   4.5     28514. Asia     \n6 Afghanistan  2006  84.3   4.6     31057  Asia     \n\n\n\nglobalpop_raw %&gt;%\n  summarise_all(~n_distinct(.))\n\n# A tibble: 1 × 6\n  Country  Year Young   Old Population Continent\n    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;int&gt;     &lt;int&gt;\n1     222    28   819   589       5791         6\n\n\n\n# check if there're any missing values\nany(is.na(globalpop_raw))\n\n[1] FALSE\n\n\n\nsummary(globalpop_raw)\n\n   Country               Year          Young             Old       \n Length:6204        Min.   :1996   Min.   : 15.50   Min.   : 1.00  \n Class :character   1st Qu.:2010   1st Qu.: 25.70   1st Qu.: 6.90  \n Mode  :character   Median :2024   Median : 34.30   Median :12.80  \n                    Mean   :2023   Mean   : 41.66   Mean   :17.93  \n                    3rd Qu.:2038   3rd Qu.: 53.60   3rd Qu.:25.90  \n                    Max.   :2050   Max.   :109.20   Max.   :77.10  \n   Population         Continent        \n Min.   :      3.3   Length:6204       \n 1st Qu.:    605.9   Class :character  \n Median :   5771.6   Mode  :character  \n Mean   :  34860.9                     \n 3rd Qu.:  22711.0                     \n Max.   :1807878.6                     \n\n\n\n\n4.2.3 Handling Data Issues\n\n\n4.2.3.1 Data Type Issues\n\nYear: Since year is a whole number rather than a decimal, we should transform its data type from double &lt;dbl&gt; to integer&lt;int&gt;.\nCountry and Continent: Since these two categorical variables will be analyzed further, we need to transform their data type from character &lt;chr&gt; to factor&lt;fctr&gt;. In R, factors are used to handle categorical data and ordered variable.\n\nHere, we use mutate_each_() of dplyr package to convert all character data type into factor, and use mutate of dplyr package to convert data values of Year field into integer.\n\ncol &lt;- c(\"Country\",\"Continent\")\n\nglobalpop_raw &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)),col) %&gt;%\n  mutate(Year = as.integer(Year))\n  \nhead(globalpop_raw)\n\n# A tibble: 6 × 6\n  Country      Year Young   Old Population Continent\n  &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;fct&gt;    \n1 Afghanistan  1996  83.6   4.5     21560. Asia     \n2 Afghanistan  1998  84.1   4.5     22913. Asia     \n3 Afghanistan  2000  84.6   4.5     23898. Asia     \n4 Afghanistan  2002  85.1   4.5     25268. Asia     \n5 Afghanistan  2004  84.5   4.5     28514. Asia     \n6 Afghanistan  2006  84.3   4.6     31057  Asia     \n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\",\"Continent\")\n\nglobalpop_raw &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n  \nhead(globalpop_raw)\n\n# A tibble: 6 × 6\n  Country      Year Young   Old Population Continent\n  &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;fct&gt;    \n1 Afghanistan  1996  83.6   4.5     21560. Asia     \n2 Afghanistan  1998  84.1   4.5     22913. Asia     \n3 Afghanistan  2000  84.6   4.5     23898. Asia     \n4 Afghanistan  2002  85.1   4.5     25268. Asia     \n5 Afghanistan  2004  84.5   4.5     28514. Asia     \n6 Afghanistan  2006  84.3   4.6     31057  Asia     \n\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\",\"Continent\")\n\nglobalpop_raw &lt;- read_xls(\"data/GlobalPopulation.xls\",sheet=\"Data\") %&gt;%\n  mutate(across(all_of(col), as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\nhead(globalpop_raw)\n\n# A tibble: 6 × 6\n  Country      Year Young   Old Population Continent\n  &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;fct&gt;    \n1 Afghanistan  1996  83.6   4.5     21560. Asia     \n2 Afghanistan  1998  84.1   4.5     22913. Asia     \n3 Afghanistan  2000  84.6   4.5     23898. Asia     \n4 Afghanistan  2002  85.1   4.5     25268. Asia     \n5 Afghanistan  2004  84.5   4.5     28514. Asia     \n6 Afghanistan  2006  84.3   4.6     31057  Asia     \n\n\n\n\n4.2.3.2 Data Quality Issues\nThe data summary statistics show that the maximum value of Young% is 109.2%, indicating inaccurate or incomplete data. This is problematic because Young% + Old% should be less than or equal to 100%. A value exceeding this would imply a negative Mid-aged%, which is neraly impossible and suggests inaccurate or missing data in this dataset.\n\nsummary(globalpop_raw)\n\n        Country          Year          Young             Old       \n Afghanistan:  28   Min.   :1996   Min.   : 15.50   Min.   : 1.00  \n Albania    :  28   1st Qu.:2010   1st Qu.: 25.70   1st Qu.: 6.90  \n Algeria    :  28   Median :2024   Median : 34.30   Median :12.80  \n Andorra    :  28   Mean   :2023   Mean   : 41.66   Mean   :17.93  \n Angola     :  28   3rd Qu.:2038   3rd Qu.: 53.60   3rd Qu.:25.90  \n Anguilla   :  28   Max.   :2050   Max.   :109.20   Max.   :77.10  \n (Other)    :6036                                                  \n   Population                Continent   \n Min.   :      3.3   Africa       :1568  \n 1st Qu.:    605.9   Asia         :1454  \n Median :   5771.6   Europe       :1344  \n Mean   :  34860.9   North America: 976  \n 3rd Qu.:  22711.0   Oceania      : 526  \n Max.   :1807878.6   South America: 336  \n                                         \n\n\nBelow are 63 observations with data accuracy issue. To maintain dataset’s integrity, we should remove these problematic countries records.\n\ndq_issues &lt;- subset(globalpop_raw, Young &gt; 100 | (Young + Old) &gt; 100)\n\ntable &lt;- DT::datatable(dq_issues, class= \"display\",\n              caption = \"Table 1: Observations with data quality issues\") %&gt;%\n  formatStyle(\n    columns = colnames(dq_issues), \n    fontSize = '12px', \n    fontFamily = 'Helvetica', \n    lineHeight = '1.2'\n  )\ntable\n\n\n\n\n\n\n\nAfter remove problematic records, there are 5,953 observations remained with 213 distinct countries.\n\nc_removed = unique(dq_issues$Country)\nglobalPop &lt;- subset(globalpop_raw, !(Country %in% c_removed))\nstr(globalPop)\n\ntibble [5,953 × 6] (S3: tbl_df/tbl/data.frame)\n $ Country   : Factor w/ 222 levels \"Afghanistan\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Year      : int [1:5953] 1996 1998 2000 2002 2004 2006 2008 2010 2012 2014 ...\n $ Young     : num [1:5953] 83.6 84.1 84.6 85.1 84.5 84.3 84.1 83.7 82.9 82.1 ...\n $ Old       : num [1:5953] 4.5 4.5 4.5 4.5 4.5 4.6 4.6 4.6 4.6 4.7 ...\n $ Population: num [1:5953] 21560 22913 23898 25268 28514 ...\n $ Continent : Factor w/ 6 levels \"Africa\",\"Asia\",..: 2 2 2 2 2 2 2 2 2 2 ...\n\nsummary(globalPop)\n\n        Country          Year          Young            Old       \n Afghanistan:  28   Min.   :1996   Min.   :15.50   Min.   : 1.00  \n Albania    :  28   1st Qu.:2010   1st Qu.:25.50   1st Qu.: 7.10  \n Algeria    :  28   Median :2024   Median :33.40   Median :13.70  \n Andorra    :  28   Mean   :2023   Mean   :40.19   Mean   :18.39  \n Angola     :  28   3rd Qu.:2038   3rd Qu.:50.90   3rd Qu.:26.50  \n Anguilla   :  28   Max.   :2050   Max.   :94.80   Max.   :77.10  \n (Other)    :5785                                                 \n   Population                Continent   \n Min.   :      3.3   Africa       :1372  \n 1st Qu.:    597.8   Asia         :1399  \n Median :   5580.3   Europe       :1344  \n Mean   :  35028.8   North America: 976  \n 3rd Qu.:  22093.1   Oceania      : 526  \n Max.   :1807878.6   South America: 336  \n                                         \n\n\n\nglobalPop %&gt;% summarise_all(~n_distinct(.))\n\n# A tibble: 1 × 6\n  Country  Year Young   Old Population Continent\n    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;int&gt;     &lt;int&gt;\n1     213    28   756   589       5549         6"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 03.b",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n4.3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young,\n                      size = Population,\n                      colour = Country))+\n  geom_point(alpha=0.7, show.legend = FALSE)+\n  scale_colour_manual(values = country_colors)+\n  scale_size(range= c(2,12))+\n  labs(title = 'Global Population Change from 1996 to 2050',\n       subtitle = 'Year:{frame_time}',\n       x = '% Aged',\n       y = '% Young')+\n  theme_economist(base_size = 8)\n\n\n\n\n\n\n\n\n\n\n4.3.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year). frame_time is a special placeholder (dynamic title) in gganimate.\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\nggplot(globalPop, aes(x = Old, y= Young,\n                      size = Population, colour = Country))+\n  geom_point(alpha = 0.7, show.legend = FALSE)+\n  scale_colour_manual(values = country_colors)+\n  scale_size(range = c(2,12))+   # control point size to be 2~12\n  labs(title = 'Global Population Change from 1996 to 2050',\n       subtitle = 'Year:{frame_time}',   # {frame_time} is a special placeholder (dynamic title) in gganimate\n       x = '% Aged',\n       y = '% Young')+\n  transition_time(Year)+\n  ease_aes('cubic-in-out')+\n  theme_economist(base_size = 8)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 03.b",
    "section": "4.4 Animated Data Visualisation: plotly",
    "text": "4.4 Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n4.4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, we will create an animated bubble plot by using ggplotly() method.\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, aes(x = Old, y = Young,\n                            size = Population, colour = Country))+\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7,\n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors)+\n  # control the size of points from 2 to 12\n  scale_size(range = c(2,12))+\n  labs(title = 'Global Population Change from 1996 to 2050',\n       x = '% Aged', \n       y = '% Young')+\n  theme_wsj(base_size = 8) + \n  theme(axis.title.x = element_text(size = 12, face = \"bold\"),\n        axis.title.y = element_text(size = 12, face = \"bold\"))\n\nggplotly(gg)\n\n\n\n\n\n4.4.1.1 Improvements Needed\n\nLegend: Notice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\nColor: Although the “country_colors” palette from gapminder provides colors for 142 countries, our dataset contains 213 countries, causing many data points to appear in grey. To improve visual distinction, we should color code the data by “Continent” rather than “Country”.\nTooltips: To improve the readability of the plot, tooltips are customized with detailed infomations by using text().\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, aes(x = Old, y = Young,\n                            size = Population, colour = Continent,\n                            text = paste(\"Year:\",Year, # customize the content in tooltips\n                                         \"&lt;br&gt;Continent:\",Continent,\n                                         \"&lt;br&gt;Country:\", Country,\n                                         \"&lt;br&gt;Population:\", scales::comma(Population), \"K\",\n                                         \"&lt;br&gt;Old:\",round(Old,2),\"%\",\n                                         \"&lt;br&gt;Young:\",round(Young,2),\"%\")))+ \n  geom_point(aes(frame = Year),alpha = 0.7) +\n  scale_size(range = c(2,12))+\n  labs(title = 'Global Population Change from 1996 to 2050',\n       x = '% Aged', \n       y = '% Young')+\n  theme_wsj(base_size = 8)+ scale_color_wsj()+\n  theme(axis.title.x = element_text(size = 12, face = \"bold\"),\n        axis.title.y = element_text(size = 12, face = \"bold\"),\n        legend.position = 'none') # remove legend\n\n\nggplotly(gg, tooltip = \"text\")\n\n\n\n\n\n4.4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\nTo customized the layout of plot_ly(), we need to use layout().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, y= ~Young,\n          size = ~Population, color = ~Continent,\n          sizes = c(2,100),\n          frame = ~Year, text = ~Country,\n          hoverinfo = \"text\",\n          type = \"scatter\", mode = \"markers\") %&gt;%\n  layout(showlegend = FALSE,\n         title = list (text = \"Global Population Change from 1996 to 2050\",\n                       font = list(size = 15,family=\"Georgia\", face = \"bold\")),\n         xaxis = list(title = \"% Aged\", \n                      titlefont = list(size = 12, family = \"Georgia\")),\n         yaxis = list(title = \"% Young\", \n                      titlefont = list(size = 12, family = \"Georgia\")),\n         plot_bgcolor = \"#f3f1e9\",\n         paper_bgcolor = \"#f3f1e9\")\n\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03-2.html#reference",
    "title": "Hands-on Exercise 03.b",
    "section": "4.5 Reference",
    "text": "4.5 Reference\n\ngganimate - Getting Started\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "Learn several ggplot2 extentions:\n\nUse ggrepel to control the placement of annotations on graphs\nUse ggthemes and hrbrthemes to create professional publication quality figure\nUse patchwork package to plot composite figure by combining ggplot2 graphs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#learning-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#learning-object",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "Learn several ggplot2 extentions:\n\nUse ggrepel to control the placement of annotations on graphs\nUse ggthemes and hrbrthemes to create professional publication quality figure\nUse patchwork package to plot composite figure by combining ggplot2 graphs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 02",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\n\n2.2.1 Installing and loading the required libraries\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork,ggthemes, hrbrthemes,tidyverse) \n\n\n\n2.2.2 Importing data\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThe dataset contains examination grades for 3 subjects from a local school. We can use head() and summary() function inspect the dataset.\nThere are a total of 7 attributes. 4 of them are categorical data type and the other 3 are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\nhead(exam_data,5)\n\n# A tibble: 5 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n\n\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 02",
    "section": "2.3 Beyond ggplot2 Annotation: ggrepel",
    "text": "2.3 Beyond ggplot2 Annotation: ggrepel\nOne of the challenges in plotting statistical graph is annotation, especially with large number of data points. As shown in the plots below, both labels and texts annotation are messy and overlapping, which makes them difficult for readers to understand.\n\ngeom_label()geom_text()\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method=lm,size=0.5)+\n  geom_label(aes(label = ID),hjust=0.5,vjust=-0.5)+\n  coord_cartesian(xlim=c(0,100), ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,y=ENGLISH))+\n  geom_point()+\n  geom_smooth(method=lm,size=0.5)+\n  geom_text(aes(label = ID),hjust=0.5,vjust=-0.5)+\n  coord_cartesian(xlim=c(0,100), ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is where ggrepel comes in. It is an extension of ggplot2 package, provides geoms for ggplot2 to repel overlapping text as in our examples above.\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\nHowever, since ggrepel’s purpose is to prevent overlapping labels and texts, it will only display non-overlapping labels when there are too many to fit in the plot. To show more labels, we can adjust the parameter max.overlaps = 20 , the higher this number, the more labels will be displayed.\n\ngeom_label_repel()geom_text_repel()\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,y=ENGLISH))+\n  # Use aes(color=cat) to seperate points by diff colors\n  geom_point(aes(color=GENDER))+\n  scale_color_manual(values = c(\"#D9A4C3\", \"#A4A8D9\"))+\n  geom_smooth(method=lm,size=0.5)+\n  # Use aes(color=cat) to seperate labels by diff colors\n  geom_label_repel(aes(label = ID, color = GENDER),\n                   size = 3,\n                   fontface=\"bold\",\n                   # change this setting to get more labels\n                   max.overlaps = 20)+\n  coord_cartesian(xlim=c(0,100), ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3 by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,y=ENGLISH))+\n  geom_point(aes(color=GENDER))+\n  scale_color_manual(values = c(\"#D9A4C3\", \"#A4A8D9\"))+\n  geom_smooth(method=lm,size=0.5)+\n  geom_text_repel(aes(label = ID,color = GENDER))+\n  coord_cartesian(xlim=c(0,100), ylim = c(0,100))+\n  ggtitle(\"English scores versus Maths scores for Primary 3 by Gender\")+\n  theme_classic()+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color behind the bar chart\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 02",
    "section": "2.4 Beyond ggplot2 Themes",
    "text": "2.4 Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void():\n\ntheme_classic()theme_minimal()theme_bw()theme_dark()theme_light()theme_linedraw()theme_void()\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_classic()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_minimal()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_bw()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        # adjust the color of panel grid\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_dark()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_light()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_linedraw()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE))+\n  geom_bar(bins=20,fill=\"#E8C8DB\",color=\"black\")+\n  coord_flip()+\n  theme_void()+\n  ggtitle(\"Number of Students by Race\")+\n  theme(plot.title = element_text(hjust = 0.5, face=\"bold\"),\n        # adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.background = element_rect(fill = \"#f3f1e9\"))\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\ntheme_wsj()theme_economist()theme_fivethirtyeight()\n\n\n\nggplot(data=exam_data, aes(x = MATHS, y= ENGLISH))+\n  geom_point(aes(color = RACE))+\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_wsj(base_size = 10) + scale_color_wsj()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS))+\n  geom_histogram(bins=20, boundary=100,color=\"grey25\",fill=\"grey90\")+\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS))+\n  geom_histogram(bins=20, boundary=100,color=\"grey25\",fill=\"grey90\")+\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_fivethirtyeight()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.2 Working with hrbthemes package\nhrbrthemes package provides a base theme that focuses on typographic elements (default font type is Arial), including where various labels are placed as well as the fonts that are used.\n\n\n\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis and y-axis grid lines. The default setting is grid = “XY”, if user only want to remain horizontal grid lines, set grid = “Y”\naxis argument control whether to show or hide the x-axis and y-axis lines. By default, the axes are hidden.\n\n\n\n\n\n\n\n\n\n\nTo make the graph more informative and descriptive, we can use lab() function to add the subtitle and the source:\nlabs( title=” “, subtitle=” “, caption=” “, x=” “, y=” “)\n\nadd “\\n” to create line breaks when your subtitle is too long to be displayed on a single line.\n\n\n\n\nBelow are the plots using hrbthemes:\n\nDefaultCustomized\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100,\n                 color=\"grey25\", fill=\"grey90\") +\n  labs(title=\"Distribution of Maths scores\",\n    subtitle=\"The Math Score distribution for Primary 3 is left-skewed,\\n indicating that most students achieved high grades in math\",\n    x=\"Math Score\",\n    caption=\"Source: ISSS608 VAA\")+\n  theme_ipsum()+\n  theme(# adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100,\n                 color=\"grey25\", fill=\"grey90\") +\n  labs(title=\"Distribution of Maths scores\",\n    subtitle=\"The Math Score distribution for Primary 3 is left-skewed,\\n indicating that most students achieved high grades in math\",\n    x=\"Math Score\",\n    caption=\"Source: ISSS608 VAA\")+\n  theme_ipsum(grid = \"Y\",  axis_title_size = 10 , base_size = 12)+\n  theme(# adjust the background color of the whole plot\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 02",
    "section": "2.5 Beyond Single Graph",
    "text": "2.5 Beyond Single Graph\nThere are several ggplot2 extensions provide functions to compose figure with multiple graphs, such as grid.arrange() of gridExtra package,  plot_grid() of cowplot package, and ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n2.5.1 Combining two ggplot2 graphs\nFirst, let’s draw several graphs:\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100,\n                 color=\"grey25\", fill=\"#E8C8DB\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")+\n  theme_classic()+\n  theme(plot.title = element_text(size = 12, face=\"bold\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, boundary = 100,\n                 color=\"grey25\", fill=\"#C8CBE8\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")+\n  theme_classic()+\n  theme(plot.title = element_text(size = 12, face=\"bold\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5) +  \n  coord_cartesian(xlim=c(0,100), ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores\")+\n  theme_classic()+\n  theme(plot.title = element_text(size = 12, face=\"bold\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA))\n\n\np1+p2\n\n\n\n\n\n\n\n\n\n\n2.5.2 Combining three or more ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\n\n2.5.3 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\ntag_levels could be ‘I’, ‘A’, ‘1’\n\ntag_levels = ‘I’tag_levels = ‘A’tag_levels = ‘1’\n\n\n\n((p1/p2)|p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n\n((p1+p2)/p3) + \n  plot_annotation(tag_levels = 'A')\n\n\n\n\n\n\n\n\n\n\n\n((p1/p2)|p3) + \n  plot_annotation(tag_levels = '1')\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.4 Adding subtitle and caption to the patchwork\nwe can also use plot_annotation() to add the title, subtitle and caption to the patchwork, and use theme() argument to cusomize the font size, font weight, background color and other visual parameters.\n\n\n\n\n\n\nHere we add theme() parameter in plot_annotation() to adjsut the element of patchwork’s title , subtitle…instead of using “&” or “+” to link functions.\nHowever, we can use “& theme()” after plot_annotation() to adjust the visual parameters of the graphs in the patchwork together.\n\n\n\n\n((p1 / p2) | p3) +\n  plot_annotation(\n    tag_levels = \"I\",\n    title = \"Exam Performance for Primary 3\",\n    subtitle = \"The plots show that there is a positive relationship between Math scores and English scores.\\nIn addtion, most students of Primary 3 got high scores on both subjects.\",\n    caption = \"Source: ISSS608 VAA\",\n    theme = theme(plot.title = element_text(size = 14, face = \"bold\"),\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n    plot.margin = margin(10, 10, 10, 10))) &\n    theme(axis.title = element_text(size=8) # adjust all axis titles to size = 8\n          )\n\n\n\n\n\n\n\n\n\n\n2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, left=0.02, bottom =0.6, right=0.5, top=1)\n\n\n\n\n\n\n\n\n\n\n2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\np4 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100,\n                 color=\"grey25\", fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\np5 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, boundary = 100,\n                 color=\"grey25\", fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\np6 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5) +  \n  coord_cartesian(xlim=c(0,100), ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores\")\n\n\n\n((p4 / p5) | p6) + \n    plot_annotation(\n    title = \"Exam Performance for Primary 3\",\n    subtitle = \"The plots show that there is a positive relationship between Math scores and English scores.\\nIn addtion, most students of Primary 3 got high scores on both subjects.\",\n    caption = \"Source: ISSS608 VAA\")& \n                    theme_economist() &\n                    theme(axis.title.x = element_text(size=8, margin = margin(t=5)), #above\n                          axis.title.y = element_text(size=8, margin = margin(r=5)),\n                          axis.text.x = element_text(size = 8),  \n                          axis.text.y = element_text(size = 6),\n                          plot.title = element_text(size = 11))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 02",
    "section": "2.6 Reference",
    "text": "2.6 Reference\n\nR for Visual Analytics-Beyond ggplot2 Fundamentals\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html",
    "title": "Hands-on Exercise 05.c",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGallypackage,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#overview",
    "title": "Hands-on Exercise 05.c",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGallypackage,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#getting-started",
    "title": "Hands-on Exercise 05.c",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImporting the dataObserving the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nLibrary\nDescription\n\n\n\n\nGGally\na ggplots extension by adding several functions to reduce the complexity of combining geoms with transformed data\n\n\ntidyverse\na family of R packages for data processing\n\n\nparallelPlot\na package for creating parallel plot\n\n\n\n\n\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 12 attributes and 156 observations with no missing values.\n\nhead(wh)\n\n# A tibble: 6 × 12\n  Country         Region `Happiness score` `Whisker-high` `Whisker-low` Dystopia\n  &lt;chr&gt;           &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 Albania         Centr…              4.59           4.70          4.48     1.46\n2 Bosnia and Her… Centr…              5.13           5.22          5.04     1.88\n3 Bulgaria        Centr…              4.93           5.02          4.84     1.22\n4 Croatia         Centr…              5.32           5.40          5.24     1.77\n5 Czech Republic  Centr…              6.71           6.78          6.64     2.49\n6 Estonia         Centr…              5.74           5.82          5.66     1.46\n# ℹ 6 more variables: `GDP per capita` &lt;dbl&gt;, `Social support` &lt;dbl&gt;,\n#   `Healthy life expectancy` &lt;dbl&gt;, `Freedom to make life choices` &lt;dbl&gt;,\n#   Generosity &lt;dbl&gt;, `Perceptions of corruption` &lt;dbl&gt;\n\n\n\nstr(wh)\n\nspc_tbl_ [156 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Country                     : chr [1:156] \"Albania\" \"Bosnia and Herzegovina\" \"Bulgaria\" \"Croatia\" ...\n $ Region                      : chr [1:156] \"Central and Eastern Europe\" \"Central and Eastern Europe\" \"Central and Eastern Europe\" \"Central and Eastern Europe\" ...\n $ Happiness score             : num [1:156] 4.59 5.13 4.93 5.32 6.71 ...\n $ Whisker-high                : num [1:156] 4.7 5.22 5.02 5.4 6.78 ...\n $ Whisker-low                 : num [1:156] 4.48 5.04 4.84 5.24 6.64 ...\n $ Dystopia                    : num [1:156] 1.46 1.88 1.22 1.77 2.49 ...\n $ GDP per capita              : num [1:156] 0.916 0.915 1.054 1.115 1.233 ...\n $ Social support              : num [1:156] 0.817 1.078 1.515 1.161 1.489 ...\n $ Healthy life expectancy     : num [1:156] 0.79 0.758 0.712 0.737 0.854 0.737 0.732 0.578 0.671 0.716 ...\n $ Freedom to make life choices: num [1:156] 0.419 0.28 0.359 0.38 0.543 0.553 0.259 0.448 0.363 0.35 ...\n $ Generosity                  : num [1:156] 0.149 0.216 0.064 0.12 0.064 0.086 0.061 0.274 0.092 0.026 ...\n $ Perceptions of corruption   : num [1:156] 0.032 0 0.009 0.039 0.034 0.174 0.022 0.023 0.066 0.006 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Country = col_character(),\n  ..   Region = col_character(),\n  ..   `Happiness score` = col_double(),\n  ..   `Whisker-high` = col_double(),\n  ..   `Whisker-low` = col_double(),\n  ..   Dystopia = col_double(),\n  ..   `GDP per capita` = col_double(),\n  ..   `Social support` = col_double(),\n  ..   `Healthy life expectancy` = col_double(),\n  ..   `Freedom to make life choices` = col_double(),\n  ..   Generosity = col_double(),\n  ..   `Perceptions of corruption` = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(wh)\n\n   Country             Region          Happiness score  Whisker-high  \n Length:156         Length:156         Min.   :2.905   Min.   :3.074  \n Class :character   Class :character   1st Qu.:4.454   1st Qu.:4.590  \n Mode  :character   Mode  :character   Median :5.378   Median :5.478  \n                                       Mean   :5.376   Mean   :5.479  \n                                       3rd Qu.:6.168   3rd Qu.:6.260  \n                                       Max.   :7.632   Max.   :7.695  \n  Whisker-low       Dystopia     GDP per capita   Social support \n Min.   :2.735   Min.   :0.292   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:4.345   1st Qu.:1.654   1st Qu.:0.6162   1st Qu.:1.077  \n Median :5.285   Median :1.909   Median :0.9495   Median :1.262  \n Mean   :5.273   Mean   :1.923   Mean   :0.8874   Mean   :1.217  \n 3rd Qu.:6.051   3rd Qu.:2.270   3rd Qu.:1.1978   3rd Qu.:1.463  \n Max.   :7.569   Max.   :2.961   Max.   :1.6490   Max.   :1.644  \n Healthy life expectancy Freedom to make life choices   Generosity    \n Min.   :0.0000          Min.   :0.0000               Min.   :0.0000  \n 1st Qu.:0.4223          1st Qu.:0.3583               1st Qu.:0.1095  \n Median :0.6440          Median :0.4940               Median :0.1740  \n Mean   :0.5980          Mean   :0.4570               Mean   :0.1816  \n 3rd Qu.:0.7772          3rd Qu.:0.5800               3rd Qu.:0.2422  \n Max.   :1.0300          Max.   :0.7240               Max.   :0.5980  \n Perceptions of corruption\n Min.   :0.0000           \n 1st Qu.:0.0510           \n Median :0.0820           \n Mean   :0.1125           \n 3rd Qu.:0.1390           \n Max.   :0.4570           \n\n\n\n# check missing value\nany(is.na(wh))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 05.c",
    "section": "3 Plotting Static Parallel Coordinates Plot",
    "text": "3 Plotting Static Parallel Coordinates Plot\nIn this section, we will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n3.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\nNotice that there are four arguments are used:\n\n Dataargument is used to map the data object (i.e. wh)\n columns is used to select the columns for preparing the parallel coordinates plot.\nalphaLines is used to adjsut transparency of the lines to reduce visual clutter.\ngroupColumn is used to highlight lines with different categories. In the code below, 2 represent column 2, whose column name is “Region”\n\n\nggparcoord(data = wh, \n           columns = c(7:12),\n           alphaLines = 0.4,\n           groupColumn = 2)+ # region\n  theme_classic()+\n  labs(title = \"Parallel coordinate by Region\", x=\"\")+\n  theme(plot.title = element_text(size=14, face = \"bold\",hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.position = \"top\",\n        legend.text = element_text(size=6), \n        legend.key.size = unit(0.1, \"cm\"))+ # Controls both width and height of legend keys.\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) # Increase Space Between Labels (Avoid Overlapping)\n\n\n\n\n\n\n\n\n\n\n3.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.3,\n           boxplot = TRUE)+\n    labs(title = \"Parallel Coordinates Plot of World Happines Variables\",x=\"\")+\n    theme(plot.title = element_text(size=14, face = \"bold\",hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.position = \"top\",\n        legend.text = element_text(size=6), \n        legend.key.size = unit(0.1, \"cm\"))+ # Controls both width and height of legend keys.\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) # Increase Space Between Labels (Avoid Overlapping)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n3.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\n\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\nTo rotate x-axis text labels, we use axis.text.x as argument to theme()function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\", #scale 0~1\n           alphaLines = 0.2,\n           boxplot = TRUE) +\n  labs(title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\",\n       x=\"\",y=\"\") +\n  facet_wrap(~ Region)+\n    theme(plot.title = element_text(size=13, face = \"bold\",hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.position = \"none\",\n        axis.text.x = element_text(angle=30, hjust=1, size= 6),\n        axis.text.y = element_text(size=6))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 05.c",
    "section": "4 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "4 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n4.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n4.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n4.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n4.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_c.html#reference",
    "title": "Hands-on Exercise 05.c",
    "section": "5 Reference",
    "text": "5 Reference\n\nKam, T.S. (2025). Visual Multivariate Analysis with Parallel Coordinates Plot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html",
    "title": "Hands-on Exercise 05.e",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#overview",
    "title": "Hands-on Exercise 05.e",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#getting-started",
    "title": "Hands-on Exercise 05.e",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\nLoading the packagesImporting the dataObserving the data\n\n\nUse the pacman package p_load() to check, install and launch the following R packages:\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\n\n\nAfter importing the data, let’s examine it to understand its data structure:\nThe dataset contains 13 attributes and 6,497 observations with no missing values.\n\nhead(wine)\n\n# A tibble: 6 × 13\n  `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides\n            &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n1             7.4               0.7           0                 1.9     0.076\n2             7.8               0.88          0                 2.6     0.098\n3             7.8               0.76          0.04              2.3     0.092\n4            11.2               0.28          0.56              1.9     0.075\n5             7.4               0.7           0                 1.9     0.076\n6             7.4               0.66          0                 1.8     0.075\n# ℹ 8 more variables: `free sulfur dioxide` &lt;dbl&gt;,\n#   `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;,\n#   alcohol &lt;dbl&gt;, quality &lt;dbl&gt;, type &lt;chr&gt;\n\n\n\nstr(wine)\n\nspc_tbl_ [6,497 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ fixed acidity       : num [1:6497] 7.4 7.8 7.8 11.2 7.4 7.4 7.9 7.3 7.8 7.5 ...\n $ volatile acidity    : num [1:6497] 0.7 0.88 0.76 0.28 0.7 0.66 0.6 0.65 0.58 0.5 ...\n $ citric acid         : num [1:6497] 0 0 0.04 0.56 0 0 0.06 0 0.02 0.36 ...\n $ residual sugar      : num [1:6497] 1.9 2.6 2.3 1.9 1.9 1.8 1.6 1.2 2 6.1 ...\n $ chlorides           : num [1:6497] 0.076 0.098 0.092 0.075 0.076 0.075 0.069 0.065 0.073 0.071 ...\n $ free sulfur dioxide : num [1:6497] 11 25 15 17 11 13 15 15 9 17 ...\n $ total sulfur dioxide: num [1:6497] 34 67 54 60 34 40 59 21 18 102 ...\n $ density             : num [1:6497] 0.998 0.997 0.997 0.998 0.998 ...\n $ pH                  : num [1:6497] 3.51 3.2 3.26 3.16 3.51 3.51 3.3 3.39 3.36 3.35 ...\n $ sulphates           : num [1:6497] 0.56 0.68 0.65 0.58 0.56 0.56 0.46 0.47 0.57 0.8 ...\n $ alcohol             : num [1:6497] 9.4 9.8 9.8 9.8 9.4 9.4 9.4 10 9.5 10.5 ...\n $ quality             : num [1:6497] 5 5 5 6 5 5 5 7 7 5 ...\n $ type                : chr [1:6497] \"red\" \"red\" \"red\" \"red\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   `fixed acidity` = col_double(),\n  ..   `volatile acidity` = col_double(),\n  ..   `citric acid` = col_double(),\n  ..   `residual sugar` = col_double(),\n  ..   chlorides = col_double(),\n  ..   `free sulfur dioxide` = col_double(),\n  ..   `total sulfur dioxide` = col_double(),\n  ..   density = col_double(),\n  ..   pH = col_double(),\n  ..   sulphates = col_double(),\n  ..   alcohol = col_double(),\n  ..   quality = col_double(),\n  ..   type = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nsummary(wine)\n\n fixed acidity    volatile acidity  citric acid     residual sugar  \n Min.   : 3.800   Min.   :0.0800   Min.   :0.0000   Min.   : 0.600  \n 1st Qu.: 6.400   1st Qu.:0.2300   1st Qu.:0.2500   1st Qu.: 1.800  \n Median : 7.000   Median :0.2900   Median :0.3100   Median : 3.000  \n Mean   : 7.215   Mean   :0.3397   Mean   :0.3186   Mean   : 5.443  \n 3rd Qu.: 7.700   3rd Qu.:0.4000   3rd Qu.:0.3900   3rd Qu.: 8.100  \n Max.   :15.900   Max.   :1.5800   Max.   :1.6600   Max.   :65.800  \n   chlorides       free sulfur dioxide total sulfur dioxide    density      \n Min.   :0.00900   Min.   :  1.00      Min.   :  6.0        Min.   :0.9871  \n 1st Qu.:0.03800   1st Qu.: 17.00      1st Qu.: 77.0        1st Qu.:0.9923  \n Median :0.04700   Median : 29.00      Median :118.0        Median :0.9949  \n Mean   :0.05603   Mean   : 30.53      Mean   :115.7        Mean   :0.9947  \n 3rd Qu.:0.06500   3rd Qu.: 41.00      3rd Qu.:156.0        3rd Qu.:0.9970  \n Max.   :0.61100   Max.   :289.00      Max.   :440.0        Max.   :1.0390  \n       pH          sulphates         alcohol         quality     \n Min.   :2.720   Min.   :0.2200   Min.   : 8.00   Min.   :3.000  \n 1st Qu.:3.110   1st Qu.:0.4300   1st Qu.: 9.50   1st Qu.:5.000  \n Median :3.210   Median :0.5100   Median :10.30   Median :6.000  \n Mean   :3.219   Mean   :0.5313   Mean   :10.49   Mean   :5.818  \n 3rd Qu.:3.320   3rd Qu.:0.6000   3rd Qu.:11.30   3rd Qu.:6.000  \n Max.   :4.010   Max.   :2.0000   Max.   :14.90   Max.   :9.000  \n     type          \n Length:6497       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n# check missing value\nany(is.na(wine))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 05.e",
    "section": "3 Building Correlation Matrix: pairs() method",
    "text": "3 Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n3.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npar(bg = \"#f3f1e9\")\npairs(wine[,1:11],main = \"Correlation Matrix\")\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npar(bg = \"#f3f1e9\")\npairs(wine[,2:12],main = \"Correlation Matrix\")\n\n\n\n\n\n\n\n\n\n\n3.2 Drawing the lower and upper corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\nlower panelupper panel\n\n\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below:\n\npar(bg = \"#f3f1e9\")\npairs(wine[,2:12], upper.panel = NULL,\n      main = \"Correlation Matrix with lower panel\")\n\n\n\n\n\n\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npar(bg = \"#f3f1e9\")\npairs(wine[,2:12], lower.panel = NULL,\n      main = \"Correlation Matrix with upper panel\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\npar(bg = \"#f3f1e9\")\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor,\n      main = \"Correlation Matrix\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#visualising-correlation-matrix-ggcormat-of-ggstatplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#visualising-correlation-matrix-ggcormat-of-ggstatplot",
    "title": "Hands-on Exercise 05.e",
    "section": "4 Visualising Correlation Matrix: ggcormat() of ggstatplot",
    "text": "4 Visualising Correlation Matrix: ggcormat() of ggstatplot\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nIn this section, we learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n4.1 Basic plot\nggcorrmat() not only visualise a correlation matrix but alos provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  tl.cex = 7,\n  title = \"Correlation Matrix\")+\n  theme(plot.title = element_text(size=13, hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        axis.text.x = element_text(angle=30, hjust=1, size= 7),\n        axis.text.y = element_text(size=7),\n        panel.grid = element_blank(),\n        plot.margin = margin(t = 15, r = 50, b = 15, l = 50, unit = \"pt\") )\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\")+\n  theme(plot.title = element_text(size=13, hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        axis.text.x = element_text(angle=30, hjust=1, size= 7),\n        axis.text.y = element_text(size=7),\n        panel.grid = element_blank(),\n        plot.margin = margin(t = 15, r = 50, b = 15, l = 50, unit = \"pt\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\n\n\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n4.2 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#visualising-correlation-matrix-using-corrplotpackage",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#visualising-correlation-matrix-using-corrplotpackage",
    "title": "Hands-on Exercise 05.e",
    "section": "5 Visualising Correlation Matrix using corrplotPackage",
    "text": "5 Visualising Correlation Matrix using corrplotPackage\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\npar(bg = \"#f3f1e9\")\ncorrplot(wine.cor,bg= \"#f3f1e9\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that :\n\nThe default visual object used to plot the corrgram is circle.\nThe default layout of the corrgram is a symmetric matrix.\nThe default colour scheme is diverging blue-red: Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients.\nThe intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\n\n\n5.1 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\npar(bg = \"#f3f1e9\")\ncorrplot(wine.cor, \n         method = \"ellipse\",\n         bg = \"#f3f1e9\") \n\n\n\n\n\n\n\n\n\n\n5.2 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\nOther layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them\n\n“lower”“upper”\n\n\n\npar(bg = \"#f3f1e9\")\ncorrplot(wine.cor, \n         method = \"ellipse\",\n         order = \"hclust\",\n         type = \"lower\",\n         bg = \"#f3f1e9\",\n         tl.col='black',\n         outline = TRUE,\n         diag = TRUE) #outline of elipse = True\n\n\n\n\n\n\n\n\n\n\n\npar(bg = \"#f3f1e9\")\ncorrplot(wine.cor, \n         method = \"ellipse\",\n         type = \"upper\",\n         bg = \"#f3f1e9\",\n         tl.col = 'grey20')\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.3 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\npar(bg = \"#f3f1e9\")\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\",\n               bg = \"#f3f1e9\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that :\n\nargument lower and upper are used to define the visualisation method used:\nIn this case:\n\nellipse is used to map the lower half of the corrgram\nnumerical matrix (i.e. number) is used to map the upper half of the corrgram.\nThe argument tl.pos, on the other, is used to specify the placement of the axis label.\nThe diag argument is used to specify the glyph on the principal diagonal of the corrgram."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#combining-corrgram-with-the-significant-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#combining-corrgram-with-the-significant-test",
    "title": "Hands-on Exercise 05.e",
    "section": "6 Combining corrgram with the significant test",
    "text": "6 Combining corrgram with the significant test\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\npar(bg = \"#f3f1e9\")\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05,\n         bg = \"#f3f1e9\")\n\n\n\n\n\n\n\n\n\n6.1 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n\npar(bg = \"#f3f1e9\")\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"grey30\",\n               bg = \"#f3f1e9\" )\n\n\n\n\n\n\n\n\n\n\n6.2 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\npar(bg = \"#f3f1e9\")\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               tl.pos = \"lt\",\n               order=\"hclust\",\n               hclust.method = \"ward.D\",\n               addrect = 3,\n               tl.col = \"grey30\",\n               bg = \"#f3f1e9\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_e.html#reference",
    "title": "Hands-on Exercise 05.e",
    "section": "7 Reference",
    "text": "7 Reference\n\nKam, T.S. (2025). Visual Correlation Analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_E00.html",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_E00.html",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "",
    "text": "Getting started\nLoading tidyverse onto r environment by using the code chunk below.\n\npacman::p_load(tidyverse)\n\n\n\nImporting data\n\nrealis_2019 &lt;- read_csv(\"data/REALIS2019.csv\")\n\n\npopdata_fat &lt;- read_csv(\"data/PopData2019_fat.csv\")\n\n\n\nPivoting data\n\npopdata_long &lt;- popdata_fat %&gt;%\n  pivot_longer(c(3,21),\n               names_to = \"Age Group\",\n               values_to = \"Population\")\n\n\n\nExport and Import R data files (.rds)\n\nwrite_rds(popdata_long, \"data/rds/popdata_long.rds\")\n\n\n\nSelect and filter columns\n\nrealis2019_filtered &lt;- realis_2019 %&gt;%\n  select(`Project Name`, `Type of Sale`, `Transacted Price ($)`, `Property Type`, `Unit Price ($ psm)`) %&gt;%\n  filter(`Property Type` == \"Condominium\" | `Property Type` == \"Apartment\") %&gt;%\n  filter(`Type of Sale` == \"New Sale\") %&gt;%\n  filter(`Unit Price ($ psm)` &gt; 11000)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Johsuan’s Visual Analytics Site",
    "section": "",
    "text": "This website contains exercises from ISSS608 Visual Analytics and Applications.\nI hope you enjoy exploring my website!\n\nHere are my latest posts :\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 05.e\n\n\nVisual Correlation Analysis\n\n\n\nFeb 13, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 05.c\n\n\nVisual Multivariate Analysis with Parallel Coordinates Plot\n\n\n\nFeb 12, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 05.d\n\n\nTreemap Visualisation with R\n\n\n\nFeb 12, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 05.b\n\n\nHeatmap for Visualising and Analysing Multivariate Data\n\n\n\nFeb 11, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 05.a\n\n\nCreating Ternary Plot with R\n\n\n\nFeb 10, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 04.d\n\n\nFunnel Plots for Fair Comparisons\n\n\n\nFeb 06, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 04.c\n\n\nVisualising Uncertainty\n\n\n\nFeb 05, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 04.b\n\n\nVisual Statistical Analysis\n\n\n\nFeb 03, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 04.a\n\n\nVisualising Distribution\n\n\n\nFeb 02, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 03.b\n\n\nProgramming Animated Statistical Graphics with R\n\n\n\nJan 28, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 03.a\n\n\nProgramming Interactive Data Visualisation with R\n\n\n\nJan 25, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 02\n\n\nBeyond ggplot2 Fundamentals\n\n\n\nJan 18, 2024\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 01\n\n\nA Layered Grammar of Graphics: ggplot2 methods\n\n\n\nJan 11, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "",
    "text": "As a graphical editor at an international media company, we publish weekly content on digital platforms. This week’s theme focuses on “Ship Performance in Gulf of Guinea.”\nOur target audience consists of general readers who are interested in the maritime sector and would like to gain insights into ship performance, including Financial Performance, Operational Performance and Route Performance.\n\n\n\nThe data we used is from Kaggle. This dataset consists of 2,736 observations with 18 attributes.\nThe Ship Performance Dataset is a synthetic collection of data including key operational metrics and attributes of various ship types in the Gulf of Guinea. This dataset aims to provide a platform for exploring ship performance trends, identifying patterns, and solving real-world maritime challenges through data-driven approaches."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#background",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#background",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "",
    "text": "As a graphical editor at an international media company, we publish weekly content on digital platforms. This week’s theme focuses on “Ship Performance in Gulf of Guinea.”\nOur target audience consists of general readers who are interested in the maritime sector and would like to gain insights into ship performance, including Financial Performance, Operational Performance and Route Performance."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "",
    "text": "The data we used is from Kaggle. This dataset consists of 2,736 observations with 18 attributes.\nThe Ship Performance Dataset is a synthetic collection of data including key operational metrics and attributes of various ship types in the Gulf of Guinea. This dataset aims to provide a platform for exploring ship performance trends, identifying patterns, and solving real-world maritime challenges through data-driven approaches."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#load-packages",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#load-packages",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\nWe load the following R packages using the pacman::p_load() function:\n\n\n\n\n\n\np_load() function allow us to load required packages that are already installed or install it first and then load if not locally available.\n\n\n\n\npacman::p_load(tidyverse, patchwork,\n               ggrepel, ggthemes, ggridges, \n               ggdist, ggiraph, plotly, DT,\n               hrbrthemes, ggiraph,ggstatsplot,\n               ggtext)\n\n\n\n\nLibrary\nDescription\n\n\n\n\ntidyverse\nA collection of core packages designed for data science.\n\n\npatchwork\nPrepare composite figure created using ggplot2\n\n\nggthemes\nExtra themes, geoms, and scales for ggplot2.\n\n\nggridges\nA ggplot2 extension specially designed for plotting ridgeline plots\n\n\ngganimate\nAn ggplot extension for creating animated statistical graphs.\n\n\nggdist\nA ggplot2 extension spacially desgin for visualising distribution and uncertainty.\n\n\nplotly\nR library for plotting interactive statistical graphs.\n\n\nDT\nprovides an R interface to the JavaScript library DataTables that create interactive table on html page.\n\n\nggiraph\nFor making ‘ggplot’ graphics interactive."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-import-overview-and-pre-processing",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-import-overview-and-pre-processing",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "2.2 Data Import, Overview and Pre-processing",
    "text": "2.2 Data Import, Overview and Pre-processing\n\nData ImportData OverviewMetadataData Pre-processing\n\n\nWe use read_csv() of readr to import data and datatable() of DT to display it:\n\nship &lt;- read_csv(\"data/Ship_Performance_Dataset.csv\")\n\n\n\n\n\n\n\n\n\n\nCheck data structure\nWe use str() function of R to check the internal structure of the data frame:\n\nstr(ship)\n\nspc_tbl_ [2,736 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                   : Date[1:2736], format: \"2023-06-04\" \"2023-06-11\" ...\n $ Ship_Type              : chr [1:2736] \"Container Ship\" \"Fish Carrier\" \"Container Ship\" \"Bulk Carrier\" ...\n $ Route_Type             : chr [1:2736] \"None\" \"Short-haul\" \"Long-haul\" \"Transoceanic\" ...\n $ Engine_Type            : chr [1:2736] \"Heavy Fuel Oil (HFO)\" \"Steam Turbine\" \"Diesel\" \"Steam Turbine\" ...\n $ Maintenance_Status     : chr [1:2736] \"Critical\" \"Good\" \"Fair\" \"Fair\" ...\n $ Speed_Over_Ground_knots: num [1:2736] 12.6 10.4 20.7 21.1 13.7 ...\n $ Engine_Power_kW        : num [1:2736] 2063 1796 1649 915 1090 ...\n $ Distance_Traveled_nm   : num [1:2736] 1031 1060 659 1127 1445 ...\n $ Draft_meters           : num [1:2736] 14.13 14.65 7.2 11.79 9.73 ...\n $ Weather_Condition      : chr [1:2736] \"Moderate\" \"Rough\" \"Moderate\" \"Moderate\" ...\n $ Cargo_Weight_tons      : num [1:2736] 1959 162 178 1737 261 ...\n $ Operational_Cost_USD   : num [1:2736] 483832 483388 448543 261350 287718 ...\n $ Revenue_per_Voyage_USD : num [1:2736] 292183 883766 394019 87551 676121 ...\n $ Turnaround_Time_hours  : num [1:2736] 25.9 63.2 49.4 22.4 64.2 ...\n $ Efficiency_nm_per_kWh  : num [1:2736] 1.455 0.29 0.5 0.703 1.331 ...\n $ Seasonal_Impact_Score  : num [1:2736] 1.416 0.886 1.406 1.371 0.583 ...\n $ Weekly_Voyage_Count    : num [1:2736] 1 6 9 1 8 7 3 6 8 2 ...\n $ Average_Load_Percentage: num [1:2736] 93.8 93.9 96.2 66.2 80 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_date(format = \"\"),\n  ..   Ship_Type = col_character(),\n  ..   Route_Type = col_character(),\n  ..   Engine_Type = col_character(),\n  ..   Maintenance_Status = col_character(),\n  ..   Speed_Over_Ground_knots = col_double(),\n  ..   Engine_Power_kW = col_double(),\n  ..   Distance_Traveled_nm = col_double(),\n  ..   Draft_meters = col_double(),\n  ..   Weather_Condition = col_character(),\n  ..   Cargo_Weight_tons = col_double(),\n  ..   Operational_Cost_USD = col_double(),\n  ..   Revenue_per_Voyage_USD = col_double(),\n  ..   Turnaround_Time_hours = col_double(),\n  ..   Efficiency_nm_per_kWh = col_double(),\n  ..   Seasonal_Impact_Score = col_double(),\n  ..   Weekly_Voyage_Count = col_double(),\n  ..   Average_Load_Percentage = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\nCheck data summary\nThe code chunk below uses R’s summary() function to display statistical summaries of our data frame.\n\nsummary(ship)\n\n      Date             Ship_Type          Route_Type        Engine_Type       \n Min.   :2023-06-04   Length:2736        Length:2736        Length:2736       \n 1st Qu.:2023-09-10   Class :character   Class :character   Class :character  \n Median :2023-12-17   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2023-12-17                                                           \n 3rd Qu.:2024-03-24                                                           \n Max.   :2024-06-30                                                           \n Maintenance_Status Speed_Over_Ground_knots Engine_Power_kW\n Length:2736        Min.   :10.01           Min.   : 501   \n Class :character   1st Qu.:13.93           1st Qu.:1148   \n Mode  :character   Median :17.71           Median :1757   \n                    Mean   :17.60           Mean   :1758   \n                    3rd Qu.:21.28           3rd Qu.:2383   \n                    Max.   :25.00           Max.   :2999   \n Distance_Traveled_nm  Draft_meters    Weather_Condition  Cargo_Weight_tons\n Min.   :  50.43      Min.   : 5.002   Length:2736        Min.   :  50.23  \n 1st Qu.: 548.51      1st Qu.: 7.437   Class :character   1st Qu.: 553.98  \n Median :1037.82      Median : 9.919   Mode  :character   Median :1043.21  \n Mean   :1036.41      Mean   : 9.929                      Mean   :1032.57  \n 3rd Qu.:1540.93      3rd Qu.:12.413                      3rd Qu.:1527.72  \n Max.   :1998.34      Max.   :14.993                      Max.   :1999.13  \n Operational_Cost_USD Revenue_per_Voyage_USD Turnaround_Time_hours\n Min.   : 10092       Min.   : 50352         Min.   :12.02        \n 1st Qu.:131293       1st Qu.:290346         1st Qu.:26.17        \n Median :257158       Median :520177         Median :41.59        \n Mean   :255143       Mean   :521362         Mean   :41.75        \n 3rd Qu.:381797       3rd Qu.:750073         3rd Qu.:57.36        \n Max.   :499735       Max.   :999917         Max.   :71.97        \n Efficiency_nm_per_kWh Seasonal_Impact_Score Weekly_Voyage_Count\n Min.   :0.1002        Min.   :0.500         Min.   :1.000      \n 1st Qu.:0.4636        1st Qu.:0.758         1st Qu.:3.000      \n Median :0.7899        Median :1.009         Median :5.000      \n Mean   :0.7987        Mean   :1.004         Mean   :4.915      \n 3rd Qu.:1.1474        3rd Qu.:1.253         3rd Qu.:7.000      \n Max.   :1.4993        Max.   :1.499         Max.   :9.000      \n Average_Load_Percentage\n Min.   : 50.01         \n 1st Qu.: 62.70         \n Median : 75.50         \n Mean   : 75.22         \n 3rd Qu.: 87.72         \n Max.   :100.00         \n\n\n\n\n\nSince the imported data types are not fully correct, we will handle them in the next tab “Data Preprocessing”. The data contains 5 categorical attributes, 1 temporal attribute, 11 decimal attributes, and 1 integer attributes:\n\n\n\n\n\n\n\n\nAttribute\nData type\nDescription\n\n\n\n\nDate\nDate\nTimestamp of the data entry from 2023/6/4 to 2024/6/30 (weekly data)\n\n\nShip_Type\nCategorical\nType of ship (e.g., Tanker, Container Ship, Fish Carrier, Bulk Carrier).\n\n\nRoute_Type\nCategorical\nShipping route type (e.g., Short-haul, Long-haul, Transoceanic).\n\n\nEngine_Type\nCategorical\nType of engine (e.g., Diesel, Heavy Fuel Oil).\n\n\nMaintenance_Status\nCategorical\nMaintenance condition of the ship (e.g., Fair, Critical, Good).\n\nLevel: Good &gt; Fair &gt; Critical\n\n\n\nWeather_Condition\nCategorical\nPrevailing weather conditions during voyages (e.g., Calm, Moderate, Rough)\n\n\nSpeed_Over_Ground_knots\nDecimal\nAverage speed of the ship over water (in knots).\n\n\nEngine_Power_kW\nDecimal\nTotal weekly Engine power output (in kilowatts).\n\n\nDistance_Traveled_nm\nDecimal\nTotal weekly distance traveled by the ship (in nautical miles).\n\n\nDraft_meters\nDecimal\nIt represents how deep the ship sits in the water and is a key measurement for navigation (in meters).\n\n\nCargo_Weight_tons\nDecimal\nTotal cargo weight per voyage (in tons)\n\n\nOperational_Cost_USD\nDecimal\nTotal operational cost per voyage (in USD).\n\n\nRevenue_per_Voyage_USD\nDecimal\nRevenue generated per voyage (in USD).\n\n\nTurnaround_Time_hours\nDecimal\nTotal time required to complete all activities necessary for a vessel to be ready for its next journey or task, including docking, unloading packages, refueling and other necessary maintainance (in hours).\n\n\nEfficiency_nm_per_kWh\nDecimal\nMeasureing how efficiently a vessel uses energy to travel in nautical miles per kilowatt-hour.\n\nA higher value means the vessel is more energy efficient\n1 nm ≈ 1.852 km\n\n\n\nSeasonal_Impact_Score\nDecimal\nMeasures how seasonal factors (e.g., monsoons, winter storms, ice conditions) impact vessel efficiency, turnaround time, or fuel consumption.\n\nA higher score indicates greater disruptions due to seasonal changes.\n\n\n\nWeekly_Voyage_Count\nInteger\nThe number of voyages a vessel completes within a week.\n\n\nAverage_Load_Percentage\nDecimal\nThe average percentage of capacity utilized by a vessel, vehicle, or transportation system over a week. Average Load Percentage = Actual Cargo Weight / Maximum Capacity * 100\n\nA low percentage may indicate inefficient routing or underutilized capacity.\n\n\n\n\n\n\n\nCheck missing values\nAs part of data wrangling, we begin by checking for missing values and duplicate records:\n\n# check missing value \nany(is.na(ship))\n\n[1] FALSE\n\n\nAlthough there are no missing values, but from the observation tab, we can see there are “None”s appearing in the dataset. The result of the code below showing each of the categorical attribute containing 136 “None” values and the related 609 records.\n\n# check None value\ncat_var &lt;- c('Route_Type', 'Ship_Type', 'Engine_Type', 'Maintenance_Status', 'Weather_Condition')\n\n#check \"None\" value in cat variables\nnone_counts &lt;- ship %&gt;%\n  select(all_of(cat_var)) %&gt;%\n  summarise(across(everything(), ~ sum(. == \"None\")))\n  \nnone_counts\n\n# A tibble: 1 × 5\n  Route_Type Ship_Type Engine_Type Maintenance_Status Weather_Condition\n       &lt;int&gt;     &lt;int&gt;       &lt;int&gt;              &lt;int&gt;             &lt;int&gt;\n1        136       136         136                136               136\n\n\n\n\n\n\n\n\n\n\nCheck duplicate records\n\ndistinct() function of dplyr package is used to identify the unique values within categorical attributes. The dataset contains 2,736 observations, matching the raw data count, which confirms there are no duplicate records.\n\n\n# check duplicate records\ndistinct(ship)\n\n# A tibble: 2,736 × 18\n   Date       Ship_Type      Route_Type   Engine_Type         Maintenance_Status\n   &lt;date&gt;     &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;               &lt;chr&gt;             \n 1 2023-06-04 Container Ship None         Heavy Fuel Oil (HF… Critical          \n 2 2023-06-11 Fish Carrier   Short-haul   Steam Turbine       Good              \n 3 2023-06-18 Container Ship Long-haul    Diesel              Fair              \n 4 2023-06-25 Bulk Carrier   Transoceanic Steam Turbine       Fair              \n 5 2023-07-02 Fish Carrier   Transoceanic Diesel              Fair              \n 6 2023-07-09 Fish Carrier   Long-haul    Heavy Fuel Oil (HF… Fair              \n 7 2023-07-16 Fish Carrier   Transoceanic Heavy Fuel Oil (HF… Critical          \n 8 2023-07-23 Container Ship Short-haul   Diesel              Critical          \n 9 2023-07-30 None           Coastal      Heavy Fuel Oil (HF… Good              \n10 2023-08-06 Container Ship Long-haul    Diesel              Fair              \n# ℹ 2,726 more rows\n# ℹ 13 more variables: Speed_Over_Ground_knots &lt;dbl&gt;, Engine_Power_kW &lt;dbl&gt;,\n#   Distance_Traveled_nm &lt;dbl&gt;, Draft_meters &lt;dbl&gt;, Weather_Condition &lt;chr&gt;,\n#   Cargo_Weight_tons &lt;dbl&gt;, Operational_Cost_USD &lt;dbl&gt;,\n#   Revenue_per_Voyage_USD &lt;dbl&gt;, Turnaround_Time_hours &lt;dbl&gt;,\n#   Efficiency_nm_per_kWh &lt;dbl&gt;, Seasonal_Impact_Score &lt;dbl&gt;,\n#   Weekly_Voyage_Count &lt;dbl&gt;, Average_Load_Percentage &lt;dbl&gt;\n\n\n\n\nConvert data type\nWe then convert the data type for 5 categorical attributes from &lt;chr&gt; to &lt;fctr&gt; and 1 integer attribute from &lt;dbl&gt; to &lt;int&gt; by using mutate() of dplyr package.\n\n# mutate data type\nship &lt;- ship %&gt;% \n  mutate_if(is.character, as.factor) %&gt;%\n  mutate(Weekly_Voyage_Count = as.integer(Weekly_Voyage_Count))\n\n#check the revised data type\nhead(ship)\n\n# A tibble: 6 × 18\n  Date       Ship_Type      Route_Type   Engine_Type          Maintenance_Status\n  &lt;date&gt;     &lt;fct&gt;          &lt;fct&gt;        &lt;fct&gt;                &lt;fct&gt;             \n1 2023-06-04 Container Ship None         Heavy Fuel Oil (HFO) Critical          \n2 2023-06-11 Fish Carrier   Short-haul   Steam Turbine        Good              \n3 2023-06-18 Container Ship Long-haul    Diesel               Fair              \n4 2023-06-25 Bulk Carrier   Transoceanic Steam Turbine        Fair              \n5 2023-07-02 Fish Carrier   Transoceanic Diesel               Fair              \n6 2023-07-09 Fish Carrier   Long-haul    Heavy Fuel Oil (HFO) Fair              \n# ℹ 13 more variables: Speed_Over_Ground_knots &lt;dbl&gt;, Engine_Power_kW &lt;dbl&gt;,\n#   Distance_Traveled_nm &lt;dbl&gt;, Draft_meters &lt;dbl&gt;, Weather_Condition &lt;fct&gt;,\n#   Cargo_Weight_tons &lt;dbl&gt;, Operational_Cost_USD &lt;dbl&gt;,\n#   Revenue_per_Voyage_USD &lt;dbl&gt;, Turnaround_Time_hours &lt;dbl&gt;,\n#   Efficiency_nm_per_kWh &lt;dbl&gt;, Seasonal_Impact_Score &lt;dbl&gt;,\n#   Weekly_Voyage_Count &lt;int&gt;, Average_Load_Percentage &lt;dbl&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#numeric-variables",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#numeric-variables",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "3.1 Numeric Variables",
    "text": "3.1 Numeric Variables\nThe numeric variables display multi-modal or uniform distributions (particularly for operational cost and revenue) rather than normal distributions. This pattern likely results from different ship types and route types creating distinct peaks in the distribution. Since this dataset contains weekly ship data, with ships making varying numbers of voyages, we should normalize all numeric variables to a per-voyage basis instead of using total amounts like “Distance_Traveled_nm”.\nIn addtion, Operational_Cost_USD and Revenue_per_Voyage_USD have notably different scales comparing to other variables, requiring adjustment.\n\n\n\nDisplay Code\n\n# select numeric variables\nship_numeric &lt;- ship %&gt;% select_if(is.numeric)\n\n# unpivot the data from wide to long format\nship_long &lt;- ship_numeric %&gt;% \n  pivot_longer(cols = everything(), # select all num variables\n               names_to = \"variable\", \n               values_to = \"value\")\n\n# Plot histograms for all numeric variables with facets\nggplot(ship_long, aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"grey70\", color = \"grey30\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  labs(title = \"Histograms of All Numeric Variables\",\n       x = \"\", y = \"Frequency\") +\n  theme_minimal()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        panel.grid = element_blank())"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#categorical-variables",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#categorical-variables",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "3.2 Categorical Variables",
    "text": "3.2 Categorical Variables\nTo understand the marine sector, we need to research and understand the characteristics of different ship types, engine types, and route types for better analysis:\n\n3.2.1 Ship Type\n\nBulk Carrier: Carry dry raw mateials like coal, grain and iron ore. The cargo normally holds with hatch covers with large quantity, following long-haul trade routes\nContainer Ship: Carry standardized constainers, designed with flat deck with container slots and securing mechanisms. It’s suitable for efficient global trade.\nFish Carrier: It is used to ship live or frozen fish from fishing vessels to processing facilities or markets, equipped with water tanks (for live fish) or refrigerated holds (for frozen fish)\nTanker: Carry liquid cargo like crude oil and petroleum products, equipped with large cylindrical tanks, reinforced hulls, following strict environmental regulations.\n\n\n\n3.2.2 Route Type\nBased on ship distance: Transoceanic Routes&gt;Long-Haul Routes&gt;Short-Haul Routes&gt;Coastal Routes\n\nCoastal Routes: Ships operate close to the coast or within a specific region, often moving between ports in the same country or nearby nations. Normally focus on frequent trips rather than high cargo volume.\nShort-Haul Routes: Routes that connect medium-distance destinations (typically within a continent or between neighboring regions). Medium-sized vessels for balanced capacity and speed.\nLong-Haul Routes: Ships travel between continents(international trade), connecting major industrial and commercial centers. Larger ships designed for fuel efficiency and maximum cargo capacity.\nTransoceanic Routes: Ships cross entire oceans(Global Trade), linking distant global markets (e.g., Asia to Europe, North America to Australia). Largest ships with ultra-long-range fuel capacity.\n\n\n\n3.2.3 Engine Type\nFuel efficeincy: Diesel &gt; HFO &gt; Stream Turbine\n\nHeavy Fuel Oil (HFO) Engines: These engines use Heavy Fuel Oil (HFO), which is a low-cost but highly polluting fuel, common in large commercial ships and long-haul or Transoceanic Routes due to cost efficiency.\nSteam Turbine Engines: These engines uses steam to drive a turbine, typically powered by boilers burning HFO or LNG. Ships with these engines supposed to be aged, for its a technology old goods. It is less fuel-efficient compared to diesel engines.\nDiesel Engines: It is the most common engine type today, which is more fuel-efficient and meets modern environmental regulations.\n\n\n\n3.2.4 Visualization\nAs for categorical variables, the distributions are also quite even, except for:\n\nThe number of ship with diesel engines is slightly higher than others\nThe count of long-haul slightly higher\nThe count of “rough” weather condition is slightly lower than others\n\nAdditionally, during data preprocessing, we observed 136 null values for each category, which will be addressed in later steps.\n\n\n\nDisplay Code\n\n# select only char variables\nship_factors &lt;- ship %&gt;% select_if(is.factor)  \n\n# unpivot the data from wide to long format\nship_long_factors &lt;- ship_factors %&gt;% \n  pivot_longer(cols = everything(), \n               names_to = \"variable\", \n               values_to = \"value\")\n\n\n# plot bar charts for all categorical variables\nggplot(ship_long_factors, aes(x = value, fill = variable)) +\n  geom_bar() +\n  facet_wrap(~ variable, scales = \"free\") +  # Facet by variable name\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(title = \"Bar Plots of All Categorical Variables\",\n       x = \"\", y = \"Count\") +\n  theme_minimal() +\n    theme(plot.title = element_text(size=13, hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.position = \"none\",\n        axis.text.x = element_text(angle=20, hjust=1, size= 7),\n        axis.text.y = element_text(size=6),\n        panel.grid = element_blank())"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#transform-data-unit",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#transform-data-unit",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "4.1 Transform Data Unit",
    "text": "4.1 Transform Data Unit\n\nOperational_Cost_USD & Revenue_per_Voyage_USD: Both variables are in USD, we should divide them by 1,000 to make them more comparable\n\n\n# divide Operational cost and revenue by 1000\n\nship_cleaned &lt;- ship %&gt;%\n  mutate(Cost_per_Voyage_k = Operational_Cost_USD/1000)\n\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(Revenue_per_Voyage_k = Revenue_per_Voyage_USD/1000)"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#derive-new-variables",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#derive-new-variables",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "4.2 Derive New Variables",
    "text": "4.2 Derive New Variables\n\nDate: Since weekly data is too granular for our analysis, “New_Date” variable is created to aggregate data monthly and “Season” variables are also created from the Date field.\n\n# create New_date (monthly)\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(New_Date = as.Date(paste(format(Date, \"%Y\"),format(Date, \"%m\"), \"01\", sep = \"-\"),\n                            format = \"%Y-%m-%d\"))\n# create season var\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(Quarter = case_when(\n    month(Date) %in% 1:3 ~ \"Q1\",\n    month(Date) %in% 4:6 ~ \"Q2\",\n    month(Date) %in% 7:9 ~ \"Q3\",\n    month(Date) %in% 10:12 ~ \"Q4\"\n  ))\n\nProfit and Net Margin Per Voyage: Profit and Net margin percentage per voyage will be calculated to evaluate ship financial performance.\n\n# create margin per voyage\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(Margin_per_Voyage = ((Revenue_per_Voyage_k - Cost_per_Voyage_k) / Revenue_per_Voyage_k) * 100)\n\n# create profit per voyage\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(Profit_per_Voyage = Revenue_per_Voyage_k - Cost_per_Voyage_k)\n\nDistance travel & Cost per Nautical Mile :According to Kaggle, “Distance_Traveled_nm” represent total distance traveled by the ship. These values will be divided by weekly_voyage_count. In addition, cost per Nautical Mile will be derived for financial performance evaluation.\n\n# create distance travel per voyage\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(distance_travel_per_V = Distance_Traveled_nm / Weekly_Voyage_Count)\n\n# create cost per nm\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(Cost_per_nm = Cost_per_Voyage_k / distance_travel_per_V)\n\nMaximum Capacity of Ships and Classification: The original dataset lacks ship size information. This is a significant factor for shipment capacity and directly affects potential revenue and operational cost per voyage.\n\n# create Maxiumn Capacity of ship\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(Max_capacity = Cargo_Weight_tons / Average_Load_Percentage*100)\n\n# categorized ship into diff size based on max capacity\n# min = \nship_cleaned$Ship_Size &lt;- cut(ship_cleaned$Max_capacity, \n                    breaks = c(0, 1300, 2000, Inf), \n                    labels = c(\"Small\", \"Medium\", \"Large\"), \n                    right = FALSE)\n# create interaction variables - ship type * ship size\nship_cleaned &lt;- ship_cleaned %&gt;%\n  mutate(\n    type_size = factor(interaction(Ship_Type,Ship_Size, sep = \"_\")))"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#drop-variables-and-none-values",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#drop-variables-and-none-values",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "4.3 Drop Variables and None Values",
    "text": "4.3 Drop Variables and None Values\nBased on the previous univariate and correlation analysis, we will retain only the relevant variables for further analysis. While the missing values in categorical data have minimal impact on our analysis, they create visualization challenges since all categorical variables contain missing values.\n\n# These variables are dropped\nship_cleaned &lt;- ship_cleaned %&gt;% select(-c(\n     'Operational_Cost_USD','Revenue_per_Voyage_USD',\n     'Draft_meters','Speed_Over_Ground_knots','Engine_Power_kW',\n     'Distance_Traveled_nm','Date','Draft_meters',\n     'Speed_Over_Ground_knots'))\n\n# filter all the cat data is not \"None\"\n\ncat_var &lt;- c('Route_Type', 'Ship_Type', 'Engine_Type', 'Maintenance_Status', 'Weather_Condition')\n\nship_cleaned &lt;- ship_cleaned %&gt;%\n  filter(if_all(all_of(cat_var), ~ . != \"None\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#check-correlation-matrix",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#check-correlation-matrix",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "4.4 Check Correlation Matrix",
    "text": "4.4 Check Correlation Matrix\nWe then use ggcorrmatexamine the correlation matrix of numerical variables. Based on the results below, 13 pairs of variables show significant correlations.\nAmong them, profit per voyage has a strong positive correlation with revenue (r = 0.73) and margin (r=0.88) per voyage , indicating that higher revenues generally lead to higher profits, though other factors like costs (r=-0.44) also influence this relationship. Lastly, max capacity and cargo weight show an almost perfect correlation (r = 0.92), indicating that ships generally operate close to their full capacity.\n\n\n\nDisplay Code\n\n\nship_cleaned_num &lt;- ship_cleaned %&gt;% select_if(is.numeric) \n\nggcorrmat(\n  data = ship_cleaned_num,\n  colors = c(  \"#D989AE\",\"white\",\"#96C6D9\"),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 8),\n  title    = \"Correlogram for ship dataset\",\n  subtitle = \"None of pairs is significant at p &lt; 0.05\")+\n  theme(plot.title = element_text(size=13, hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        axis.text.x = element_text(angle=30, hjust=1, size= 7),\n        axis.text.y = element_text(size=7),\n        panel.grid = element_blank(),\n        plot.margin = margin(t = 15, r = 50, b = 15, l = 50, unit = \"pt\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#check-variable-distribution-and-summary-after-data-wrangling",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#check-variable-distribution-and-summary-after-data-wrangling",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "4.5 Check Variable Distribution and Summary After Data Wrangling",
    "text": "4.5 Check Variable Distribution and Summary After Data Wrangling\nAfter transformation, Profit_per_Voyage shows a normal distribution. However, Margin_per_Voyage displays extreme values—ranging from -842.56% to 98.73%, with a median of 50.56%—indicating substantial variation in profit margins across ships.\n\nNumerical Data DistributionCategorical Data DistributionNew Summary\n\n\n\n\n\nDisplay Code\n\n# select numeric variables\nship_cleaned_num&lt;- ship_cleaned %&gt;% select_if(is.numeric)\n\n# unpivot the data from wide to long format\nship_long &lt;- ship_cleaned_num %&gt;% \n  pivot_longer(cols = everything(), # select all num variables\n               names_to = \"variable\", \n               values_to = \"value\")\n\n# Plot histograms for all numeric variables with facets\nggplot(ship_long, aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"grey70\", color = \"grey30\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  labs(title = \"Histograms of All Numeric Variables\",\n       x = \"\", y = \"Frequency\") +\n  theme_minimal()+\n  theme(panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        panel.grid = element_blank(),\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\n\nship_factors &lt;- ship_cleaned %&gt;% select_if(is.factor)  \n\n# unpivot the data from wide to long format\nship_long_factors &lt;- ship_factors %&gt;% \n  pivot_longer(cols = everything(), \n               names_to = \"variable\", \n               values_to = \"value\")\n\n\n# plot bar charts for all categorical variables\nggplot(ship_long_factors, aes(x = value, fill = variable)) +\n  geom_bar() +\n  facet_wrap(~ variable, scales = \"free\") +  # Facet by variable name\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(title = \"Bar Plots of All Categorical Variables\",\n       x = \"\", y = \"Count\") +\n  theme_minimal() +\n    theme(plot.title = element_text(size=13, hjust=0),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\",color = NA),\n        legend.position = \"none\",\n        axis.text.x = element_text(angle=30, hjust=1, size= 7),\n        axis.text.y = element_text(size=6),\n        panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(ship_cleaned)\n\n          Ship_Type          Route_Type                Engine_Type \n Bulk Carrier  :550   Coastal     :533   Diesel              :721  \n Container Ship:524   Long-haul   :566   Heavy Fuel Oil (HFO):702  \n Fish Carrier  :521   None        :  0   None                :  0  \n None          :  0   Short-haul  :513   Steam Turbine       :704  \n Tanker        :532   Transoceanic:515                             \n                                                                   \n                                                                   \n Maintenance_Status Weather_Condition Cargo_Weight_tons Turnaround_Time_hours\n Critical:716       Calm    :724      Min.   :  50.23   Min.   :12.02        \n Fair    :713       Moderate:738      1st Qu.: 557.07   1st Qu.:26.31        \n Good    :698       None    :  0      Median :1045.37   Median :41.53        \n None    :  0       Rough   :665      Mean   :1033.47   Mean   :41.77        \n                                      3rd Qu.:1526.15   3rd Qu.:57.56        \n                                      Max.   :1999.13   Max.   :71.97        \n                                                                             \n Efficiency_nm_per_kWh Seasonal_Impact_Score Weekly_Voyage_Count\n Min.   :0.1002        Min.   :0.5000        Min.   :1.000      \n 1st Qu.:0.4553        1st Qu.:0.7529        1st Qu.:3.000      \n Median :0.7750        Median :1.0076        Median :5.000      \n Mean   :0.7899        Mean   :1.0016        Mean   :4.906      \n 3rd Qu.:1.1363        3rd Qu.:1.2503        3rd Qu.:7.000      \n Max.   :1.4982        Max.   :1.4992        Max.   :9.000      \n                                                                \n Average_Load_Percentage Cost_per_Voyage_k Revenue_per_Voyage_k\n Min.   :50.01           Min.   : 10.1     Min.   : 50.35      \n 1st Qu.:62.51           1st Qu.:133.9     1st Qu.:292.18      \n Median :75.16           Median :259.1     Median :524.08      \n Mean   :75.13           Mean   :257.0     Mean   :523.43      \n 3rd Qu.:87.69           3rd Qu.:384.5     3rd Qu.:752.93      \n Max.   :99.95           Max.   :499.7     Max.   :999.81      \n                                                               \n    New_Date            Quarter          Margin_per_Voyage Profit_per_Voyage\n Min.   :2023-06-01   Length:2127        Min.   :-842.56   Min.   :-428.28  \n 1st Qu.:2023-09-01   Class :character   1st Qu.:  15.78   1st Qu.:  47.54  \n Median :2023-12-01   Mode  :character   Median :  50.56   Median : 259.07  \n Mean   :2023-12-03                      Mean   :  21.30   Mean   : 266.39  \n 3rd Qu.:2024-03-01                      3rd Qu.:  74.22   3rd Qu.: 492.05  \n Max.   :2024-06-01                      Max.   :  98.73   Max.   : 977.17  \n                                                                            \n distance_travel_per_V  Cost_per_nm        Max_capacity      Ship_Size  \n Min.   :   6.316      Min.   : 0.00771   Min.   :  57.47   Small :987  \n 1st Qu.: 115.068      1st Qu.: 0.44204   1st Qu.: 757.34   Medium:629  \n Median : 211.288      Median : 1.04372   Median :1387.72   Large :511  \n Mean   : 333.200      Mean   : 2.30613   Mean   :1428.79               \n 3rd Qu.: 377.859      3rd Qu.: 2.26576   3rd Qu.:1974.02               \n Max.   :1996.554      Max.   :63.01965   Max.   :3993.33               \n                                                                        \n                 type_size  \n Bulk Carrier_Small   :275  \n Container Ship_Small :242  \n Tanker_Small         :236  \n Fish Carrier_Small   :234  \n Tanker_Medium        :176  \n Container Ship_Medium:159  \n (Other)              :805"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#financial-performance-average-revenue-and-net-margin-across-ship-types",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#financial-performance-average-revenue-and-net-margin-across-ship-types",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "5.1 Financial Performance: Average Revenue and Net Margin Across Ship Types",
    "text": "5.1 Financial Performance: Average Revenue and Net Margin Across Ship Types\nThe interactive plot below showcases average revenue and net margin trends for different ship types in the Gulf of Guinea:\n\nBulk Carrier: Displays the highest fluctuations, with peaks in May and August, a decline in November, and the lowest performance in January. Its profit margin drops to negative in November and January, with an average margin of 16.05% and revenue of 523.06K.\nFish Carrier: Stands out for its consistent performance throughout the year, showing a small dip in August due to reduced demand. It boasts the highest profit margin at 24.26% and revenue of 534.89K.\nContainer Ship: Experiences peaks in November and January, coinciding with high-demand periods like Black Friday, Christmas, and Chinese New Year, but has negative margin in July, December 2023 and May 2024. Profit margin is 21.27% with revenue of 524.55K.\nTanker: Shows no clear peak season, though revenue fluctuates, with lower points in September, January, and May. Its profit margin remains stable at 23.87%, with revenue of 511.48K.\n\n\n\n\nDisplay Code\n\n# calculate Monthly average revenue, cost, and profit margin per Ship_Type over time\nship_avg &lt;- ship_cleaned %&gt;%\n  group_by(New_Date, Ship_Type) %&gt;%\n  summarize(\n    avg_revenue = mean(Revenue_per_Voyage_k, na.rm = TRUE),\n    avg_margin = mean(Margin_per_Voyage, na.rm = TRUE))\n\n# calculate all ship's Monthly average revenue, cost, and profit margin over time\navg &lt;- ship_cleaned %&gt;%\n  group_by(New_Date) %&gt;%\n  summarize(\n    avg_revenue = mean(Revenue_per_Voyage_k, na.rm = TRUE),\n    avg_margin = mean(Margin_per_Voyage, na.rm = TRUE))\n\n# compute yearly average per Ship_Type for tooltips\nyearly_avg &lt;- ship_cleaned %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarize(\n    avg_revenue_yearly = mean(Revenue_per_Voyage_k, na.rm = TRUE),\n    avg_margin_yearly = mean(Margin_per_Voyage, na.rm = TRUE)\n  )\n\nship_avg &lt;- ship_avg %&gt;%\n  left_join(yearly_avg, by = \"Ship_Type\")\n\n\n# plot avg rev by ship type\np1 &lt;- ggplot() + \n  geom_line_interactive(data = ship_avg, \n                        aes(x = New_Date, \n                            y = avg_revenue,\n                            color = Ship_Type, \n                            tooltip = round(avg_revenue_yearly,2),\n                            data_id = Ship_Type), size = 1) +\n  geom_line(data = avg, \n            aes(x = New_Date, y = avg_revenue), \n            size = 0.4, \n            linetype = \"dashed\", \n            color='grey40') +\n  # Add label \"Mean\" \n  annotate(\"text\", x = as.Date(\"2024-06-03\"), y = 505, label = \"Mean\\n523K\", \n           color = \"grey40\", size = 2, hjust = 0) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\\n%Y\") +\n  scale_color_manual(values = my_palette) +\n  guides(\n    fill = guide_legend(order = 1),\n    linetype = guide_legend(title = \"Line Type\", order = 2)  # Only for the reference line\n  ) +\n  labs(x = \"\",\n       y = \"Revenue per Voyage ($000s)\",\n       title = \"Exploring Average Revenue and Net Margin Across Ship Types\",\n       color = \"Legend\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 11, hjust = 0.5, face = 'bold'),\n        axis.title.y = element_text(size = 7),\n        axis.text = element_text(size = 6),\n        legend.position = 'top',\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        legend.key.size = unit(0.2, \"cm\"),\n        legend.title = element_text(size = 9),\n        legend.text = element_text(size = 8),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\", color = NA))\n\n# plot avg profit margin by ship type\n\np2 &lt;- ggplot() + \n  geom_line_interactive(data = ship_avg, \n                        aes(x = New_Date, y = avg_margin,\n                            color = Ship_Type,\n                            tooltip = round(avg_margin_yearly,2),\n                            data_id = Ship_Type), size = 1) +\n  geom_line(data = avg, aes(x = New_Date, y = avg_margin),\n            size = 0.4, linetype = \"dashed\", color='grey40') + \n  annotate(\"text\", x = as.Date(\"2024-06-03\"), y = 14, label = \"Mean\\n21.3%\", \n           color = \"grey40\", size = 2, hjust = 0) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\\n%Y\") +\n  scale_color_manual(values = my_palette) +\n  guides(\n    fill = guide_legend(order = 1),\n    linetype = guide_legend(title = \"Line Type\", order = 2)  # Only for the reference line\n  ) +\n  labs(x = \"\",\n       y = \"Profit Margin %\",\n       color = \"Legend\") +\n  theme_classic() +\n  theme(\n        axis.title.y = element_text(size = 7),\n        axis.text = element_text(size = 6),\n        legend.position = 'none',\n        legend.justification = c(0, 1),\n        legend.background = element_rect(fill = \"#f3f1e9\"),\n        panel.background = element_rect(fill = \"#f3f1e9\"),\n        plot.background = element_rect(fill = \"#f3f1e9\", color = NA)\n  )\n\n# Combine the two plots\npatch &lt;- p1 / p2 & \n  theme(\n    plot.margin = margin(0, 0, 0, 0),  # Removes extra space around the combined plots\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA)\n  )\n\n# Generate the interactive graph\ngirafe(\n  code = print(patch), \n  width_svg = 6,\n  height_svg = 4,\n  options = list(\n    opts_hover(css = \"stroke-width:3px; opacity: 1;\"),\n    opts_hover_inv(css = \"opacity: 0.2;\")\n  ))"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#financial-performance-seasonal-profit-trends-by-ship-type",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#financial-performance-seasonal-profit-trends-by-ship-type",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "5.2 Financial Performance: Seasonal Profit Trends by Ship Type",
    "text": "5.2 Financial Performance: Seasonal Profit Trends by Ship Type\nBased on the previous Plot 5.1, we analyze operational profit by ship type among quaters. The “Average Load Percentage” tab suggests that lower profits may result from reduced load percentages, leading to decreased revenue and lower profit margins.\nThe two plots show:\n\nTanker: Revenue dips in September(Q3), January(Q1), and May(Q2) are linked to large tankers operating below the quarterly medium load percentage of 74.3%–76.2%, which reduces overall profit.\nBulk Carrier: In January (Q1) and November (Q4), both medium and large bulk carriers show lower loading rates, likely correlating with decreased profitability.\nContainer Ship: Although Q4 is a typical busy season for container ships, the second plot shows large container ships have low average loading rate compared to other ship sizes, likely contributing to the revenue and margin dip in December (as seen in Plot 5.1)\n\n\nOperational ProfitAverage Load Percentage\n\n\n\n\n\nDisplay Code\n\n# calculate average profit per quarter\nquarter_avg &lt;- ship_cleaned %&gt;%\n  group_by(Quarter) %&gt;%\n  summarise(avg_profit = mean(Profit_per_Voyage, na.rm = TRUE))\n\nquarter_median &lt;- ship_cleaned %&gt;%\n  group_by(Quarter) %&gt;%\n  summarise(median_profit = median(Profit_per_Voyage, na.rm = TRUE))\n\n# Create a dataframe for line reference with linetype mapping\nline_data &lt;- bind_rows(\n  quarter_avg %&gt;% mutate(linetype = \"Mean\"),\n  quarter_median %&gt;% mutate(linetype = \"Median\")\n)\n\nggplot(ship_cleaned, aes(x = Profit_per_Voyage, \n                              y = interaction(Ship_Size,Ship_Type),\n                              fill = Ship_Type)) + \n  geom_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE,\n                      quantiles = 4,\n                      alpha = 0.6,\n                      scale = 0.8) +\n  geom_boxplot(outlier.shape = 16, \n               outlier.colour = \"black\",  \n               outlier.size = 0.5,\n               width = 0.2, \n               position = position_dodge(width = 0.7)) +\n  geom_vline(data = line_data, \n             aes(xintercept = median_profit, linetype = linetype), \n             color = \"white\", size = 0.4)+\n  scale_fill_manual(values = my_palette) +\n  scale_linetype_manual(name = \"Reference\", values = c(\"Median\" = \"dashed\")) +\n  guides(\n    fill = guide_legend(order = 1),\n    linetype = guide_legend(order = 2) # Adds linetype to the legend\n  ) +\n  # set facet title order\n  facet_wrap(~ factor(Quarter, levels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")), ncol = 4) +\n  theme_classic() +  \n  labs(title = \"Seasonal Profit Trends by Ship Type: A Closer Look\",\n       x = \"Operational Profit ('000 USD)\", \n       y = \"Route, Engine & Ship Type\") +\n  theme(\n    axis.text.y = element_text(size = 6), \n    axis.text.x = element_text(size = 6),  \n    axis.title.x = element_text(size = 9),\n    axis.title.y = element_text(size = 9),\n    strip.text = element_text(size = 7, face = \"bold\"),  # Facet title size\n    legend.position = \"top\",\n    legend.title = element_text(size = 8),\n    legend.key.size = unit(0.3, \"cm\"),\n    legend.text = element_text(size = 6),\n    legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n    plot.title = element_text(size = 15,hjust = 0.5,face='bold'),\n    plot.margin = margin(10, 50, 10 ,20), \n    panel.spacing = unit(1, \"lines\"),\n    strip.placement = \"outside\",  # Places strip above the panel\n    strip.switch.pad.wrap = unit(1, \"cm\") \n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\n\n# calculate average profit per quarter\nquarter_median &lt;- ship_cleaned %&gt;%\n  group_by(Quarter) %&gt;%\n  summarise(median_lp = median(Average_Load_Percentage, na.rm = TRUE))\n\n# Create a dataframe for line reference with linetype mapping\nline_data &lt;- bind_rows(\n  quarter_avg %&gt;% mutate(linetype = \"Mean\"),\n  quarter_median %&gt;% mutate(linetype = \"Median\")\n)\n\nggplot(ship_cleaned, aes(x = Average_Load_Percentage, \n                              y = interaction(Ship_Size,Ship_Type),\n                              fill = Ship_Type)) + \n  geom_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE,\n                      quantiles = 4,\n                      alpha = 0.6,\n                      scale = 0.8) +\n  geom_boxplot(outlier.shape = 16, \n               outlier.colour = \"black\",  \n               outlier.size = 0.5,\n               width = 0.2, \n               position = position_dodge(width = 0.7)) + \n  geom_vline(data = line_data, \n             aes(xintercept = median_lp, linetype = linetype), \n             color = \"white\", size = 0.4)+\n  scale_fill_manual(values = my_palette) +\n  scale_linetype_manual(name = \"Reference\", values = c(\"Median\" = \"dashed\")) +\n  guides(\n    fill = guide_legend(order = 1),\n    linetype = guide_legend(order = 2) # Adds linetype to the legend\n  ) +\n  scale_fill_manual(values = my_palette) +\n  # set facet title order\n  facet_wrap(~ factor(Quarter, levels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")), ncol = 4) +\n  theme_classic() +  \n  labs(title = \"Could a lower loading percentage be contributing to decreased revenue?\",\n       subtitle = \"\",\n       x = \"Average Load Percentage (%)\", \n       y = \"Route, Engine & Ship Type\") +\n  theme(\n    axis.text.y = element_text(size = 6), \n    axis.text.x = element_text(size = 6),  \n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_text(size = 10),\n    strip.text = element_text(size = 7, face = \"bold\"),  # Facet title size\n    legend.position = \"top\",\n    legend.title = element_text(size = 8),\n    legend.key.size = unit(0.3, \"cm\"),\n    legend.text = element_text(size = 6),\n    legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n    plot.title = element_text(size = 13,hjust = 0.5,face='bold'),\n    plot.margin = margin(10, 50, 10 ,20), \n    panel.spacing = unit(1, \"lines\"),\n    strip.placement = \"outside\",  # Places strip above the panel\n    strip.switch.pad.wrap = unit(1, \"cm\") \n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.1 Correlation Test\nHowever, the correlation between profit and average load percentage is 0.03, with a p-value of 0.097, indicating a weak and statistically insignificant relationship. This suggests that while load percentage may influence profit, other operational factors likely play a more substantial role.\n\ncor.test(ship_cleaned$Profit_per_Voyage, ship_cleaned$Average_Load_Percentage)\n\n\n    Pearson's product-moment correlation\n\ndata:  ship_cleaned$Profit_per_Voyage and ship_cleaned$Average_Load_Percentage\nt = 1.662, df = 2125, p-value = 0.09666\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.006481381  0.078412419\nsample estimates:\n       cor \n0.03603052"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#financial-perfomance-which-ship-route-types-lead-the-way",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#financial-perfomance-which-ship-route-types-lead-the-way",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "5.3 Financial Perfomance: Which Ship & Route Types Lead the Way?",
    "text": "5.3 Financial Perfomance: Which Ship & Route Types Lead the Way?\nRevenue, profit margin, and cost per nautical mile are crucial indicators of a ship’s financial performance. Higher revenue and profit margins reflect income generation, while cost per nautical mile assesses operational efficiency, including fuel, crew wages, and maintenance. A lower cost per nautical mile indicates better efficiency and enhances profitability.\nThe chart, sorted by profit margin, shows that:\n\nRevenue and Profitability: While revenue remains consistent across different ship and route types, profit margins show substantial variation, ranging from 7.4% to 36.6% among ship types.\nCost Efficiency: The Medium Fish Carrier demonstrates strong operational efficiency with a cost of 1.84 per nautical mile. In contrast, the Medium Bulk Carrier’s higher cost per nautical mile indicates poor cost management. Among route types, shorter distances perform better. Coastal routes show the best cost efficiency, while transoceanic routes have the lowest.\n\nThe Kruskal-Wallis test provides significant evidence (p-value = 0.01) that Cost per nm differs by Route Type, with coastal routes demonstrating notably better cost efficiency compared to long-haul and transoceanic routes. Although the Kruskal-Wallis test fails to reject the null hypothesis for margin, revenue, and cost per nautical mile across ship types, performance differences remain apparent.\n\nby Ship Typeby Route Type\n\n\n\n\n\nDisplay Code\n\n\n# Create a summary dataframe for total revenue per ship_engine for sorting purpose\nship_summary &lt;- ship_cleaned %&gt;%\n  group_by(type_size) %&gt;%\n  summarise(mean_margin_all = mean(Margin_per_Voyage, na.rm = TRUE)) %&gt;%\n  arrange(mean_margin_all)\n\n# Create the long format dataframe for rev & p &gt;&gt; column 1\nship_rev &lt;- ship_cleaned %&gt;%\n    group_by(type_size) %&gt;%\n    summarise(\n        avg_revenue = mean(Revenue_per_Voyage_k, na.rm = TRUE)) %&gt;%\n    pivot_longer(cols = c(avg_revenue), \n                names_to = \"metric\", \n                values_to = \"value\") \n\n# Create the long format dataframe for growth rate and margin &gt;&gt; column 2\nship_margin &lt;- ship_cleaned %&gt;%\n    group_by(type_size) %&gt;%\n    summarise(\n        avg_margin =mean(Margin_per_Voyage, na.rm = TRUE)\n\n    ) %&gt;%\n    pivot_longer(cols = c(avg_margin), \n                names_to = \"metric\", \n                values_to = \"value\") \n\n# Create the long format dataframe for growth rate and margin &gt;&gt; column 3\nship_op_efficiency &lt;- ship_cleaned %&gt;%\n    group_by(type_size) %&gt;%\n    summarise(\n        avg_cost_nm = mean(Cost_per_nm, na.rm = TRUE)\n    ) %&gt;%\n    pivot_longer(cols = c(avg_cost_nm), \n                names_to = \"metric\", \n                values_to = \"value\") \n\n# summary for tooltips\nship_metrics_summary &lt;- ship_cleaned %&gt;%\n  group_by(type_size) %&gt;%\n  summarise(\n    avg_revenue = mean(Revenue_per_Voyage_k, na.rm = TRUE),\n    avg_margin = mean(Margin_per_Voyage, na.rm = TRUE),\n    avg_cost_nm = mean(Cost_per_nm, na.rm = TRUE)\n  )\n\n# Create the combined dataframe with correct tooltips\nship_combined &lt;- bind_rows(\n    ship_rev %&gt;% mutate(category = \"Revenue\"),\n    ship_margin %&gt;% mutate(category = \"Profitability\"),\n    ship_op_efficiency %&gt;% mutate(category = \"Cost Efficiency\")\n) %&gt;%\n  left_join(ship_metrics_summary, by = \"type_size\") %&gt;%\n  mutate(\n    tooltip = case_when(\n      metric == \"avg_revenue\" ~ sprintf(\"Ship Type: %s\\nRevenue: %.2f K\", type_size, value),\n      metric == \"avg_margin\" ~ sprintf(\"Ship Type: %s\\nProfit Margin: %.2f%%\", type_size, value),\n      metric == \"avg_cost_nm\" ~ sprintf(\"Ship Type: %s\\nCost per nm: %.2f\", type_size, value)\n    )\n  )\n\n# avg ref line \navg_revenue &lt;- mean(ship_metrics_summary$avg_revenue, na.rm = TRUE)\navg_margin &lt;- mean(ship_metrics_summary$avg_margin, na.rm = TRUE)\navg_cost &lt;- mean(ship_metrics_summary$avg_cost_nm, na.rm = TRUE)\n\n# Plot with Facet & Hover\np &lt;- ggplot(ship_combined, \n       aes(x = case_when(\n           category == \"Revenue\" ~ factor(type_size, \n                                          levels = ship_summary$type_size),\n           category == \"Profitability\" ~ factor(type_size, \n                                                levels = ship_summary$type_size),\n           category == \"Cost Efficiency\" ~ factor(type_size, \n                                                  levels = ship_summary$type_size)\n         ), \n           y = value,\n           fill = metric)) +\n  geom_bar_interactive(stat = \"identity\",\n                       position = position_dodge(width = 0.7),\n                       aes(tooltip = tooltip, \n                           data_id = type_size),\n                       width = 0.5) +\n  # Reference line using geom_hline\n  geom_hline(data = data.frame(\n    category = c(\"Revenue\", \"Profitability\", \"Cost Efficiency\"),\n    avg_value = c(avg_revenue, avg_margin, avg_cost)\n  ),\n    aes(yintercept = avg_value, linetype = \"Mean*\"),\n    color = \"black\",\n    size = 0.5\n  ) +\n  coord_flip() +\n  facet_wrap(~ factor(category, \n                      levels = c(\"Profitability\", \"Revenue\", \"Cost Efficiency\")),\n             scales = \"free_x\") + \n  labs(\n    title = \"Sailing Towards Profit: Which Ship Types Lead the Way?\",\n    subtitle = \"The Medium Fish Carrier reigns as the top performer, with a revenue of 595K and a profit margin of 36.6%. \\nIn contrast, the Medium Bulk Carrier underperforms, generating 516K in revenue and the lowest margin at 7.4%\",\n    caption = \"*Mean Margin = 21.3%\\n*Mean Revenue = 523K\\n*Mean Cost per nm = 2.31\",\n    x = \"Ship Type\",\n    y = \"\",\n    fill = \"Metric\"\n  ) +\n  theme_classic() +  \n  scale_fill_manual(values = my_palette) +\n  scale_linetype_manual(name = \"Reference\",\n                        values = c(\"Mean*\" = \"dashed\",\"Median\"=\"dashed\")) +\n  guides(\n    fill = guide_legend(order = 1),\n    linetype = guide_legend(order = 2) #adding line type legend\n  ) +\n  theme(\n    axis.text.y = element_text(size = 6,color=\"grey20\"), \n    axis.text.x = element_text(size = 6,color=\"grey20\"),  \n    axis.title.x = element_text(size = 8,color=\"grey20\"),\n    axis.title.y = element_text(size = 8,color=\"grey20\"),\n    strip.text = element_text(size = 7, face = \"bold\"), \n    legend.position = \"top\",\n    legend.title = element_text(size = 6),\n    legend.key.size = unit(0.2, \"cm\"),\n    legend.text = element_text(size = 6),\n    legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n    plot.title = element_text(size = 11,hjust = 0.5,face='bold'),\n    plot.subtitle = element_text(size = 6, hjust = 0, lineheight = 1.1),\n    plot.caption = element_text(size = 6,color=\"grey40\"),\n    plot.margin = margin(10, 50, 10 ,30), \n    panel.spacing = unit(1, \"lines\"),\n    strip.placement = \"outside\",  \n    strip.switch.pad.wrap = unit(2, \"cm\")\n  )\n\ntooltip_css &lt;- \"background-color:white; font-style: bold; font-size:10px; color:black; border-radius: 5px; margin: 3px; padding:3px;\"  \n\n# Convert to Interactive\ngirafe(\n  code = print(p), \n  width_svg = 6,\n  height_svg = 4,\n  options = list(\n    opts_hover(css = \"stroke-width:3px; opacity: 1;\"),\n    opts_hover_inv(css = \"opacity: 0.2;\"),\n    opts_tooltip(css = tooltip_css)\n  ))\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\n\n# Create a summary dataframe for total revenue per ship_engine for sorting purpose\nship_summary &lt;- ship_cleaned %&gt;%\n  group_by(Route_Type) %&gt;%\n  summarise(mean_margin_all = mean(Margin_per_Voyage, na.rm = TRUE)) %&gt;%\n  arrange(mean_margin_all)\n\n# Create the long format dataframe for rev & p &gt;&gt; column 1\nship_rev &lt;- ship_cleaned %&gt;%\n    group_by(Route_Type) %&gt;%\n    summarise(\n        avg_revenue = mean(Revenue_per_Voyage_k, na.rm = TRUE)) %&gt;%\n    pivot_longer(cols = c(avg_revenue), \n                names_to = \"metric\", \n                values_to = \"value\") \n\n# Create the long format dataframe for growth rate and margin &gt;&gt; column 2\nship_margin &lt;- ship_cleaned %&gt;%\n    group_by(Route_Type) %&gt;%\n    summarise(\n        avg_margin =mean(Margin_per_Voyage, na.rm = TRUE)\n\n    ) %&gt;%\n    pivot_longer(cols = c(avg_margin), \n                names_to = \"metric\", \n                values_to = \"value\") \n\n# Create the long format dataframe for growth rate and margin &gt;&gt; column 3\nship_op_efficiency &lt;- ship_cleaned %&gt;%\n    group_by(Route_Type) %&gt;%\n    summarise(\n        avg_cost_nm = mean(Cost_per_nm, na.rm = TRUE)\n    ) %&gt;%\n    pivot_longer(cols = c(avg_cost_nm), \n                names_to = \"metric\", \n                values_to = \"value\") \n\n# summary for tooltips\nship_metrics_summary &lt;- ship_cleaned %&gt;%\n  group_by(Route_Type) %&gt;%\n  summarise(\n    avg_revenue = mean(Revenue_per_Voyage_k, na.rm = TRUE),\n    avg_margin = mean(Margin_per_Voyage, na.rm = TRUE),\n    avg_cost_nm = mean(Cost_per_nm, na.rm = TRUE)\n  )\n\n# Create the combined dataframe with correct tooltips\nship_combined &lt;- bind_rows(\n    ship_rev %&gt;% mutate(category = \"Revenue\"),\n    ship_margin %&gt;% mutate(category = \"Profitability\"),\n    ship_op_efficiency %&gt;% mutate(category = \"Cost Efficiency\")\n) %&gt;%\n  left_join(ship_metrics_summary, by = \"Route_Type\") %&gt;%\n  mutate(\n    tooltip = case_when(\n      metric == \"avg_revenue\" ~ sprintf(\"Ship Type: %s\\nRevenue: %.2f K\", Route_Type, value),\n      metric == \"avg_margin\" ~ sprintf(\"Ship Type: %s\\nProfit Margin: %.2f%%\", Route_Type, value),\n      metric == \"avg_cost_nm\" ~ sprintf(\"Ship Type: %s\\nCost per nm: %.2f\", Route_Type, value)\n    )\n  )\n\n# avg ref line \navg_revenue &lt;- mean(ship_metrics_summary$avg_revenue, na.rm = TRUE)\navg_margin &lt;- mean(ship_metrics_summary$avg_margin, na.rm = TRUE)\navg_cost &lt;- mean(ship_metrics_summary$avg_cost_nm, na.rm = TRUE)\n\n# Plot with Facet & Hover\np &lt;- ggplot(ship_combined, \n       aes(x = case_when(\n           category == \"Revenue\" ~ factor(Route_Type, \n                                          levels = ship_summary$Route_Type),\n           category == \"Profitability\" ~ factor(Route_Type, \n                                                levels = ship_summary$Route_Type),\n           category == \"Cost Efficiency\" ~ factor(Route_Type, \n                                                  levels = ship_summary$Route_Type)\n         ), \n           y = value,\n           fill = metric)) +\n  geom_bar_interactive(stat = \"identity\",\n                       position = position_dodge(width = 0.7),\n                       aes(tooltip = tooltip, \n                           data_id = Route_Type),\n                       width = 0.5) +\n  # Reference line using geom_hline\n  geom_hline(data = data.frame(\n    category = c(\"Revenue\", \"Profitability\", \"Cost Efficiency\"),\n    avg_value = c(avg_revenue, avg_margin, avg_cost)\n  ),\n    aes(yintercept = avg_value, linetype = \"Mean*\"),\n    color = \"black\",\n    size = 0.5\n  ) +\n  coord_flip() +\n  facet_wrap(~ factor(category, \n                      levels = c(\"Profitability\", \"Revenue\", \"Cost Efficiency\")),\n             scales = \"free_x\") + \n  labs(\n    title = \"Sailing Towards Profit: Which Route Types Lead the Way?\",\n    subtitle = \"The plot indicates that short-term routes generally yield higher profit margins and better cost efficiency.\\nNotably, coastal routes achieve the highest profit margin of 25.12% while maintaining the lowest cost per nautical mile at 2\",\n    x = \"Route Type\",\n    y = \"\",\n    fill = \"Metric\"\n  ) +\n  theme_classic() +  \n  scale_fill_manual(values = my_palette) +\n  scale_linetype_manual(name = \"Reference\",\n                        values = c(\"Mean*\" = \"dashed\",\"Median\"=\"dashed\")) +\n  guides(\n    fill = guide_legend(order = 1),\n    linetype = guide_legend(order = 2) #adding line type legend\n  ) +\n  theme(\n    axis.text.y = element_text(size = 6,color=\"grey20\"), \n    axis.text.x = element_text(size = 6,color=\"grey20\"),  \n    axis.title.x = element_text(size = 8,color=\"grey20\"),\n    axis.title.y = element_text(size = 8,color=\"grey20\"),\n    strip.text = element_text(size = 7, face = \"bold\"), \n    legend.position = \"top\",\n    legend.title = element_text(size = 6),\n    legend.key.size = unit(0.2, \"cm\"),\n    legend.text = element_text(size = 6),\n    legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n    plot.title = element_text(size = 11,hjust = 0.5,face='bold'),\n    plot.subtitle = element_text(size = 6, hjust = 0, lineheight = 1.1),\n    plot.caption = element_text(size = 6,color=\"grey40\"),\n    plot.margin = margin(10, 50, 10 ,30), \n    panel.spacing = unit(1, \"lines\"),\n    strip.placement = \"outside\",  \n    strip.switch.pad.wrap = unit(2, \"cm\")\n  )\n\ntooltip_css &lt;- \"background-color:white; font-style: bold; font-size:10px; color:black; border-radius: 5px; margin: 3px; padding:3px;\"  \n\n# Convert to Interactive\ngirafe(\n  code = print(p), \n  width_svg = 6,\n  height_svg = 4,\n  options = list(\n    opts_hover(css = \"stroke-width:3px; opacity: 1;\"),\n    opts_hover_inv(css = \"opacity: 0.2;\"),\n    opts_tooltip(css = tooltip_css)\n  ))\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.1 Normality and Kruskal-Wallis Test\n\nNormality TestKruskal-Wallis Test\n\n\nThe result from Shapiro-Wilk test shows siginificant evidence (p-value &lt;0.05) to reject the null hypothesis and conclude that the attribute “Margin_per_Voyage”,“Revenue_per_Voyage_k” and “Cost_per_nm” do not follow normal distribution . Thus, non parametric Kruskal-Wallis Tests are performed.\n\nshapiro.test(ship_cleaned$Margin_per_Voyage)\n\n\n    Shapiro-Wilk normality test\n\ndata:  ship_cleaned$Margin_per_Voyage\nW = 0.64444, p-value &lt; 2.2e-16\n\nshapiro.test(ship_cleaned$Revenue_per_Voyage_k)\n\n\n    Shapiro-Wilk normality test\n\ndata:  ship_cleaned$Revenue_per_Voyage_k\nW = 0.95836, p-value &lt; 2.2e-16\n\nshapiro.test(ship_cleaned$Cost_per_nm)\n\n\n    Shapiro-Wilk normality test\n\ndata:  ship_cleaned$Cost_per_nm\nW = 0.44123, p-value &lt; 2.2e-16\n\n\n\n\nThree tests all show p-value &gt; 0.05, failing to reject the null hypothesis.\n\n# Kruskal-Wallis test with both Route_Type and Ship_Type\nkruskal_test_margin &lt;- kruskal.test(Margin_per_Voyage ~ type_size, data = ship_cleaned)\nkruskal_test_rev &lt;- kruskal.test(Revenue_per_Voyage_k ~ type_size, data = ship_cleaned)\nkruskal_test_costnm &lt;- kruskal.test(Cost_per_nm ~ type_size, data = ship_cleaned)\n\nkruskal_test_margin_r &lt;- kruskal.test(Margin_per_Voyage ~ Route_Type, data = ship_cleaned)\nkruskal_test_rev_r &lt;- kruskal.test(Revenue_per_Voyage_k ~ Route_Type, data = ship_cleaned)\nkruskal_test_costnm_r &lt;- kruskal.test(Cost_per_nm ~ Route_Type, data = ship_cleaned)\n\nprint(kruskal_test_margin)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Margin_per_Voyage by type_size\nKruskal-Wallis chi-squared = 11.773, df = 11, p-value = 0.3809\n\nprint(kruskal_test_rev)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Revenue_per_Voyage_k by type_size\nKruskal-Wallis chi-squared = 13.122, df = 11, p-value = 0.2854\n\nprint(kruskal_test_costnm)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Cost_per_nm by type_size\nKruskal-Wallis chi-squared = 10.836, df = 11, p-value = 0.4571\n\nprint(kruskal_test_margin_r)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Margin_per_Voyage by Route_Type\nKruskal-Wallis chi-squared = 1.3874, df = 3, p-value = 0.7085\n\nprint(kruskal_test_rev_r)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Revenue_per_Voyage_k by Route_Type\nKruskal-Wallis chi-squared = 1.4154, df = 3, p-value = 0.7019\n\nprint(kruskal_test_costnm_r)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Cost_per_nm by Route_Type\nKruskal-Wallis chi-squared = 10.464, df = 3, p-value = 0.01501\n\n\n\nlibrary(dunn.test)\nmean_cnm &lt;- ship_cleaned %&gt;%\n  group_by(Route_Type) %&gt;%\n  summarise(mean_Cost_per_nm = mean(Cost_per_nm, na.rm = TRUE))\n\nprint(mean_cnm)\n\n# A tibble: 4 × 2\n  Route_Type   mean_Cost_per_nm\n  &lt;fct&gt;                   &lt;dbl&gt;\n1 Coastal                  1.95\n2 Long-haul                2.33\n3 Short-haul               2.05\n4 Transoceanic             2.90\n\ndunn.test(ship_cleaned$Cost_per_nm, ship_cleaned$Route_Type, kw = TRUE)\n\n  Kruskal-Wallis rank sum test\n\ndata: x and group\nKruskal-Wallis chi-squared = 10.4637, df = 3, p-value = 0.02\n\n                           Comparison of x by group                            \n                                (No adjustment)                                \nCol Mean-|\nRow Mean |    Coastal   Long-hau   Short-ha\n---------+---------------------------------\nLong-hau |  -1.475976\n         |     0.0700\n         |\nShort-ha |  -1.357421   0.084122\n         |     0.0873     0.4665\n         |\nTransoce |  -3.223291  -1.807614  -1.846916\n         |    0.0006*     0.0353     0.0324\n\nalpha = 0.05\nReject Ho if p &lt;= alpha/2"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#operational-performance-does-maintenance-status-and-engine-type-influence-operational-cost",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#operational-performance-does-maintenance-status-and-engine-type-influence-operational-cost",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "5.4 Operational Performance: Does Maintenance status and Engine Type Influence Operational Cost?",
    "text": "5.4 Operational Performance: Does Maintenance status and Engine Type Influence Operational Cost?\nAs marine regulations tighten, ship maintenance becomes crucial, as poor upkeep leads to higher operational costs. The plot below shows that Diesel and Heavy Fuel Oil engines with critical maintenance status also incur higher costs.\nTo confirm statistical differences, we conducted a Kruskal-Wallis test to assess whether operational cost per voyage varies by engine type, maintenance status, and their interaction. While neither engine type nor maintenance status alone has a significant impact, there is strong evidence of an interaction effect (p-value = 0.001). This suggests that operational costs depend on the combination of these factors, highlighting the need to consider both when managing expenses.\n\n\n\nDisplay Code\n\n# Create the plot\n\np &lt;- ggplot(ship_cleaned, aes(x = Cost_per_Voyage_k, \n                                  y =  Maintenance_Status,\n                                  fill = Engine_Type)) +   \n  geom_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE,\n                      quantiles = 4,\n                      alpha = 0.6,\n                      scale = 0.8) +\n  geom_boxplot(aes(x = Cost_per_Voyage_k), \n               width = 0.2, \n               position = position_dodge(width = 0.8), \n               alpha = 0.6,\n               outliers = TRUE) +\n  coord_flip()+\n  scale_fill_manual(values = my_palette) +\n  facet_grid(~Engine_Type)+\n  theme_ridges() +\n  labs(title = \"Does Maintenance x Engine Type Influence Cost?\",\n       subtitle = \"Yes, it does affect. The Kruskal-Wallis tests show there's an interaction effect (p-value = 0.001) \\nbetween Maintenance Status and Engine Type on Operational Cost.\",\n       x=\"Operational Cost ('000USD)\" ,\n       y=\"Maintenance\\n Status\")+\n  theme(\n    axis.text.y = element_text(size = 7), \n    axis.text.x = element_text(size = 7),  \n    axis.title.x = element_text(size = 8),\n    axis.title.y = element_text(size = 8),\n    strip.text = element_text(size = 9, face = \"bold\"),  # Facet title size\n    plot.margin = margin(10, 20, 10, 20),  \n    legend.position = \"none\",\n    legend.title = element_text(size=8),\n    legend.key.size = unit(0.3, \"cm\"),\n    legend.text = element_text(size=6),\n    legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n    plot.title = element_text(size=13,hjust=0),\n    plot.subtitle = element_text(size=8,hjust=0),\n    plot.background = element_rect(fill = \"#f3f1e9\",color = NA)\n    )\n    \nplot(p)\n    \n\n\n\n\n\n\n\n\n\n\n\n\n5.4.1 Normality and Kruskal-Wallis Test\n\nNormality TestKruskal-Wallis Test\n\n\nThe result from Shapiro-Wilk test shows siginificant evidence (p-value &lt;0.05) to reject the null hypothesis and conclude that the attribute “Cost per Voyage” does not follow normal distribution . Thus non parametric is used in the following test.\n\nshapiro.test(ship_cleaned$Cost_per_Voyage_k)\n\n\n    Shapiro-Wilk normality test\n\ndata:  ship_cleaned$Cost_per_Voyage_k\nW = 0.95402, p-value &lt; 2.2e-16\n\n\n\n\n\n# Kruskal-Wallis test with both Route_Type and Ship_Type\nkruskal_test_engine &lt;- kruskal.test(Cost_per_Voyage_k ~ Engine_Type, data = ship_cleaned)\nkruskal_test_maintain &lt;- kruskal.test(Cost_per_Voyage_k ~ Maintenance_Status, data = ship_cleaned)\n\n# Create a new interaction factor\nship_cleaned$Interaction &lt;- interaction(ship_cleaned$Maintenance_Status, ship_cleaned$Engine_Type)\n\n# Kruskal-Wallis test on the interaction factor\nkruskal_interaction &lt;- kruskal.test(Cost_per_Voyage_k ~ Interaction, data = ship_cleaned)\n\nprint(kruskal_test_engine)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Cost_per_Voyage_k by Engine_Type\nKruskal-Wallis chi-squared = 0.6954, df = 2, p-value = 0.7063\n\nprint(kruskal_test_maintain)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Cost_per_Voyage_k by Maintenance_Status\nKruskal-Wallis chi-squared = 3.3567, df = 2, p-value = 0.1867\n\nprint(kruskal_interaction)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Cost_per_Voyage_k by Interaction\nKruskal-Wallis chi-squared = 26.162, df = 8, p-value = 0.0009852"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#operational-performance-which-ship-types-have-shorter-tat",
    "href": "Take-home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#operational-performance-which-ship-types-have-shorter-tat",
    "title": "Take Home Exercise 1: Ship performance Analysis",
    "section": "5.5 Operational Performance: Which Ship Types Have Shorter TAT?",
    "text": "5.5 Operational Performance: Which Ship Types Have Shorter TAT?\nTurnaround Time (TAT) measures the time a ship spends in port for operations like unloading, loading, refueling, and maintenance before its next voyage. Shorter turnaround times increase operational efficiency by allowing more voyages and reducing port costs.\nThe plot reveals an unexpected trend:\n\nLarge ships generally have shorter turnaround times across ship types. Only transoceanic container ships, short-haul tankers, and coastal fish carriers exceed the median TAT.\nIn contrast, small and medium ships tend to have longer turnaround times.\n\nA Kruskal-Wallis test (p = 0.029) confirms significant differences in turnaround times across ship sizes. Dunn’s Test further shows that medium ships have longer TAT than large ships, indicating that ship size is a key factor in turnaround efficiency.\n\n\n\nDisplay Code\n\n# Calculate median turnaround time per Ship Type\nturnaround_medians &lt;- ship_cleaned %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarize(median_turnaround = median(Turnaround_Time_hours, na.rm = TRUE))\n\n# reorder factor level\nship_cleaned$Route_Type &lt;- factor(ship_cleaned$Route_Type, \n                                  levels = c(\"Coastal\", \"Short-haul\",\n                                             \"Long-haul\", \"Transoceanic\"))\n\np &lt;- ggplot(ship_cleaned, aes(x = Turnaround_Time_hours, \n                                  y = Route_Type,\n                                  fill = Ship_Type,\n                              color = Ship_Type)) +   \n  geom_boxplot(aes(x = Turnaround_Time_hours), \n               width = 0.4, \n               position = position_dodge(width = 1), \n               alpha = 0.6,\n               outliers = TRUE) +\n  #stat_dots(binwidth = NA,dotsize = 1)+ #\n  # Add Median Turnaround Time reference line\n  geom_vline(data = turnaround_medians, \n             aes(xintercept = median_turnaround, linetype = \"Median\"), \n             color = \"black\", size = 0.3) +\n  # Add \"Median\" to legend\n  scale_linetype_manual(name = \"Reference\", values = c(\"Median\" = \"dotted\")) +\n  scale_fill_manual(values = my_palette) +\n  facet_grid(Ship_Size~Ship_Type)+\n  theme_ridges() +\n  labs(title = \"Which ship types have shorter turnaround times?\",\n       subtitle = \"Shorter turnaround times enhance efficiency by enabling more voyages and lowering port costs.\\nSurprisingly, large ships have shorter turnaround times.\",\n       x=\"Turnaround Time\\n(Hours)\" ,\n       y=\"Route Type\")+\n  theme(\n    axis.text.y = element_text(size = 7), \n    axis.text.x = element_text(size = 7),  \n    axis.title.x = element_text(size = 8),\n    axis.title.y = element_text(size = 8),\n    strip.text = element_text(size = 9, face = \"bold\"), # Facet title size\n    plot.margin = margin(10, 20, 10, 20),  \n    legend.position = \"top\",\n    legend.title = element_text(size=8),\n    legend.key.size = unit(0.3, \"cm\"),\n    legend.text = element_text(size=6),\n    legend.background = element_rect(fill = \"#f3f1e9\"),\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n    plot.title = element_text(size=12,hjust=0),\n    plot.subtitle = element_text(size=8,hjust=0),\n    plot.background = element_rect(fill = \"#f3f1e9\",color = NA)\n    )\n    \nplot(p)\n\n\n\n\n\n\n\n\n\n\n\n\n5.5.1 Normality and Kruskal-Wallis Test\n\nNormality TestKruskal-Wallis Test\n\n\nThe result from Shapiro-Wilk test shows siginificant evidence (p-value &lt;0.05) to reject the null hypothesis and conclude that the attribute “Turnaround Time” does not follow normal distribution . Thus non parametric is used in the following test.\n\nshapiro.test(ship_cleaned$Turnaround_Time_hours)\n\n\n    Shapiro-Wilk normality test\n\ndata:  ship_cleaned$Turnaround_Time_hours\nW = 0.95006, p-value &lt; 2.2e-16\n\n\n\n\n\n# Kruskal-Wallis test with both Route_Type and Ship_Type\nkruskal.test(Turnaround_Time_hours ~ Ship_Size, data = ship_cleaned)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Turnaround_Time_hours by Ship_Size\nKruskal-Wallis chi-squared = 7.0956, df = 2, p-value = 0.02879\n\n\n\nlibrary(dunn.test)\nmean_tat &lt;- ship_cleaned %&gt;%\n  group_by(Ship_Size) %&gt;%\n  summarise(mean_turnaround_time = mean(Turnaround_Time_hours, na.rm = TRUE))\n\nprint(mean_tat)\n\n# A tibble: 3 × 2\n  Ship_Size mean_turnaround_time\n  &lt;fct&gt;                    &lt;dbl&gt;\n1 Small                     41.6\n2 Medium                    43.2\n3 Large                     40.4\n\ndunn.test(ship_cleaned$Turnaround_Time_hours, ship_cleaned$Ship_Size, kw = TRUE)\n\n  Kruskal-Wallis rank sum test\n\ndata: x and group\nKruskal-Wallis chi-squared = 7.0956, df = 2, p-value = 0.03\n\n                           Comparison of x by group                            \n                                (No adjustment)                                \nCol Mean-|\nRow Mean |      Large     Medium\n---------+----------------------\n  Medium |  -2.615613\n         |    0.0045*\n         |\n   Small |  -1.174826   1.798244\n         |     0.1200     0.0361\n\nalpha = 0.05\nReject Ho if p &lt;= alpha/2"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Ex05",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, SmartEDA,easystats,\n               gtsummary,ggthemes, ggstatsplot)\n\n\n# import \"data\" sheet only\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\"data\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-importing-the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-importing-the-data",
    "title": "In-class Ex05",
    "section": "",
    "text": "pacman::p_load(tidyverse, readxl, SmartEDA,easystats,\n               gtsummary,ggthemes, ggstatsplot)\n\n\n# import \"data\" sheet only\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\"data\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#data-overview",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#data-overview",
    "title": "In-class Ex05",
    "section": "2 Data Overview",
    "text": "2 Data Overview\n\n2.1 Check Data with R packages\n\nsummarystrglimpse\n\n\n\nsummary(car_resale)\n\n       Id            Model               Price         Age_08_04    \n Min.   :   1.0   Length:1436        Min.   : 4350   Min.   : 1.00  \n 1st Qu.: 361.8   Class :character   1st Qu.: 8450   1st Qu.:44.00  \n Median : 721.5   Mode  :character   Median : 9900   Median :61.00  \n Mean   : 721.6                      Mean   :10731   Mean   :55.95  \n 3rd Qu.:1081.2                      3rd Qu.:11950   3rd Qu.:70.00  \n Max.   :1442.0                      Max.   :32500   Max.   :80.00  \n   Mfg_Month         Mfg_Year          KM         Quarterly_Tax   \n Min.   : 1.000   Min.   :1998   Min.   :     1   Min.   : 19.00  \n 1st Qu.: 3.000   1st Qu.:1998   1st Qu.: 43000   1st Qu.: 69.00  \n Median : 5.000   Median :1999   Median : 63390   Median : 85.00  \n Mean   : 5.549   Mean   :2000   Mean   : 68533   Mean   : 87.12  \n 3rd Qu.: 8.000   3rd Qu.:2001   3rd Qu.: 87021   3rd Qu.: 85.00  \n Max.   :12.000   Max.   :2004   Max.   :243000   Max.   :283.00  \n     Weight     Guarantee_Period    HP_Bin             CC_bin         \n Min.   :1000   Min.   : 3.000   Length:1436        Length:1436       \n 1st Qu.:1040   1st Qu.: 3.000   Class :character   Class :character  \n Median :1070   Median : 3.000   Mode  :character   Mode  :character  \n Mean   :1072   Mean   : 3.815                                        \n 3rd Qu.:1085   3rd Qu.: 3.000                                        \n Max.   :1615   Max.   :36.000                                        \n     Doors           Gears         Cylinders  Fuel_Type        \n Min.   :2.000   Min.   :3.000   Min.   :4   Length:1436       \n 1st Qu.:3.000   1st Qu.:5.000   1st Qu.:4   Class :character  \n Median :4.000   Median :5.000   Median :4   Mode  :character  \n Mean   :4.033   Mean   :5.026   Mean   :4                     \n 3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:4                     \n Max.   :5.000   Max.   :6.000   Max.   :4                     \n    Color             Met_Color        Automatic       Mfr_Guarantee   \n Length:1436        Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :1.0000   Median :0.00000   Median :0.0000  \n                    Mean   :0.6748   Mean   :0.05571   Mean   :0.4095  \n                    3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n                    Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n BOVAG_Guarantee       ABS            Airbag_1         Airbag_2     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  \n Mean   :0.8955   Mean   :0.8134   Mean   :0.9708   Mean   :0.7228  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n     Airco        Automatic_airco   Boardcomputer      CD_Player     \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.00000   Median :0.0000   Median :0.0000  \n Mean   :0.5084   Mean   :0.05641   Mean   :0.2946   Mean   :0.2187  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  \n  Central_Lock    Powered_Windows Power_Steering       Radio       \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.000   Median :1.0000   Median :0.0000  \n Mean   :0.5801   Mean   :0.562   Mean   :0.9777   Mean   :0.1462  \n 3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n   Mistlamps      Sport_Model     Backseat_Divider  Metallic_Rim   \n Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :0.000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.257   Mean   :0.3001   Mean   :0.7702   Mean   :0.2047  \n 3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n Radio_cassette      Tow_Bar      \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000  \n Mean   :0.1455   Mean   :0.2779  \n 3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n\nstr(car_resale)\n\ntibble [1,436 × 38] (S3: tbl_df/tbl/data.frame)\n $ Id              : num [1:1436] 81 1 2 3 4 5 6 7 8 44 ...\n $ Model           : chr [1:1436] \"TOYOTA Corolla 1.6 5drs 1 4/5-Doors\" \"TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\" \"TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\" \" TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\" ...\n $ Price           : num [1:1436] 18950 13500 13750 13950 14950 ...\n $ Age_08_04       : num [1:1436] 25 23 23 24 26 30 32 27 30 27 ...\n $ Mfg_Month       : num [1:1436] 8 10 10 9 7 3 1 6 3 6 ...\n $ Mfg_Year        : num [1:1436] 2002 2002 2002 2002 2002 ...\n $ KM              : num [1:1436] 20019 46986 72937 41711 48000 ...\n $ Quarterly_Tax   : num [1:1436] 100 210 210 210 210 210 210 210 210 234 ...\n $ Weight          : num [1:1436] 1180 1165 1165 1165 1165 ...\n $ Guarantee_Period: num [1:1436] 3 3 3 3 3 3 3 3 3 3 ...\n $ HP_Bin          : chr [1:1436] \"100-120\" \"&lt; 100\" \"&lt; 100\" \"&lt; 100\" ...\n $ CC_bin          : chr [1:1436] \"1600\" \"&gt;1600\" \"&gt;1600\" \"&gt;1600\" ...\n $ Doors           : num [1:1436] 5 3 3 3 3 3 3 3 3 5 ...\n $ Gears           : num [1:1436] 5 5 5 5 5 5 5 5 5 5 ...\n $ Cylinders       : num [1:1436] 4 4 4 4 4 4 4 4 4 4 ...\n $ Fuel_Type       : chr [1:1436] \"Petrol\" \"Diesel\" \"Diesel\" \"Diesel\" ...\n $ Color           : chr [1:1436] \"Blue\" \"Blue\" \"Silver\" \"Blue\" ...\n $ Met_Color       : num [1:1436] 1 1 1 1 0 0 0 1 1 0 ...\n $ Automatic       : num [1:1436] 1 0 0 0 0 0 0 0 0 0 ...\n $ Mfr_Guarantee   : num [1:1436] 0 0 0 1 1 1 0 0 1 1 ...\n $ BOVAG_Guarantee : num [1:1436] 0 1 1 1 1 1 1 1 1 1 ...\n $ ABS             : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Airbag_1        : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Airbag_2        : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Airco           : num [1:1436] 1 0 1 0 0 1 1 1 1 1 ...\n $ Automatic_airco : num [1:1436] 1 0 0 0 0 0 0 0 0 0 ...\n $ Boardcomputer   : num [1:1436] 0 1 1 1 1 1 1 1 1 1 ...\n $ CD_Player       : num [1:1436] 1 0 1 0 0 0 0 0 1 0 ...\n $ Central_Lock    : num [1:1436] 1 1 1 0 0 1 1 1 1 1 ...\n $ Powered_Windows : num [1:1436] 1 1 0 0 0 1 1 1 1 1 ...\n $ Power_Steering  : num [1:1436] 1 1 1 1 1 1 1 1 1 1 ...\n $ Radio           : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n $ Mistlamps       : num [1:1436] 0 0 0 0 0 1 1 0 0 0 ...\n $ Sport_Model     : num [1:1436] 0 0 0 0 0 0 0 1 0 1 ...\n $ Backseat_Divider: num [1:1436] 0 1 1 1 1 1 1 1 1 1 ...\n $ Metallic_Rim    : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n $ Radio_cassette  : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n $ Tow_Bar         : num [1:1436] 0 0 0 0 0 0 0 0 0 0 ...\n\n\n\n\n\nglimpse(car_resale)\n\nRows: 1,436\nColumns: 38\n$ Id               &lt;dbl&gt; 81, 1, 2, 3, 4, 5, 6, 7, 8, 44, 45, 46, 47, 49, 51, 6…\n$ Model            &lt;chr&gt; \"TOYOTA Corolla 1.6 5drs 1 4/5-Doors\", \"TOYOTA Coroll…\n$ Price            &lt;dbl&gt; 18950, 13500, 13750, 13950, 14950, 13750, 12950, 1690…\n$ Age_08_04        &lt;dbl&gt; 25, 23, 23, 24, 26, 30, 32, 27, 30, 27, 22, 23, 27, 2…\n$ Mfg_Month        &lt;dbl&gt; 8, 10, 10, 9, 7, 3, 1, 6, 3, 6, 11, 10, 6, 11, 11, 11…\n$ Mfg_Year         &lt;dbl&gt; 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002,…\n$ KM               &lt;dbl&gt; 20019, 46986, 72937, 41711, 48000, 38500, 61000, 9461…\n$ Quarterly_Tax    &lt;dbl&gt; 100, 210, 210, 210, 210, 210, 210, 210, 210, 234, 234…\n$ Weight           &lt;dbl&gt; 1180, 1165, 1165, 1165, 1165, 1170, 1170, 1245, 1245,…\n$ Guarantee_Period &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ HP_Bin           &lt;chr&gt; \"100-120\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100…\n$ CC_bin           &lt;chr&gt; \"1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", …\n$ Doors            &lt;dbl&gt; 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 3, 3,…\n$ Gears            &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ Cylinders        &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ Fuel_Type        &lt;chr&gt; \"Petrol\", \"Diesel\", \"Diesel\", \"Diesel\", \"Diesel\", \"Di…\n$ Color            &lt;chr&gt; \"Blue\", \"Blue\", \"Silver\", \"Blue\", \"Black\", \"Black\", \"…\n$ Met_Color        &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,…\n$ Automatic        &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mfr_Guarantee    &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,…\n$ BOVAG_Guarantee  &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ ABS              &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_1         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_2         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airco            &lt;dbl&gt; 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Automatic_airco  &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,…\n$ Boardcomputer    &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ CD_Player        &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,…\n$ Central_Lock     &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Powered_Windows  &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Power_Steering   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Radio            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mistlamps        &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Sport_Model      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,…\n$ Backseat_Divider &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Metallic_Rim     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Radio_cassette   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Tow_Bar          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\n\n\n\n\n2.2 Check Data Using ExpData()\n\nType 1Type 2\n\n\nType 1 is overall data summary;\n\nHaving complete case: It means no missing value\n\n\ncar_resale %&gt;%\n  # explore data\n  ExpData(type = 1) \n\n                                          Descriptions     Value\n1                                   Sample size (nrow)      1436\n2                              No. of variables (ncol)        38\n3                    No. of numeric/interger variables        33\n4                              No. of factor variables         0\n5                                No. of text variables         5\n6                             No. of logical variables         0\n7                          No. of identifier variables         1\n8                                No. of date variables         0\n9             No. of zero variance variables (uniform)         1\n10               %. of variables having complete cases 100% (38)\n11   %. of variables having &gt;0% and &lt;50% missing cases    0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases    0% (0)\n13          %. of variables having &gt;=90% missing cases    0% (0)\n\n\n\n\nType 2 is variable level summary\n\ncar_resale %&gt;%\n  # explore data\n  ExpData(type = 2) \n\n   Index    Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1      1               Id       numeric     1436             0              0\n2      2            Model     character     1436             0              0\n3      3            Price       numeric     1436             0              0\n4      4        Age_08_04       numeric     1436             0              0\n5      5        Mfg_Month       numeric     1436             0              0\n6      6         Mfg_Year       numeric     1436             0              0\n7      7               KM       numeric     1436             0              0\n8      8    Quarterly_Tax       numeric     1436             0              0\n9      9           Weight       numeric     1436             0              0\n10    10 Guarantee_Period       numeric     1436             0              0\n11    11           HP_Bin     character     1436             0              0\n12    12           CC_bin     character     1436             0              0\n13    13            Doors       numeric     1436             0              0\n14    14            Gears       numeric     1436             0              0\n15    15        Cylinders       numeric     1436             0              0\n16    16        Fuel_Type     character     1436             0              0\n17    17            Color     character     1436             0              0\n18    18        Met_Color       numeric     1436             0              0\n19    19        Automatic       numeric     1436             0              0\n20    20    Mfr_Guarantee       numeric     1436             0              0\n21    21  BOVAG_Guarantee       numeric     1436             0              0\n22    22              ABS       numeric     1436             0              0\n23    23         Airbag_1       numeric     1436             0              0\n24    24         Airbag_2       numeric     1436             0              0\n25    25            Airco       numeric     1436             0              0\n26    26  Automatic_airco       numeric     1436             0              0\n27    27    Boardcomputer       numeric     1436             0              0\n28    28        CD_Player       numeric     1436             0              0\n29    29     Central_Lock       numeric     1436             0              0\n30    30  Powered_Windows       numeric     1436             0              0\n31    31   Power_Steering       numeric     1436             0              0\n32    32            Radio       numeric     1436             0              0\n33    33        Mistlamps       numeric     1436             0              0\n34    34      Sport_Model       numeric     1436             0              0\n35    35 Backseat_Divider       numeric     1436             0              0\n36    36     Metallic_Rim       numeric     1436             0              0\n37    37   Radio_cassette       numeric     1436             0              0\n38    38          Tow_Bar       numeric     1436             0              0\n   No_of_distinct_values\n1                   1436\n2                    372\n3                    236\n4                     77\n5                     12\n6                      7\n7                   1263\n8                     13\n9                     59\n10                     9\n11                     3\n12                     3\n13                     4\n14                     4\n15                     1\n16                     3\n17                    10\n18                     2\n19                     2\n20                     2\n21                     2\n22                     2\n23                     2\n24                     2\n25                     2\n26                     2\n27                     2\n28                     2\n29                     2\n30                     2\n31                     2\n32                     2\n33                     2\n34                     2\n35                     2\n36                     2\n37                     2\n38                     2\n\n\n\n\n\n\n\n2.3 Re-Import Data Again and Transform Data Type\n\n# Define selected columns correctly\ncols &lt;- c(\"Mfg_Month\", \"HP_Bin\", \"CC_bin\", \"Doors\", \"Gears\", \"Cylinders\",\n          \"Fuel_Type\", \"Color\", \"Met_Color\", \"Automatic\", \"Mfr_Guarantee\",\n          \"BOVAG_Guarantee\", \"ABS\",\"Airbag_1\", \"Airbag_2\", \"Airco\",\n          \"Automatic_airco\", \"Boardcomputer\", \n          \"CD_Player\", \"Central_Lock\", \"Powered_Windows\", \"Power_Steering\",\n          \"Radio\",\"Mistlamps\", \"Sport_Model\", \"Backseat_Divider\", \"Metallic_Rim\", \n          \"Radio_cassette\", \"Tow_Bar\")  \n\n# Read the dataset\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", sheet = \"data\") %&gt;%\n  mutate(Id = as.character(Id)) %&gt;%  \n  mutate(across(all_of(cols), as.factor))  # Convert selected columns to factors"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#explore-data-using-smarteda-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#explore-data-using-smarteda-packages",
    "title": "In-class Ex05",
    "section": "3 Explore Data Using SmartEDA Packages",
    "text": "3 Explore Data Using SmartEDA Packages\n\n3.1 Explore Numerical Attributes\n\ncar_resale %&gt;%\n  ExpNumViz(target = NULL,\n            nlim = 10,\n            Page=c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target = \"Price\",\n            nlim = 10,\n            Page=c(2,2),\n            col = \"#96C6D999\")\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n3.2 Explore Categorical Attributes\nThe default fig.width = 7 and fig.width = 5 in R markdown, but we can overwrite fig-width and height in Quarto. Let’s plot bar charts for all cat variables:\n\ncar_resale %&gt;%\n  ExpCatViz(target = NULL,\n            clim = 10,\n            col = \"#96C6D999\",\n            margin = 2,\n            Page=c(4,4),\n            sample = 16)\n\n$`0`"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#fit-linear-regression-model",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#fit-linear-regression-model",
    "title": "In-class Ex05",
    "section": "4 Fit Linear Regression Model",
    "text": "4 Fit Linear Regression Model\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight +\n              Guarantee_Period, data = car_resale)\n\n\n4.1 Check Normality with Parameters package\n\ncheck_normality(model)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\n\n4.2 Check Collinearity with Parameters package\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nThe plot indicates benchmark of VIF for us easily to check which variables have potential issue. As the plot shows below, “Age_08_04” and “Mfg_Year” have high VIF\n\n# it will organize the result into dataframe\ncheck_c &lt;- check_collinearity(model)\n# use see package to draw collinearity plot\nplot(check_c)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#remove-mfg_year-and-fit-the-model-again",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#remove-mfg_year-and-fit-the-model-again",
    "title": "In-class Ex05",
    "section": "5 Remove “Mfg_Year” and fit the model again",
    "text": "5 Remove “Mfg_Year” and fit the model again\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight +\n              Guarantee_Period, data = car_resale)\ncheck_normality(model1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nThe plot shows the model have heteroscedasticity:\n\ncheck_model(model1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#gtsummary-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#gtsummary-packages",
    "title": "In-class Ex05",
    "section": "6 gtsummary Packages",
    "text": "6 gtsummary Packages\n\n6.1 Default summary of R\n\nsummary(model1)\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10249.4   -768.6    -15.4    738.5   6356.5 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -2.186e+03  9.722e+02  -2.248   0.0247 *  \nAge_08_04        -1.195e+02  2.760e+00 -43.292   &lt;2e-16 ***\nKM               -2.406e-02  1.201e-03 -20.042   &lt;2e-16 ***\nWeight            1.972e+01  8.379e-01  23.533   &lt;2e-16 ***\nGuarantee_Period  2.682e+01  1.261e+01   2.126   0.0336 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1413 on 1431 degrees of freedom\nMultiple R-squared:  0.8486,    Adjusted R-squared:  0.8482 \nF-statistic:  2005 on 4 and 1431 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n6.2 Use gtsummary to format the layout of the summary\nIt also offer formatting for other tests like ANOVA tests.\n\ntbl_regression(model1, intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"), #extract sigma sign\n    include = c(r.squared, adj.r.squared,\n                AIC, statistic,\n                p.value,sigma)\n  )\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,186\n-4,093, -278\n0.025\n    Age_08_04\n-119\n-125, -114\n&lt;0.001\n    KM\n-0.02\n-0.03, -0.02\n&lt;0.001\n    Weight\n20\n18, 21\n&lt;0.001\n    Guarantee_Period\n27\n2.1, 52\n0.034\n  \n  \n    \n      R² = 0.849; Adjusted R² = 0.848; AIC = 24,915; Statistic = 2,005; p-value = &lt;0.001; σ = 1,413\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\np1 &lt;- parameters(model1)\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\nggcoefstats() gives more information compared to parameters()\n\nggcoefstats(model1, output = \"plot\")"
  }
]